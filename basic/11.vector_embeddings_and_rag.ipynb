{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Embeddingsì™€ RAG ê¸°ì´ˆ\n",
    "\n",
    "ì´ë²ˆ ë…¸íŠ¸ë¶ì—ì„œëŠ” í˜„ëŒ€ AI ì‹œìŠ¤í…œì˜ í•µì‹¬ ê¸°ìˆ ì¸ **ë²¡í„° ì„ë² ë”©(Vector Embeddings)** ê³¼ **RAG(Retrieval-Augmented Generation)** ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
    "\n",
    "## ê°œìš”\n",
    "\n",
    "| ì£¼ì œ | ë‚´ìš© |\n",
    "|------|------|\n",
    "| ë²¡í„° ì„ë² ë”© | í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ìˆ  |\n",
    "| ìœ ì‚¬ë„ ê³„ì‚° | ë²¡í„° ê°„ ì˜ë¯¸ì  ìœ ì‚¬ì„± ì¸¡ì • |\n",
    "| RAG | ì™¸ë¶€ ì§€ì‹ì„ í™œìš©í•œ LLM ì‘ë‹µ ìƒì„± |\n",
    "| ì‹¤ì „ í™œìš© | ë¬¸ì„œ ê²€ìƒ‰ê³¼ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬ì¶• |\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "1. ë²¡í„° ì„ë² ë”©ì˜ ê°œë…ê³¼ ì‘ë™ ì›ë¦¬ ì´í•´í•˜ê¸°\n",
    "2. OpenAI Embeddings APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê¸°\n",
    "3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ í™œìš©í•œ ì˜ë¯¸ì  ìœ ì‚¬ì„± ê³„ì‚°í•˜ê¸°\n",
    "4. RAGì˜ ê°œë…ê³¼ í•„ìš”ì„± ì´í•´í•˜ê¸°\n",
    "5. ê°„ë‹¨í•œ RAG ì‹œìŠ¤í…œ êµ¬í˜„í•˜ê¸°\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë²¡í„° ì„ë² ë”©(Vector Embeddings)ì´ë€?\n",
    "\n",
    "### ê°œë…\n",
    "\n",
    "ë²¡í„° ì„ë² ë”©ì€ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë“±ì˜ ë°ì´í„°ë¥¼ **ê³ ì°¨ì› ë²¡í„° ê³µê°„ì˜ ì **ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ ë°ì´í„°ëŠ” ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œìš´ ìœ„ì¹˜ì— ë°°ì¹˜ë©ë‹ˆë‹¤.\n",
    "\n",
    "### ì™œ í•„ìš”í•œê°€?\n",
    "\n",
    "- **ì˜ë¯¸ì  ê²€ìƒ‰**: í‚¤ì›Œë“œê°€ ì•„ë‹Œ ì˜ë¯¸ë¡œ ê²€ìƒ‰ ê°€ëŠ¥\n",
    "- **ìœ ì‚¬ë„ ê³„ì‚°**: ë‘ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ ìˆ˜ì¹˜ë¡œ ì¸¡ì •\n",
    "- **í´ëŸ¬ìŠ¤í„°ë§**: ë¹„ìŠ·í•œ ë‚´ìš©ì„ ìë™ìœ¼ë¡œ ê·¸ë£¹í™”\n",
    "- **ì¶”ì²œ ì‹œìŠ¤í…œ**: ì‚¬ìš©ì ì·¨í–¥ê³¼ ìœ ì‚¬í•œ ì½˜í…ì¸  ì¶”ì²œ\n",
    "\n",
    "### ì‘ë™ ì›ë¦¬\n",
    "\n",
    "```\n",
    "\"ê°•ì•„ì§€ê°€ ê³µì›ì—ì„œ ë›°ì–´ë†€ê³  ìˆë‹¤\" â†’ [0.2, -0.5, 0.8, ..., 0.3]  (1536ì°¨ì› ë²¡í„°)\n",
    "\"ê°œê°€ ì‚°ì±…í•˜ê³  ìˆì–´ìš”\"            â†’ [0.21, -0.48, 0.82, ..., 0.29]\n",
    "\"ì£¼ì‹ ì‹œì¥ì´ í•˜ë½í–ˆë‹¤\"            â†’ [-0.7, 0.3, -0.1, ..., 0.9]\n",
    "```\n",
    "\n",
    "ìœ„ì˜ ì²« ë‘ ë¬¸ì¥ì€ ì˜ë¯¸ê°€ ë¹„ìŠ·í•˜ë¯€ë¡œ ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œìš´ ìœ„ì¹˜ì— ë†“ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai numpy python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ë¡œë“œ\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"âŒ API key not found\")\n",
    "else:\n",
    "    print(\"âœ… API key loaded\")\n",
    "    \n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. OpenAI Embeddings API ì‚¬ìš©í•˜ê¸°\n",
    "\n",
    "### ì„ë² ë”© ëª¨ë¸\n",
    "\n",
    "OpenAIëŠ” ì—¬ëŸ¬ ì„ë² ë”© ëª¨ë¸ì„ ì œê³µí•©ë‹ˆë‹¤:\n",
    "\n",
    "| ëª¨ë¸ | ì°¨ì› | ì„±ëŠ¥ | ë¹„ìš© |\n",
    "|------|------|------|------|\n",
    "| text-embedding-3-small | 1536 | ë¹ ë¥´ê³  ì €ë ´ | ë‚®ìŒ |\n",
    "| text-embedding-3-large | 3072 | ë†’ì€ ì •í™•ë„ | ë†’ìŒ |\n",
    "\n",
    "ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” `text-embedding-3-small`ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# ì˜ˆì‹œ í…ìŠ¤íŠ¸\n",
    "text = \"ê°•ì•„ì§€ê°€ ê³µì›ì—ì„œ ë›°ì–´ë†€ê³  ìˆë‹¤\"\n",
    "embedding = get_embedding(text)\n",
    "\n",
    "print(f\"ì›ë³¸ í…ìŠ¤íŠ¸: {text}\")\n",
    "print(f\"ì„ë² ë”© ë²¡í„° ì°¨ì›: {len(embedding)}\")\n",
    "print(f\"ë²¡í„°ì˜ ì²« 10ê°œ ê°’: {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì„ë² ë”©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ëŸ¬ ë¬¸ì¥ ì„ë² ë”©\n",
    "sentences = [\n",
    "    \"ê°•ì•„ì§€ê°€ ê³µì›ì—ì„œ ë›°ì–´ë†€ê³  ìˆë‹¤\",\n",
    "    \"ê°œê°€ ì‚°ì±…í•˜ê³  ìˆì–´ìš”\",\n",
    "    \"ê³ ì–‘ì´ê°€ ì†ŒíŒŒì—ì„œ ìê³  ìˆë‹¤\",\n",
    "    \"ì£¼ì‹ ì‹œì¥ì´ í•˜ë½í–ˆë‹¤\",\n",
    "    \"ê²½ì œ ë‰´ìŠ¤ê°€ ë°œí‘œë˜ì—ˆë‹¤\"\n",
    "]\n",
    "\n",
    "embeddings = [get_embedding(sentence) for sentence in sentences]\n",
    "\n",
    "print(f\"ì´ {len(embeddings)}ê°œì˜ ë¬¸ì¥ì„ ì„ë² ë”©í–ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"ê° ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›: {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì½”ì‚¬ì¸ ìœ ì‚¬ë„(Cosine Similarity)\n",
    "\n",
    "### ê°œë…\n",
    "\n",
    "ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” ë‘ ë²¡í„° ì‚¬ì´ì˜ ê°ë„ë¥¼ ì´ìš©í•´ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **1ì— ê°€ê¹Œìš¸ìˆ˜ë¡**: ë§¤ìš° ìœ ì‚¬í•¨ (ê°™ì€ ë°©í–¥)\n",
    "- **0ì— ê°€ê¹Œìš¸ìˆ˜ë¡**: ë¬´ê´€í•¨ (ì§ê°)\n",
    "- **-1ì— ê°€ê¹Œìš¸ìˆ˜ë¡**: ë°˜ëŒ€ë¨ (ì •ë°˜ëŒ€ ë°©í–¥)\n",
    "\n",
    "### ê³„ì‚° ê³µì‹\n",
    "\n",
    "```\n",
    "cosine_similarity = (A Â· B) / (||A|| Ã— ||B||)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\"\"\"\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    \n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "similarity = cosine_similarity(embeddings[0], embeddings[1])\n",
    "print(f\"'{sentences[0]}'\")\n",
    "print(f\"'{sentences[1]}'\")\n",
    "print(f\"ìœ ì‚¬ë„: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë“  ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±\n",
    "print(\"\\n=== ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ===\")\n",
    "print(\"\\n\" + \" \" * 30, end=\"\")\n",
    "for i, _ in enumerate(sentences):\n",
    "    print(f\"ë¬¸ì¥{i+1:2d}\", end=\"  \")\n",
    "print()\n",
    "\n",
    "for i, sent1 in enumerate(sentences):\n",
    "    print(f\"ë¬¸ì¥{i+1} ({sent1[:12]}...)\", end=\" \")\n",
    "    for j, sent2 in enumerate(sentences):\n",
    "        sim = cosine_similarity(embeddings[i], embeddings[j])\n",
    "        print(f\"{sim:6.3f}\", end=\"  \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì¥ ì°¾ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar(query, sentences, embeddings, top_k=3):\n",
    "    \"\"\"ì¿¼ë¦¬ì™€ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì¥ ì°¾ê¸°\"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    similarities = []\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        sim = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append((sentences[i], sim))\n",
    "    \n",
    "    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return similarities[:top_k]\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "query = \"ì• ì™„ë™ë¬¼ì´ ë†€ê³  ìˆì–´ìš”\"\n",
    "results = find_most_similar(query, sentences, embeddings)\n",
    "\n",
    "print(f\"ì§ˆë¬¸: '{query}'\\n\")\n",
    "print(\"ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì¥ë“¤:\")\n",
    "for i, (sentence, similarity) in enumerate(results, 1):\n",
    "    print(f\"{i}. {sentence}\")\n",
    "    print(f\"   ìœ ì‚¬ë„: {similarity:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RAG (Retrieval-Augmented Generation)ë€?\n",
    "\n",
    "### ê°œë…\n",
    "\n",
    "RAGëŠ” ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ LLMì˜ ì‘ë‹µì— í™œìš©í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
    "\n",
    "### ì™œ í•„ìš”í•œê°€?\n",
    "\n",
    "LLMì˜ í•œê³„:\n",
    "- **ì§€ì‹ ì°¨ë‹¨**: í•™ìŠµ ë°ì´í„°ì˜ ì‹œì ê¹Œì§€ë§Œ ì•Œê³  ìˆìŒ\n",
    "- **í™˜ê°(Hallucination)**: ëª¨ë¥´ëŠ” ë‚´ìš©ì„ ê·¸ëŸ´ë“¯í•˜ê²Œ ì§€ì–´ëƒ„\n",
    "- **ë„ë©”ì¸ ì§€ì‹ ë¶€ì¡±**: íŠ¹ì • íšŒì‚¬ë‚˜ ì œí’ˆì˜ ìµœì‹  ì •ë³´ ëª¨ë¦„\n",
    "\n",
    "RAGì˜ í•´ê²°ì±…:\n",
    "- ì‹¤ì‹œê°„ìœ¼ë¡œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì œê³µ\n",
    "- ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ ê¸°ë°˜ ë‹µë³€\n",
    "- ë„ë©”ì¸ íŠ¹í™” ì§€ì‹ë² ì´ìŠ¤ í™œìš©\n",
    "\n",
    "### RAG íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "```\n",
    "1. ë¬¸ì„œ ì¤€ë¹„\n",
    "   â””â†’ ë¬¸ì„œë“¤ì„ ì„ë² ë”©í•˜ì—¬ ë²¡í„° DBì— ì €ì¥\n",
    "   \n",
    "2. ì§ˆë¬¸ ë°›ê¸°\n",
    "   â””â†’ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì„ë² ë”©\n",
    "   \n",
    "3. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "   â””â†’ ìœ ì‚¬ë„ê°€ ë†’ì€ ë¬¸ì„œë“¤ ì°¾ê¸°\n",
    "   \n",
    "4. ì»¨í…ìŠ¤íŠ¸ ì£¼ì…\n",
    "   â””â†’ ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ì§ˆë¬¸ì„ í•¨ê»˜ LLMì— ì „ë‹¬\n",
    "   \n",
    "5. ë‹µë³€ ìƒì„±\n",
    "   â””â†’ LLMì´ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ê°„ë‹¨í•œ RAG ì‹œìŠ¤í…œ êµ¬í˜„\n",
    "\n",
    "ë²¡í„° DB ì—†ì´ numpyë§Œìœ¼ë¡œ ê°„ë‹¨í•œ RAGë¥¼ êµ¬í˜„í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ì§€ì‹ë² ì´ìŠ¤ ì¤€ë¹„ (ì˜ˆ: íšŒì‚¬ ì •ì±… ë¬¸ì„œ)\n",
    "knowledge_base = [\n",
    "    \"ìš°ë¦¬ íšŒì‚¬ì˜ ì—°ì°¨ íœ´ê°€ëŠ” ì…ì‚¬ 1ë…„ í›„ë¶€í„° ì—° 15ì¼ì´ ì œê³µë©ë‹ˆë‹¤.\",\n",
    "    \"ì¬íƒê·¼ë¬´ëŠ” ì£¼ 2íšŒê¹Œì§€ ê°€ëŠ¥í•˜ë©°, ì‚¬ì „ì— íŒ€ì¥ì˜ ìŠ¹ì¸ì„ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "    \"ì ì‹¬ì‹œê°„ì€ 12ì‹œë¶€í„° 1ì‹œê¹Œì§€ì´ë©°, êµ¬ë‚´ì‹ë‹¹ì„ ë¬´ë£Œë¡œ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
    "    \"íšŒì‚¬ ê±´ë¬¼ì€ ì˜¤ì „ 8ì‹œì— ê°œë°©ë˜ê³  ì˜¤í›„ 10ì‹œì— íì‡„ë©ë‹ˆë‹¤.\",\n",
    "    \"ì‹ ì…ì‚¬ì› êµìœ¡ì€ ì…ì‚¬ ì²« ì£¼ì— 3ì¼ê°„ ì§„í–‰ë˜ë©°, í•„ìˆ˜ ì°¸ì„ì…ë‹ˆë‹¤.\",\n",
    "    \"ê²½ì¡°ì‚¬ íœ´ê°€ëŠ” ê²½ì¡°ì‚¬ ì¢…ë¥˜ì— ë”°ë¼ 1ì¼ì—ì„œ 5ì¼ê¹Œì§€ ì œê³µë©ë‹ˆë‹¤.\",\n",
    "    \"ë³µì§€í¬ì¸íŠ¸ëŠ” ë§¤ë…„ 100ë§Œì›ì´ ì§€ê¸‰ë˜ë©°, ììœ ë¡­ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "print(\"ì§€ì‹ë² ì´ìŠ¤ ë¬¸ì„œ ìˆ˜:\", len(knowledge_base))\n",
    "print(\"\\në¬¸ì„œ ëª©ë¡:\")\n",
    "for i, doc in enumerate(knowledge_base, 1):\n",
    "    print(f\"{i}. {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ëª¨ë“  ë¬¸ì„œë¥¼ ì„ë² ë”©\n",
    "print(\"ë¬¸ì„œë“¤ì„ ì„ë² ë”©í•˜ëŠ” ì¤‘...\")\n",
    "kb_embeddings = [get_embedding(doc) for doc in knowledge_base]\n",
    "print(f\"âœ… {len(kb_embeddings)}ê°œ ë¬¸ì„œ ì„ë² ë”© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. RAG í•¨ìˆ˜ êµ¬í˜„\n",
    "def rag_query(question, knowledge_base, kb_embeddings, top_k=2):\n",
    "    \"\"\"\n",
    "    RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€\n",
    "    \n",
    "    Args:\n",
    "        question: ì‚¬ìš©ì ì§ˆë¬¸\n",
    "        knowledge_base: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "        kb_embeddings: ë¬¸ì„œ ì„ë² ë”© ë¦¬ìŠ¤íŠ¸\n",
    "        top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜\n",
    "    \"\"\"\n",
    "    # Step 1: ì§ˆë¬¸ ì„ë² ë”©\n",
    "    print(f\"ì§ˆë¬¸: {question}\\n\")\n",
    "    question_embedding = get_embedding(question)\n",
    "    \n",
    "    # Step 2: ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    print(\"ğŸ“š ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...\")\n",
    "    similarities = []\n",
    "    for i, doc_embedding in enumerate(kb_embeddings):\n",
    "        sim = cosine_similarity(question_embedding, doc_embedding)\n",
    "        similarities.append((i, knowledge_base[i], sim))\n",
    "    \n",
    "    # ìœ ì‚¬ë„ ìˆœ ì •ë ¬\n",
    "    similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "    top_docs = similarities[:top_k]\n",
    "    \n",
    "    print(f\"\\nê°€ì¥ ê´€ë ¨ìˆëŠ” {top_k}ê°œ ë¬¸ì„œ:\")\n",
    "    for i, (idx, doc, sim) in enumerate(top_docs, 1):\n",
    "        print(f\"  {i}. (ìœ ì‚¬ë„: {sim:.4f}) {doc}\")\n",
    "    \n",
    "    # Step 3: ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n",
    "    context = \"\\n\".join([doc for _, doc, _ in top_docs])\n",
    "    \n",
    "    # Step 4: LLMì— ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ ì „ë‹¬\n",
    "    print(\"\\nğŸ¤– LLM ì‘ë‹µ ìƒì„± ì¤‘...\\n\")\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"ë‹¹ì‹ ì€ íšŒì‚¬ ì •ì±…ì— ëŒ€í•´ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ëŠ” HR ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì„œ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"ë‹¤ìŒì€ ê´€ë ¨ ë¬¸ì„œì…ë‹ˆë‹¤:\n",
    "\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ìœ„ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message.content\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"ë‹µë³€:\")\n",
    "    print(answer)\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return answer, top_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 1: ì—°ì°¨ ê´€ë ¨ ì§ˆë¬¸\n",
    "answer, docs = rag_query(\n",
    "    \"ì…ì‚¬í•˜ë©´ íœ´ê°€ë¥¼ ëª‡ ì¼ì´ë‚˜ ì“¸ ìˆ˜ ìˆë‚˜ìš”?\",\n",
    "    knowledge_base,\n",
    "    kb_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 2: ì¬íƒê·¼ë¬´ ê´€ë ¨ ì§ˆë¬¸\n",
    "answer, docs = rag_query(\n",
    "    \"ì§‘ì—ì„œ ì¼í•˜ê³  ì‹¶ì€ë° ê°€ëŠ¥í•œê°€ìš”?\",\n",
    "    knowledge_base,\n",
    "    kb_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 3: ë³µí•© ì§ˆë¬¸\n",
    "answer, docs = rag_query(\n",
    "    \"ì‹ ì…ì‚¬ì›ì´ ì•Œì•„ì•¼ í•  ì¤‘ìš”í•œ ì •ë³´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    knowledge_base,\n",
    "    kb_embeddings,\n",
    "    top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. RAG vs ì¼ë°˜ LLM ë¹„êµ\n",
    "\n",
    "ì§€ì‹ë² ì´ìŠ¤ì— ì—†ëŠ” ì •ë³´ë¥¼ ë¬¼ì–´ë³´ë©´ ì–´ë–»ê²Œ ë ê¹Œìš”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG ì—†ì´ ì§ì ‘ ì§ˆë¬¸\n",
    "def ask_without_rag(question):\n",
    "    \"\"\"RAG ì—†ì´ LLMì— ì§ì ‘ ì§ˆë¬¸\"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"ë‹¹ì‹ ì€ íšŒì‚¬ ì •ì±…ì— ëŒ€í•´ ë‹µë³€í•˜ëŠ” HR ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# ë¹„êµ í…ŒìŠ¤íŠ¸\n",
    "question = \"ìš°ë¦¬ íšŒì‚¬ ì—°ì°¨ëŠ” ë©°ì¹ ì¸ê°€ìš”?\"\n",
    "\n",
    "print(\"ğŸ” RAG ì‚¬ìš© (ì§€ì‹ë² ì´ìŠ¤ ì°¸ê³ ):\")\n",
    "print(\"=\"*60)\n",
    "rag_answer, _ = rag_query(question, knowledge_base, kb_embeddings)\n",
    "\n",
    "print(\"\\n\\nâŒ RAG ë¯¸ì‚¬ìš© (LLM ì§€ì‹ë§Œ ì‚¬ìš©):\")\n",
    "print(\"=\"*60)\n",
    "no_rag_answer = ask_without_rag(question)\n",
    "print(no_rag_answer)\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nğŸ’¡ ì°¨ì´ì :\")\n",
    "print(\"- RAG: ì •í™•í•œ íšŒì‚¬ ì •ì±…(15ì¼)ì„ ì œê³µ\")\n",
    "print(\"- No RAG: ì¼ë°˜ì ì¸ ë‹µë³€ì´ê±°ë‚˜ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì‹¤ì „ íŒ\n",
    "\n",
    "### ì„±ëŠ¥ í–¥ìƒ ë°©ë²•\n",
    "\n",
    "1. **ì²­í¬ í¬ê¸° ì¡°ì •**: ë¬¸ì„œë¥¼ ì ì ˆí•œ í¬ê¸°ë¡œ ë¶„í• \n",
    "2. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: í‚¤ì›Œë“œ + ë²¡í„° ê²€ìƒ‰ ë³‘í–‰\n",
    "3. **ì¬ìˆœìœ„í™”(Re-ranking)**: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì •ë ¬\n",
    "4. **ë©”íƒ€ë°ì´í„° í™œìš©**: ë‚ ì§œ, ì¶œì²˜ ë“± ì¶”ê°€ ì •ë³´ í™œìš©\n",
    "\n",
    "### ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤\n",
    "\n",
    "ì‹¤ì „ì—ì„œëŠ” numpy ëŒ€ì‹  ì „ë¬¸ ë²¡í„° DBë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:\n",
    "\n",
    "| ë²¡í„° DB | íŠ¹ì§• | ì¶”ì²œ ìš©ë„ |\n",
    "|---------|------|----------|\n",
    "| **Pinecone** | ì™„ì „ ê´€ë¦¬í˜•, í™•ì¥ì„± | í”„ë¡œë•ì…˜ ì„œë¹„ìŠ¤ |\n",
    "| **ChromaDB** | ì˜¤í”ˆì†ŒìŠ¤, ê°„ë‹¨ | í”„ë¡œí† íƒ€ì…, ì†Œê·œëª¨ |\n",
    "| **Weaviate** | ì˜¤í”ˆì†ŒìŠ¤, í’ë¶€í•œ ê¸°ëŠ¥ | ë³µì¡í•œ ê²€ìƒ‰ |\n",
    "| **Qdrant** | ì˜¤í”ˆì†ŒìŠ¤, ë¹ ë¥¸ ì„±ëŠ¥ | ëŒ€ìš©ëŸ‰ ë°ì´í„° |\n",
    "\n",
    "### ë¹„ìš© ìµœì í™”\n",
    "\n",
    "- ì„ë² ë”© ìºì‹±: ë™ì¼í•œ í…ìŠ¤íŠ¸ëŠ” ì¬ì‚¬ìš©\n",
    "- ë°°ì¹˜ ì²˜ë¦¬: ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ì„ë² ë”©\n",
    "- ì‘ì€ ëª¨ë¸ ì‚¬ìš©: `text-embedding-3-small` ì„ íƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ìš”ì•½\n",
    "\n",
    "ì´ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ ë‹¤ë£¬ ë‚´ìš©:\n",
    "\n",
    "### í•µì‹¬ í¬ì¸íŠ¸\n",
    "\n",
    "1. **ë²¡í„° ì„ë² ë”©**: í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì˜ë¯¸ë¥¼ ìˆ˜ì¹˜í™”\n",
    "2. **ì½”ì‚¬ì¸ ìœ ì‚¬ë„**: ë‘ ë²¡í„°ì˜ ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ -1~1 ë²”ìœ„ë¡œ ì¸¡ì •\n",
    "3. **RAG**: ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ LLM ì‘ë‹µì˜ ì •í™•ì„± í–¥ìƒ\n",
    "4. **RAG íŒŒì´í”„ë¼ì¸**: ì„ë² ë”© â†’ ê²€ìƒ‰ â†’ ì»¨í…ìŠ¤íŠ¸ ì£¼ì… â†’ ìƒì„±\n",
    "5. **ì‹¤ì „ í™œìš©**: ë¬¸ì„œ ê²€ìƒ‰, ì§ˆì˜ì‘ë‹µ, ì¶”ì²œ ì‹œìŠ¤í…œ ë“±\n",
    "\n",
    "### RAGì˜ ì¥ì \n",
    "\n",
    "- âœ… ìµœì‹  ì •ë³´ í™œìš© ê°€ëŠ¥\n",
    "- âœ… ë„ë©”ì¸ íŠ¹í™” ì§€ì‹ ì œê³µ\n",
    "- âœ… í™˜ê°(Hallucination) ê°ì†Œ\n",
    "- âœ… ì¶œì²˜ ì¶”ì  ê°€ëŠ¥\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ë‹¤ìŒ í•™ìŠµì—ì„œëŠ”:\n",
    "- ChromaDB, Pinecone ë“± ë²¡í„° DB í™œìš©\n",
    "- ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ (ì²­í‚¹ ì „ëµ)\n",
    "- ê³ ê¸‰ RAG ê¸°ë²• (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰, ì¬ìˆœìœ„í™”)\n",
    "- LangChainì„ í™œìš©í•œ RAG íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "---\n",
    "\n",
    "**ì°¸ê³  ìë£Œ**\n",
    "- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)\n",
    "- [Vector Database Comparison](https://github.com/erikbern/ann-benchmarks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
