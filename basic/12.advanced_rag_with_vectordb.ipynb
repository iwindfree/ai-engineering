{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ê³ ê¸‰ RAG: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™œìš©í•œ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ\n",
    "\n",
    "## ê°œìš”\n",
    "\n",
    "ì´ë²ˆ ë…¸íŠ¸ë¶ì—ì„œëŠ” 11ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ ë°°ìš´ RAG ê°œë…ì„ í™•ì¥í•˜ì—¬, **ì‹¤ì „ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê³ ê¸‰ RAG ì‹œìŠ¤í…œ**ì„ êµ¬ì¶•í•©ë‹ˆë‹¤. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ëŸ‰ì˜ ë¬¸ì„œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³ , LLMì´ ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ë§Œë“¤ì–´ë´…ë‹ˆë‹¤.\n",
    "\n",
    "| ì£¼ì œ | ë‚´ìš© |\n",
    "|------|------|\n",
    "| RAG ë³µìŠµ | 11ë²ˆì—ì„œ ë°°ìš´ ê°„ë‹¨í•œ RAG ë³µìŠµ |\n",
    "| ë¬¸ì„œ ì²­í‚¹ | ëŒ€ìš©ëŸ‰ ë¬¸ì„œë¥¼ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë¶„í•  |\n",
    "| ë²¡í„° DB | ChromaDBë¥¼ ì‚¬ìš©í•œ ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶• |\n",
    "| ê³ ê¸‰ ê²€ìƒ‰ | ì˜ë¯¸ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ |\n",
    "| ì‹œê°í™” | t-SNEë¥¼ ì‚¬ìš©í•œ ë²¡í„° ì‹œê°í™” |\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "1. í‚¤ì›Œë“œ ê²€ìƒ‰ê³¼ ë²¡í„° ê²€ìƒ‰ì˜ ì°¨ì´ ì´í•´í•˜ê¸°\n",
    "2. LangChainì„ ì‚¬ìš©í•œ ë¬¸ì„œ ë¡œë”© ë° ì²­í‚¹ ë§ˆìŠ¤í„°í•˜ê¸°\n",
    "3. ChromaDB ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ë° í™œìš©í•˜ê¸°\n",
    "4. ì‹¤ì „ RAG ì‹œìŠ¤í…œ êµ¬í˜„í•˜ê¸°\n",
    "5. ë²¡í„°ë¥¼ ì‹œê°í™”í•˜ì—¬ ê²€ìƒ‰ ì›ë¦¬ ì´í•´í•˜ê¸°\n",
    "\n",
    "## ì‹¤ìŠµ ì‹œë‚˜ë¦¬ì˜¤\n",
    "\n",
    "**CloudStore**ë¼ëŠ” í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ì œí’ˆì˜ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ë§Œë“­ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì œí’ˆ ê¸°ëŠ¥, API ì‚¬ìš©ë²•, ë³´ì•ˆ ì •ì±… ë“±ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê³ , AI ì–´ì‹œìŠ¤í„´íŠ¸ê°€ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•„ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai langchain langchain-openai langchain-community langchain-chroma langchain-huggingface chromadb tiktoken numpy scikit-learn plotly python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# LangChain ê´€ë ¨\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ì‹œê°í™” ê´€ë ¨\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ ì„¤ì •\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"âœ… OpenAI API Key loaded (ì‹œì‘: {openai_api_key[:8]}...)\")\n",
    "else:\n",
    "    print(\"âŒ OpenAI API Key not found\")\n",
    "\n",
    "MODEL = \"gpt-4\"\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RAG ê°œë… ë³µìŠµ\n",
    "\n",
    "11ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ ìš°ë¦¬ëŠ” ê°„ë‹¨í•œ RAGë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. ë³µìŠµí•´ë´…ì‹œë‹¤:\n",
    "\n",
    "### RAGì˜ ê¸°ë³¸ íë¦„\n",
    "\n",
    "```\n",
    "1. ì§ˆë¬¸ ë°›ê¸°: \"Pro í”Œëœ ê°€ê²©ì´ ì–¼ë§ˆì¸ê°€ìš”?\"\n",
    "2. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰: pricing.md ë¬¸ì„œ ì°¾ê¸°\n",
    "3. ì»¨í…ìŠ¤íŠ¸ ì£¼ì…: ì°¾ì€ ë¬¸ì„œ + ì§ˆë¬¸ì„ LLMì— ì „ë‹¬\n",
    "4. ë‹µë³€ ìƒì„±: \"Pro í”Œëœì€ ì›” $15ì…ë‹ˆë‹¤.\"\n",
    "```\n",
    "\n",
    "### 11ë²ˆì—ì„œ ì‚¬ìš©í•œ ë°©ë²• vs ì´ë²ˆ ë…¸íŠ¸ë¶\n",
    "\n",
    "| ë¹„êµ í•­ëª© | 11ë²ˆ ë…¸íŠ¸ë¶ | 12ë²ˆ ë…¸íŠ¸ë¶ |\n",
    "|----------|------------|-------------|\n",
    "| ê²€ìƒ‰ ë°©ì‹ | numpy ì½”ì‚¬ì¸ ìœ ì‚¬ë„ | ChromaDB ë²¡í„° ê²€ìƒ‰ |\n",
    "| ë¬¸ì„œ ì²˜ë¦¬ | ì‘ì€ ì˜ˆì œ í…ìŠ¤íŠ¸ | ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²­í‚¹ |\n",
    "| í™•ì¥ì„± | ì†Œê·œëª¨ | ëŒ€ê·œëª¨ í”„ë¡œë•ì…˜ |\n",
    "| ì„ë² ë”© | OpenAI API | HuggingFace (ë¬´ë£Œ) |\n",
    "| ì‹œê°í™” | ì—†ìŒ | t-SNE ì‹œê°í™” |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Part 1: ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ RAG\n",
    "\n",
    "ë¨¼ì € ê°€ì¥ ê°„ë‹¨í•œ ë°©ì‹ì¸ **í‚¤ì›Œë“œ ë§¤ì¹­**ìœ¼ë¡œ RAGë¥¼ êµ¬í˜„í•´ë´…ì‹œë‹¤. ë¬¸ì„œì—ì„œ ì§ˆë¬¸ì˜ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  ë¬¸ì„œë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë¡œë“œ\n",
    "knowledge = {}\n",
    "\n",
    "# sample_docs í´ë”ì˜ ëª¨ë“  .md íŒŒì¼ ì½ê¸°\n",
    "doc_path = \"sample_docs/**/*.md\"\n",
    "filenames = glob.glob(doc_path, recursive=True)\n",
    "\n",
    "print(f\"ğŸ“š {len(filenames)}ê°œì˜ ë¬¸ì„œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤:\\n\")\n",
    "\n",
    "for filename in filenames:\n",
    "    # íŒŒì¼ëª…ì—ì„œ í‚¤ ìƒì„± (ì˜ˆ: cloudstore_pro.md -> cloudstore_pro)\n",
    "    key = Path(filename).stem.lower()\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        knowledge[key] = f.read()\n",
    "    print(f\"  - {key}: {len(knowledge[key]):,} ë¬¸ì\")\n",
    "\n",
    "print(f\"\\nâœ… ì´ {len(knowledge)}ê°œì˜ ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ í•¨ìˆ˜\n",
    "def get_relevant_context_keyword(message):\n",
    "    \"\"\"ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\"\"\"\n",
    "    # ì•ŒíŒŒë²³ê³¼ ê³µë°±ë§Œ ë‚¨ê¸°ê³  ì œê±°\n",
    "    text = ''.join(ch for ch in message if ch.isalpha() or ch.isspace())\n",
    "    words = text.lower().split()\n",
    "    \n",
    "    # í‚¤ì›Œë“œê°€ ë¬¸ì„œëª…ì— í¬í•¨ëœ ê²½ìš° í•´ë‹¹ ë¬¸ì„œ ë°˜í™˜\n",
    "    relevant_docs = []\n",
    "    for word in words:\n",
    "        for doc_key, doc_content in knowledge.items():\n",
    "            if word in doc_key and doc_content not in relevant_docs:\n",
    "                relevant_docs.append(doc_content)\n",
    "    \n",
    "    return relevant_docs\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_query = \"CloudStore Pro í”Œëœì˜ ê°€ê²©ì´ ì–¼ë§ˆì¸ê°€ìš”?\"\n",
    "results = get_relevant_context_keyword(test_query)\n",
    "\n",
    "print(f\"ì§ˆë¬¸: {test_query}\")\n",
    "print(f\"\\nì°¾ì€ ë¬¸ì„œ ê°œìˆ˜: {len(results)}\")\n",
    "if results:\n",
    "    print(f\"ì²« ë²ˆì§¸ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°:\\n{results[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í‚¤ì›Œë“œ ê²€ìƒ‰ì˜ í•œê³„\n",
    "\n",
    "í‚¤ì›Œë“œ ê²€ìƒ‰ì˜ ë¬¸ì œì :\n",
    "\n",
    "1. **ë™ì˜ì–´ ë¬¸ì œ**: \"ê°€ê²©\"ê³¼ \"ìš”ê¸ˆ\"ì„ ë‹¤ë¥´ê²Œ ì·¨ê¸‰\n",
    "2. **ë¬¸ë§¥ ë¬´ì‹œ**: ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ì§€ ëª»í•¨\n",
    "3. **ì •í™•í•œ ë§¤ì¹­ í•„ìš”**: ì˜¤íƒ€ë‚˜ ë³€í˜•ì— ì·¨ì•½\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "- \"Pro í”Œëœ ë¹„ìš©ì€?\" â†’ \"pro\" í‚¤ì›Œë“œë¡œ ì°¾ìŒ âœ…\n",
    "- \"í”„ë¡œ ë²„ì „ ì–¼ë§ˆì˜ˆìš”?\" â†’ \"í”„ë¡œ\"ëŠ” ì˜ì–´ê°€ ì•„ë‹ˆë¼ì„œ ëª» ì°¾ìŒ âŒ\n",
    "- \"íŒ€ìš© ìš”ê¸ˆì œ ì•Œë ¤ì£¼ì„¸ìš”\" â†’ \"pro\"ë¼ëŠ” í‚¤ì›Œë“œê°€ ì—†ì–´ì„œ ëª» ì°¾ìŒ âŒ\n",
    "\n",
    "**í•´ê²°ì±…**: ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ (Semantic Search) â†’ ë²¡í„° ì„ë² ë”© ì‚¬ìš©!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Part 2: ë¬¸ì„œ ì¤€ë¹„ ë° ì²­í‚¹(Chunking)\n",
    "\n",
    "### ì²­í‚¹ì´ë€?\n",
    "\n",
    "ëŒ€ìš©ëŸ‰ ë¬¸ì„œë¥¼ **ì‘ì€ ì¡°ê°(chunk)** ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "\n",
    "### ì™œ ì²­í‚¹ì´ í•„ìš”í•œê°€?\n",
    "\n",
    "1. **ì„ë² ë”© ëª¨ë¸ ì œí•œ**: í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ\n",
    "2. **ê²€ìƒ‰ ì •í™•ë„**: ì‘ì€ ì¡°ê°ì´ ë” ì •í™•í•œ ë§¤ì¹­\n",
    "3. **ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°**: LLMì— ì „ë‹¬í•  ìˆ˜ ìˆëŠ” í† í° ìˆ˜ ì œí•œ\n",
    "\n",
    "### ì²­í‚¹ ì „ëµ\n",
    "\n",
    "| ì „ëµ | ì„¤ëª… | ì¥ì  | ë‹¨ì  |\n",
    "|------|------|------|------|\n",
    "| ê³ ì • í¬ê¸° | Nê°œ ë¬¸ìë§ˆë‹¤ ë¶„í•  | ê°„ë‹¨ | ë¬¸ë§¥ ë¬´ì‹œ |\n",
    "| ë¬¸ì¥ ë‹¨ìœ„ | ë¬¸ì¥ë³„ë¡œ ë¶„í•  | ì˜ë¯¸ ë³´ì¡´ | í¬ê¸° ë¶ˆê· ë“± |\n",
    "| ì¬ê·€ì  ë¶„í•  | ê³„ì¸µì ìœ¼ë¡œ ë¶„í•  | ìœ ì—°í•¨ | ë³µì¡í•¨ |\n",
    "\n",
    "ìš°ë¦¬ëŠ” **RecursiveCharacterTextSplitter**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ë¬¸ì„œì˜ ë¬¸ì ìˆ˜ì™€ í† í° ìˆ˜ í™•ì¸\n",
    "entire_knowledge_base = \"\"\n",
    "\n",
    "for content in knowledge.values():\n",
    "    entire_knowledge_base += content + \"\\n\\n\"\n",
    "\n",
    "print(f\"ğŸ“Š ì „ì²´ ë¬¸ì„œ í†µê³„:\")\n",
    "print(f\"  ì´ ë¬¸ì ìˆ˜: {len(entire_knowledge_base):,}\")\n",
    "\n",
    "# í† í° ìˆ˜ ê³„ì‚°\n",
    "encoding = tiktoken.encoding_for_model(MODEL)\n",
    "tokens = encoding.encode(entire_knowledge_base)\n",
    "print(f\"  ì´ í† í° ìˆ˜: {len(tokens):,}\")\n",
    "print(f\"\\nğŸ’¡ ì´ ëª¨ë“  ë‚´ìš©ì„ í•œ ë²ˆì— LLMì— ì „ë‹¬í•˜ë©´ ë¹„ìš©ì´ ë§ì´ ë“­ë‹ˆë‹¤!\")\n",
    "print(f\"   ì²­í‚¹ì„ í†µí•´ ê´€ë ¨ ë¶€ë¶„ë§Œ ì°¾ì•„ì„œ ì „ë‹¬í•©ì‹œë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChainì˜ DirectoryLoaderë¡œ ë¬¸ì„œ ë¡œë“œ\n",
    "folders = glob.glob(\"sample_docs/*\")\n",
    "documents = []\n",
    "\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(\n",
    "        folder, \n",
    "        glob=\"**/*.md\", \n",
    "        loader_cls=TextLoader, \n",
    "        loader_kwargs={'encoding': 'utf-8'}\n",
    "    )\n",
    "    folder_docs = loader.load()\n",
    "    \n",
    "    # ë©”íƒ€ë°ì´í„° ì¶”ê°€\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\"âœ… {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"\\nì²« ë²ˆì§¸ ë¬¸ì„œ ì •ë³´:\")\n",
    "print(f\"  íƒ€ì…: {documents[0].metadata['doc_type']}\")\n",
    "print(f\"  íŒŒì¼: {Path(documents[0].metadata['source']).name}\")\n",
    "print(f\"  ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\\n{documents[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecursiveCharacterTextSplitterë¡œ ì²­í‚¹\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # ê° ì²­í¬ì˜ ìµœëŒ€ í¬ê¸° (ë¬¸ì ìˆ˜)\n",
    "    chunk_overlap=200,      # ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„ (ë¬¸ë§¥ ìœ ì§€ë¥¼ ìœ„í•´)\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"âœ‚ï¸  ì²­í‚¹ ê²°ê³¼:\")\n",
    "print(f\"  ì›ë³¸ ë¬¸ì„œ: {len(documents)}ê°œ\")\n",
    "print(f\"  ì²­í¬ ê°œìˆ˜: {len(chunks)}ê°œ\")\n",
    "print(f\"  í‰ê·  ì²­í¬ í¬ê¸°: {sum(len(c.page_content) for c in chunks) // len(chunks):,} ë¬¸ì\")\n",
    "\n",
    "print(f\"\\nì²« ë²ˆì§¸ ì²­í¬:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(chunks[0].page_content)\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"ë©”íƒ€ë°ì´í„°: {chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chunk_sizeì™€ chunk_overlap íŒŒë¼ë¯¸í„°\n",
    "\n",
    "**chunk_size**: ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜\n",
    "- ë„ˆë¬´ í¬ë©´: ê²€ìƒ‰ ì •í™•ë„ â†“, ë¹„ìš© â†‘\n",
    "- ë„ˆë¬´ ì‘ìœ¼ë©´: ë¬¸ë§¥ ì†ì‹¤, ì²­í¬ ê°œìˆ˜ â†‘\n",
    "- ê¶Œì¥: 500-1500 ë¬¸ì\n",
    "\n",
    "**chunk_overlap**: ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„\n",
    "- ë¬¸ë§¥ì´ ì²­í¬ ê²½ê³„ì—ì„œ ëŠê¸°ëŠ” ê²ƒ ë°©ì§€\n",
    "- ê¶Œì¥: chunk_sizeì˜ 10-20%\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "```\n",
    "chunk_size=1000, chunk_overlap=200\n",
    "\n",
    "ì²­í¬ 1: [0----800====1000]\n",
    "ì²­í¬ 2:       [800====1000----1800====2000]\n",
    "ì²­í¬ 3:                    [1800====2000----2800]\n",
    "              ^^^^^ ê²¹ì¹˜ëŠ” ë¶€ë¶„ (overlap)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Part 3: ë²¡í„° ì„ë² ë”©ê³¼ ChromaDB\n",
    "\n",
    "### ChromaDBë€?\n",
    "\n",
    "ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë° íŠ¹í™”ëœ ì˜¤í”ˆì†ŒìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.\n",
    "\n",
    "### ì„ë² ë”© ëª¨ë¸ ì„ íƒ\n",
    "\n",
    "| ëª¨ë¸ | ì œê³µì | ì°¨ì› | ë¹„ìš© | ì„±ëŠ¥ |\n",
    "|------|--------|------|------|------|\n",
    "| text-embedding-3-small | OpenAI | 1536 | ìœ ë£Œ | ë†’ìŒ |\n",
    "| text-embedding-3-large | OpenAI | 3072 | ìœ ë£Œ | ë§¤ìš° ë†’ìŒ |\n",
    "| all-MiniLM-L6-v2 | HuggingFace | 384 | **ë¬´ë£Œ** | ì¤‘ê°„ |\n",
    "\n",
    "ë¹„ìš©ì„ ê³ ë ¤í•˜ì—¬ **all-MiniLM-L6-v2** (HuggingFace)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ë² ë”© ëª¨ë¸ ì„ íƒ\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ë˜ëŠ” OpenAI ì„ë² ë”©ì„ ì‚¬ìš©í•˜ë ¤ë©´:\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "print(\"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"   ëª¨ë¸: all-MiniLM-L6-v2 (HuggingFace)\")\n",
    "print(f\"   ë²¡í„° ì°¨ì›: 384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromaDB ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\n",
    "db_name = \"cloudstore_vector_db\"\n",
    "\n",
    "# ê¸°ì¡´ DBê°€ ìˆë‹¤ë©´ ì‚­ì œ (ì²˜ìŒë¶€í„° ë‹¤ì‹œ ë§Œë“¤ê¸°)\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "    print(\"ğŸ—‘ï¸  ê¸°ì¡´ ë²¡í„° DB ì‚­ì œ\")\n",
    "\n",
    "# ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\n",
    "print(\"ğŸ”„ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘...\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=embeddings, \n",
    "    persist_directory=db_name\n",
    ")\n",
    "\n",
    "print(f\"âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"   ì €ì¥ ìœ„ì¹˜: {db_name}/\")\n",
    "print(f\"   ì´ ë²¡í„° ê°œìˆ˜: {vectorstore._collection.count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²¡í„° ì •ë³´ í™•ì¸\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "# ìƒ˜í”Œ ë²¡í„° ê°€ì ¸ì˜¤ê¸°\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "\n",
    "print(f\"ğŸ“Š ë²¡í„° ìŠ¤í† ì–´ ì •ë³´:\")\n",
    "print(f\"   ì´ ë²¡í„° ê°œìˆ˜: {count:,}\")\n",
    "print(f\"   ë²¡í„° ì°¨ì›: {dimensions:,}\")\n",
    "print(f\"\\n   ìƒ˜í”Œ ë²¡í„°ì˜ ì²« 10ê°œ ê°’:\")\n",
    "print(f\"   {sample_embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì´ì œ ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "query = \"Pro í”Œëœì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?\"\n",
    "\n",
    "# top_kê°œì˜ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰\n",
    "results = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"ì§ˆë¬¸: '{query}'\\n\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"ê°€ì¥ ìœ ì‚¬í•œ {len(results)}ê°œì˜ ì²­í¬:\\n\")\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"[{i}] ì¶œì²˜: {Path(doc.metadata['source']).name}\")\n",
    "    print(f\"    íƒ€ì…: {doc.metadata['doc_type']}\")\n",
    "    print(f\"    ë‚´ìš©:\\n{doc.page_content[:300]}...\\n\")\n",
    "    print(f\"{'-'*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰\n",
    "results_with_scores = vectorstore.similarity_search_with_score(query, k=5)\n",
    "\n",
    "print(f\"ì§ˆë¬¸: '{query}'\\n\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "for i, (doc, score) in enumerate(results_with_scores, 1):\n",
    "    print(f\"[{i}] ìœ ì‚¬ë„ ì ìˆ˜: {score:.4f}\")\n",
    "    print(f\"    ì¶œì²˜: {Path(doc.metadata['source']).name}\")\n",
    "    print(f\"    ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Part 4: RAG ì‹œìŠ¤í…œ êµ¬í˜„\n",
    "\n",
    "ì´ì œ ë²¡í„° ê²€ìƒ‰ê³¼ LLMì„ ê²°í•©í•˜ì—¬ ì™„ì „í•œ RAG ì‹œìŠ¤í…œì„ ë§Œë“­ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(question, top_k=3):\n",
    "    \"\"\"\n",
    "    RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€\n",
    "    \n",
    "    Args:\n",
    "        question: ì‚¬ìš©ì ì§ˆë¬¸\n",
    "        top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜\n",
    "    \"\"\"\n",
    "    print(f\"ì§ˆë¬¸: {question}\\n\")\n",
    "    \n",
    "    # Step 1: ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°\n",
    "    print(\"ğŸ“š ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...\")\n",
    "    results = vectorstore.similarity_search(question, k=top_k)\n",
    "    \n",
    "    print(f\"   âœ… {len(results)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\\n\")\n",
    "    \n",
    "    # ê²€ìƒ‰ëœ ë¬¸ì„œ í‘œì‹œ\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"   [{i}] {Path(doc.metadata['source']).name}\")\n",
    "    \n",
    "    # Step 2: ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "    \n",
    "    # Step 3: LLMì— ì§ˆë¬¸ + ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬\n",
    "    print(\"\\nğŸ¤– AI ë‹µë³€ ìƒì„± ì¤‘...\\n\")\n",
    "    \n",
    "    system_message = f\"\"\"ë‹¹ì‹ ì€ CloudStoreì˜ ë¬¸ì„œ ê²€ìƒ‰ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "ì£¼ì–´ì§„ ë¬¸ì„œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ 'ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë‹µí•˜ì„¸ìš”.\n",
    "\n",
    "ê´€ë ¨ ë¬¸ì„œ:\n",
    "{context}\n",
    "\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.3  # ë‚®ì€ temperatureë¡œ ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€ ìœ ë„\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message.content\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"ë‹µë³€:\\n{answer}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return answer, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 1: ê°€ê²© ê´€ë ¨ ì§ˆë¬¸\n",
    "answer, docs = rag_query(\"Pro í”Œëœì˜ ì›” ìš”ê¸ˆì€ ì–¼ë§ˆì¸ê°€ìš”?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 2: API ê´€ë ¨ ì§ˆë¬¸\n",
    "answer, docs = rag_query(\"íŒŒì¼ì„ ì—…ë¡œë“œí•˜ëŠ” APIëŠ” ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 3: ë³´ì•ˆ ê´€ë ¨ ì§ˆë¬¸\n",
    "answer, docs = rag_query(\"2ë‹¨ê³„ ì¸ì¦ì„ ì„¤ì •í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 4: ì œí’ˆ ë¹„êµ ì§ˆë¬¸\n",
    "answer, docs = rag_query(\n",
    "    \"Basic í”Œëœê³¼ Pro í”Œëœì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    top_k=5  # ë” ë§ì€ ë¬¸ì„œ ê²€ìƒ‰\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Part 5: ë²¡í„° ì‹œê°í™”\n",
    "\n",
    "ë²¡í„°ê°€ ì–´ë–»ê²Œ ë¶„í¬ë˜ì–´ ìˆëŠ”ì§€ ì‹œê°í™”í•˜ì—¬ RAGì˜ ì‘ë™ ì›ë¦¬ë¥¼ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•´ë´…ì‹œë‹¤.\n",
    "\n",
    "### t-SNEë€?\n",
    "\n",
    "**t-SNE** (t-distributed Stochastic Neighbor Embedding)ëŠ” ê³ ì°¨ì› ë°ì´í„°ë¥¼ 2D ë˜ëŠ” 3Dë¡œ ì¶•ì†Œí•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "- 384ì°¨ì› ë²¡í„° â†’ 2D/3Dë¡œ ë³€í™˜\n",
    "- ë¹„ìŠ·í•œ ë²¡í„°ëŠ” ê°€ê¹Œì´, ë‹¤ë¥¸ ë²¡í„°ëŠ” ë©€ë¦¬ ë°°ì¹˜\n",
    "- ì‹œê°í™”ë¥¼ í†µí•´ í´ëŸ¬ìŠ¤í„°ë§ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  ë²¡í„°ì™€ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "\n",
    "# ë¬¸ì„œ íƒ€ì… ì¶”ì¶œ\n",
    "doc_types = [metadata['doc_type'] for metadata in metadatas]\n",
    "\n",
    "# ë¬¸ì„œ íƒ€ì…ë³„ ìƒ‰ìƒ ì§€ì •\n",
    "color_map = {\n",
    "    'products': 'blue',\n",
    "    'api_docs': 'green',\n",
    "    'guides': 'red'\n",
    "}\n",
    "colors = [color_map.get(t, 'gray') for t in doc_types]\n",
    "\n",
    "print(f\"ğŸ“Š ì‹œê°í™” ì¤€ë¹„:\")\n",
    "print(f\"   ë²¡í„° ê°œìˆ˜: {len(vectors):,}\")\n",
    "print(f\"   ë²¡í„° ì°¨ì›: {vectors.shape[1]:,}\")\n",
    "print(f\"   ë¬¸ì„œ íƒ€ì… ë¶„í¬:\")\n",
    "for doc_type in set(doc_types):\n",
    "    count = doc_types.count(doc_type)\n",
    "    print(f\"     - {doc_type}: {count}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNEë¡œ 2Dë¡œ ì¶•ì†Œ\n",
    "print(\"ğŸ”„ t-SNEë¡œ ì°¨ì› ì¶•ì†Œ ì¤‘ (384D â†’ 2D)...\")\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "reduced_vectors_2d = tsne.fit_transform(vectors)\n",
    "\n",
    "print(\"âœ… ì°¨ì› ì¶•ì†Œ ì™„ë£Œ!\")\n",
    "\n",
    "# 2D ì‚°ì ë„ ìƒì„±\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors_2d[:, 0],\n",
    "    y=reduced_vectors_2d[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=8, color=colors, opacity=0.7),\n",
    "    text=[f\"íƒ€ì…: {t}<br>ë‚´ìš©: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='CloudStore ë¬¸ì„œ ë²¡í„° 2D ì‹œê°í™”',\n",
    "    xaxis_title='ì°¨ì› 1',\n",
    "    yaxis_title='ì°¨ì› 2',\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ ì‹œê°í™” í•´ì„:\")\n",
    "print(\"   - íŒŒë€ìƒ‰: ì œí’ˆ ë¬¸ì„œ (products)\")\n",
    "print(\"   - ì´ˆë¡ìƒ‰: API ë¬¸ì„œ (api_docs)\")\n",
    "print(\"   - ë¹¨ê°„ìƒ‰: ê°€ì´ë“œ (guides)\")\n",
    "print(\"   - ë¹„ìŠ·í•œ ë‚´ìš©ì˜ ë¬¸ì„œë¼ë¦¬ ê°€ê¹Œì´ ìœ„ì¹˜í•©ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNEë¡œ 3Dë¡œ ì¶•ì†Œ\n",
    "print(\"ğŸ”„ t-SNEë¡œ ì°¨ì› ì¶•ì†Œ ì¤‘ (384D â†’ 3D)...\")\n",
    "\n",
    "tsne_3d = TSNE(n_components=3, random_state=42, perplexity=30)\n",
    "reduced_vectors_3d = tsne_3d.fit_transform(vectors)\n",
    "\n",
    "print(\"âœ… ì°¨ì› ì¶•ì†Œ ì™„ë£Œ!\")\n",
    "\n",
    "# 3D ì‚°ì ë„ ìƒì„±\n",
    "fig_3d = go.Figure(data=[go.Scatter3d(\n",
    "    x=reduced_vectors_3d[:, 0],\n",
    "    y=reduced_vectors_3d[:, 1],\n",
    "    z=reduced_vectors_3d[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"íƒ€ì…: {t}<br>ë‚´ìš©: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig_3d.update_layout(\n",
    "    title='CloudStore ë¬¸ì„œ ë²¡í„° 3D ì‹œê°í™”',\n",
    "    scene=dict(\n",
    "        xaxis_title='ì°¨ì› 1',\n",
    "        yaxis_title='ì°¨ì› 2',\n",
    "        zaxis_title='ì°¨ì› 3'\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=800,\n",
    "    margin=dict(r=10, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig_3d.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ 3D ì‹œê°í™”ëŠ” ë§ˆìš°ìŠ¤ë¡œ íšŒì „í•˜ì—¬ ë‹¤ì–‘í•œ ê°ë„ì—ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Part 6: ì„±ëŠ¥ ë¹„êµ ë° ìµœì í™”\n",
    "\n",
    "### í‚¤ì›Œë“œ ê²€ìƒ‰ vs ë²¡í„° ê²€ìƒ‰ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„êµ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤\n",
    "test_questions = [\n",
    "    \"íŒ€ìš© ìš”ê¸ˆì œì˜ ê°€ê²©ì€?\",\n",
    "    \"API í‚¤ë¥¼ ì–´ë–»ê²Œ ë§Œë“œë‚˜ìš”?\",\n",
    "    \"ë³´ì•ˆì„ ê°•í™”í•˜ëŠ” ë°©ë²•\",\n",
    "    \"ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ”¬ í‚¤ì›Œë“œ ê²€ìƒ‰ vs ë²¡í„° ê²€ìƒ‰ ë¹„êµ\\n\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"ì§ˆë¬¸: '{question}'\\n\")\n",
    "    \n",
    "    # í‚¤ì›Œë“œ ê²€ìƒ‰\n",
    "    keyword_results = get_relevant_context_keyword(question)\n",
    "    print(f\"  í‚¤ì›Œë“œ ê²€ìƒ‰: {len(keyword_results)}ê°œ ë¬¸ì„œ ë°œê²¬\")\n",
    "    \n",
    "    # ë²¡í„° ê²€ìƒ‰\n",
    "    vector_results = vectorstore.similarity_search(question, k=3)\n",
    "    print(f\"  ë²¡í„° ê²€ìƒ‰: {len(vector_results)}ê°œ ë¬¸ì„œ ë°œê²¬\")\n",
    "    if vector_results:\n",
    "        print(f\"    â†’ {Path(vector_results[0].metadata['source']).name}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì²­í¬ í¬ê¸° ìµœì í™” íŒ\n",
    "\n",
    "#### ì‹¤í—˜ ê²°ê³¼ (ì¼ë°˜ì ì¸ ê°€ì´ë“œë¼ì¸)\n",
    "\n",
    "| chunk_size | ê²€ìƒ‰ ì •í™•ë„ | ì²˜ë¦¬ ì†ë„ | ë¹„ìš© | ì¶”ì²œ ìš©ë„ |\n",
    "|------------|------------|----------|------|----------|\n",
    "| 200-300 | â­â­ | â­â­â­ | $ | ì§§ì€ ì§ˆë¬¸ |\n",
    "| 500-1000 | â­â­â­ | â­â­ | $$ | ì¼ë°˜ì  |\n",
    "| 1500-2000 | â­â­ | â­ | $$$ | ê¸´ ë¬¸ë§¥ í•„ìš” |\n",
    "\n",
    "#### ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- [ ] ë¬¸ì„œ íƒ€ì…ë³„ë¡œ ë‹¤ë¥¸ chunk_size ì‚¬ìš©\n",
    "- [ ] chunk_overlapì€ chunk_sizeì˜ 10-20%\n",
    "- [ ] ê²€ìƒ‰ í›„ ì¬ìˆœìœ„í™”(re-ranking) ê³ ë ¤\n",
    "- [ ] ë©”íƒ€ë°ì´í„° í•„í„°ë§ í™œìš©\n",
    "- [ ] ì„ë² ë”© ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬\n",
    "\n",
    "### ë¹„ìš© ìµœì í™”\n",
    "\n",
    "**ì„ë² ë”© ë¹„ìš© ì ˆê°:**\n",
    "- HuggingFace ëª¨ë¸ ì‚¬ìš© (ë¬´ë£Œ)\n",
    "- ì„ë² ë”© ìºì‹±\n",
    "- ë°°ì¹˜ ì²˜ë¦¬\n",
    "\n",
    "**LLM ë¹„ìš© ì ˆê°:**\n",
    "- top_k ê°’ ìµœì†Œí™” (í•„ìš”í•œ ë§Œí¼ë§Œ)\n",
    "- ì§§ì€ ì²­í¬ ì‚¬ìš©\n",
    "- temperature ë‚®ì¶”ê¸° (ì‚¬ì‹¤ ê¸°ë°˜ ë‹µë³€)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ìš”ì•½\n",
    "\n",
    "ì´ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ ë°°ìš´ ë‚´ìš©:\n",
    "\n",
    "### í•µì‹¬ ê°œë…\n",
    "\n",
    "1. **ì²­í‚¹(Chunking)**: ëŒ€ìš©ëŸ‰ ë¬¸ì„œë¥¼ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë¶„í• \n",
    "   - RecursiveCharacterTextSplitter ì‚¬ìš©\n",
    "   - chunk_sizeì™€ chunk_overlap ìµœì í™”\n",
    "\n",
    "2. **ë²¡í„° ì„ë² ë”©**: í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜\n",
    "   - HuggingFace all-MiniLM-L6-v2 ëª¨ë¸ ì‚¬ìš©\n",
    "   - 384ì°¨ì› ë²¡í„° ìƒì„±\n",
    "\n",
    "3. **ChromaDB**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¡œ íš¨ìœ¨ì  ê²€ìƒ‰\n",
    "   - ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰\n",
    "   - ë©”íƒ€ë°ì´í„° í•„í„°ë§\n",
    "\n",
    "4. **RAG íŒŒì´í”„ë¼ì¸**: ê²€ìƒ‰ + ìƒì„± í†µí•©\n",
    "   - ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°\n",
    "   - ì»¨í…ìŠ¤íŠ¸ ì£¼ì…í•˜ì—¬ LLM í˜¸ì¶œ\n",
    "\n",
    "5. **ì‹œê°í™”**: t-SNEë¡œ ë²¡í„° ë¶„í¬ í™•ì¸\n",
    "   - 2D/3D ì‚°ì ë„\n",
    "   - ë¬¸ì„œ í´ëŸ¬ìŠ¤í„°ë§ í™•ì¸\n",
    "\n",
    "### 11ë²ˆ ë…¸íŠ¸ë¶ê³¼ì˜ ì°¨ì´\n",
    "\n",
    "| í•­ëª© | 11ë²ˆ (ê¸°ë³¸ RAG) | 12ë²ˆ (ê³ ê¸‰ RAG) |\n",
    "|------|----------------|----------------|\n",
    "| ê²€ìƒ‰ ë°©ì‹ | numpy ì½”ì‚¬ì¸ ìœ ì‚¬ë„ | ChromaDB ë²¡í„° ê²€ìƒ‰ |\n",
    "| ë¬¸ì„œ ì²˜ë¦¬ | ì‘ì€ ì˜ˆì œ | LangChain ì²­í‚¹ |\n",
    "| í™•ì¥ì„± | ì†Œê·œëª¨ | ëŒ€ê·œëª¨ ê°€ëŠ¥ |\n",
    "| ì‹œê°í™” | ì—†ìŒ | t-SNE ì‹œê°í™” |\n",
    "| í”„ë¡œë•ì…˜ | í•™ìŠµìš© | ì‹¤ì „ í™œìš© ê°€ëŠ¥ |\n",
    "\n",
    "### í”„ë¡œë•ì…˜ ê³ ë ¤ì‚¬í•­\n",
    "\n",
    "ì‹¤ì œ ì„œë¹„ìŠ¤ì— ì ìš©í•˜ë ¤ë©´:\n",
    "\n",
    "1. **í™•ì¥ì„±**\n",
    "   - Pinecone, Weaviate ë“± ê´€ë¦¬í˜• ë²¡í„° DB ì‚¬ìš©\n",
    "   - ë¶„ì‚° ì²˜ë¦¬\n",
    "\n",
    "2. **ì„±ëŠ¥**\n",
    "   - ì„ë² ë”© ìºì‹±\n",
    "   - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í‚¤ì›Œë“œ + ë²¡í„°)\n",
    "   - ì¬ìˆœìœ„í™”(re-ranking)\n",
    "\n",
    "3. **ëª¨ë‹ˆí„°ë§**\n",
    "   - ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­\n",
    "   - ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘\n",
    "   - A/B í…ŒìŠ¤íŒ…\n",
    "\n",
    "4. **ë¹„ìš© ìµœì í™”**\n",
    "   - ì˜¤í”ˆì†ŒìŠ¤ ì„ë² ë”© ëª¨ë¸\n",
    "   - ë°°ì¹˜ ì²˜ë¦¬\n",
    "   - ìºì‹± ì „ëµ\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ë” ê¹Šì´ í•™ìŠµí•˜ë ¤ë©´:\n",
    "\n",
    "- **ê³ ê¸‰ RAG ê¸°ë²•**\n",
    "  - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + ë²¡í„°)\n",
    "  - ì¬ìˆœìœ„í™” (Cross-Encoder)\n",
    "  - ì¿¼ë¦¬ í™•ì¥ (Query Expansion)\n",
    "\n",
    "- **ë‹¤ë¥¸ ë²¡í„° DB**\n",
    "  - Pinecone (ê´€ë¦¬í˜•)\n",
    "  - Weaviate (ì˜¤í”ˆì†ŒìŠ¤)\n",
    "  - Qdrant (ê³ ì„±ëŠ¥)\n",
    "\n",
    "- **LangChain ê³ ê¸‰ ê¸°ëŠ¥**\n",
    "  - RetrievalQA ì²´ì¸\n",
    "  - ëŒ€í™” ë©”ëª¨ë¦¬\n",
    "  - ì—ì´ì „íŠ¸\n",
    "\n",
    "---\n",
    "\n",
    "## ì°¸ê³  ìë£Œ\n",
    "\n",
    "- [LangChain ê³µì‹ ë¬¸ì„œ](https://python.langchain.com/docs/)\n",
    "- [ChromaDB ë¬¸ì„œ](https://docs.trychroma.com/)\n",
    "- [HuggingFace Sentence Transformers](https://www.sbert.net/)\n",
    "- [RAG ë…¼ë¬¸ (Lewis et al., 2020)](https://arxiv.org/abs/2005.11401)\n",
    "- [t-SNE ì‹œê°í™” ê°€ì´ë“œ](https://distill.pub/2016/misread-tsne/)\n",
    "\n",
    "---\n",
    "\n",
    "**ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰**\n",
    "\n",
    "ì‹¤ì „ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. ì´ì œ ìì‹ ë§Œì˜ ë¬¸ì„œ ê²€ìƒ‰ AIë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
