{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM API 기초 (Part 1/3)\n",
    "\n",
    "이 노트북은 LLM API 시리즈의 첫 번째 파트로, 대형 언어 모델 API의 기본 개념과 사용법을 다룹니다.\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "| 목표 | 설명 |\n",
    "|------|------|\n",
    "| LLM API 이해 | 대형 언어 모델 API의 개념과 구조 |\n",
    "| 환경 설정 | API 키 발급 및 설정 방법 |\n",
    "| 메시지 구조 | role과 messages 배열 이해 |\n",
    "| 첫 API 호출 | OpenAI API 기본 사용법 |\n",
    "| 기본 활용 | 요약, 번역, Q&A 예시 |\n",
    "\n",
    "## 시리즈 구성\n",
    "\n",
    "- **Part 1 (현재)**: LLM API 기초 - 환경설정, 메시지 구조, 기본 호출\n",
    "- **Part 2**: LLM API 중급 - 파라미터, 스트리밍, 에러처리, 다중 LLM\n",
    "- **Part 3**: LLM API 고급 - 대화 이력, 캐싱, 에이전트, 프레임워크\n",
    "\n",
    "## 사전 요구사항\n",
    "\n",
    "- Python 환경 설정 완료 (`0.environment.ipynb` 참조)\n",
    "- OpenAI API 키 (필수)\n",
    "- Anthropic API 키 (선택)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. LLM API란?\n",
    "\n",
    "**대형 언어 모델(LLM) API**는 HTTP 요청을 통해 AI 모델에 접근하는 인터페이스입니다. \n",
    "텍스트 생성, 요약, 번역, 코드 작성 등 다양한 작업을 수행할 수 있습니다.\n",
    "\n",
    "### 주요 LLM 제공업체\n",
    "\n",
    "| 제공업체 | 대표 모델 | 특징 |\n",
    "|----------|----------|------|\n",
    "| OpenAI | GPT-4o, GPT-4.1 | 업계 표준 API, 가장 널리 사용 |\n",
    "| Anthropic | Claude 3.5/4 | 긴 컨텍스트(200K), 안전성 강조 |\n",
    "| Google | Gemini 2.0 | 멀티모달, 무료 티어 제공 |\n",
    "| Meta | Llama 3 | 오픈소스, 로컬 실행 가능 |\n",
    "\n",
    "### API 호출 흐름\n",
    "\n",
    "```\n",
    "[사용자 코드] → HTTP POST 요청 → [LLM 서버] → JSON 응답 → [결과 처리]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 환경 설정\n",
    "\n",
    "### API 키 발급\n",
    "\n",
    "각 서비스에서 API 키를 발급받아야 합니다:\n",
    "\n",
    "| 서비스 | 발급 링크 | 무료 티어 |\n",
    "|--------|----------|----------|\n",
    "| OpenAI | https://platform.openai.com | 유료 |\n",
    "| Anthropic | https://console.anthropic.com | 유료 |\n",
    "| Google AI | https://aistudio.google.com | 무료 티어 있음 |\n",
    "\n",
    "### .env 파일 설정\n",
    "\n",
    "프로젝트 루트에 `.env` 파일을 생성하고 API 키를 추가합니다:\n",
    "\n",
    "```bash\n",
    "OPENAI_API_KEY=sk-...\n",
    "ANTHROPIC_API_KEY=sk-ant-...\n",
    "GOOGLE_API_KEY=AI...\n",
    "```\n",
    "\n",
    "> **주의**: `.env` 파일은 절대 Git에 커밋하지 마세요! `.gitignore`에 추가하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치 (필요시 주석 해제)\n",
    "# !pip install openai anthropic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# 환경변수 로드\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== API 키 상태 ===\n",
      "  OPENAI_API_KEY: sk-pr...\n",
      "  ANTHROPIC_API_KEY: 설정되지 않음\n",
      "  GOOGLE_API_KEY: 설정되지 않음\n"
     ]
    }
   ],
   "source": [
    "# API 키 확인 함수\n",
    "def check_api_key(name: str, key: str | None, prefix_len: int = 5) -> None:\n",
    "    \"\"\"API 키 존재 여부를 확인하고 앞부분만 출력합니다.\"\"\"\n",
    "    if key:\n",
    "        print(f\"  {name}: {key[:prefix_len]}...\")\n",
    "    else:\n",
    "        print(f\"  {name}: 설정되지 않음\")\n",
    "\n",
    "# API 키 로드 및 확인\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "print(\"=== API 키 상태 ===\")\n",
    "check_api_key(\"OPENAI_API_KEY\", openai_api_key)\n",
    "check_api_key(\"ANTHROPIC_API_KEY\", anthropic_api_key)\n",
    "check_api_key(\"GOOGLE_API_KEY\", google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 클라이언트 초기화\n",
    "client = OpenAI()  # OPENAI_API_KEY 환경변수를 자동으로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 메시지 구조 이해\n",
    "\n",
    "LLM API 를 사용하여 전송되는 메세지는  일반적으로 아래와 같이  **메시지 배열** 형태로 구성됩니다..\n",
    "\n",
    "### 기본 구조\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"model\": \"gpt-4o-mini\",\n",
    "  \"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"당신은 친절한 AI입니다.\"},\n",
    "    {\"role\": \"user\", \"content\": \"안녕하세요!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"안녕하세요! 무엇을 도와드릴까요?\"},\n",
    "    {\"role\": \"user\", \"content\": \"파이썬에 대해 알려주세요.\"}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### 메시지 역할(Role)\n",
    "\n",
    "| 역할 | 설명 | 필수 여부 |\n",
    "|------|------|----------|\n",
    "| **system** | AI의 행동 지침, 페르소나 설정 | 선택 |\n",
    "| **user** | 사용자의 질문이나 요청 | 필수 |\n",
    "| **assistant** | AI의 이전 응답 (대화 이력) | 선택 |\n",
    "\n",
    "### 핵심 포인트\n",
    "\n",
    "- `system` 메시지로 AI의 역할과 행동 방식을 지정\n",
    "- 대화 맥락을 유지하려면 이전 메시지들을 배열에 포함\n",
    "- LLM은 상태를 저장하지 않으므로, 매 요청마다 전체 대화 전달 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 메시지 구조 ===\n",
      "[0] role: system, content: 당신은 친절한 AI 어시스턴트입니다. 간결하게 답변하세...\n",
      "[1] role: user, content: 파이썬이란 무엇인가요?...\n"
     ]
    }
   ],
   "source": [
    "# 메시지 구조 예시\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"당신은 친절한 AI 어시스턴트입니다. 간결하게 답변하세요.\"},\n",
    "    {\"role\": \"user\", \"content\": \"파이썬이란 무엇인가요?\"}\n",
    "]\n",
    "\n",
    "# 메시지 구조 확인\n",
    "print(\"=== 메시지 구조 ===\")\n",
    "for i, msg in enumerate(messages):\n",
    "    print(f\"[{i}] role: {msg['role']}, content: {msg['content'][:30]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 첫 번째 API 호출\n",
    "\n",
    "이제 실제로 OpenAI API를 호출해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AI 응답 ===\n",
      "안녕하세요! 저는 AI 어시스턴트입니다. 다양한 주제에 대해 정보를 제공하고, 질문에 답변하며, 사람들의 필요를 지원하기 위해 만들어졌습니다. 언제든지 도움이 필요하시면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 기본 API 호출\n",
    "client = OpenAI()\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"당신은 친절한 AI 어시스턴트입니다.\"},\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요! 간단히 자기소개 해주세요.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 응답 출력\n",
    "print(\"=== AI 응답 ===\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 응답 객체 구조\n",
    "\n",
    "API 응답에는 생성된 텍스트 외에도 다양한 메타데이터가 포함됩니다.\n",
    "\n",
    "| 필드 | 설명 |\n",
    "|------|------|\n",
    "| `id` | 요청 고유 식별자 |\n",
    "| `model` | 실제 사용된 모델명 |\n",
    "| `choices[0].message.content` | 생성된 응답 텍스트 |\n",
    "| `choices[0].finish_reason` | 종료 이유 (stop, length 등) |\n",
    "| `usage.prompt_tokens` | 입력 토큰 수 |\n",
    "| `usage.completion_tokens` | 출력 토큰 수 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 응답 객체 상세 ===\n",
      "ID: chatcmpl-CxiAEiw6HXl9cB8Km3umVtJTVDo84\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Finish Reason: stop\n",
      "\n",
      "--- 토큰 사용량 ---\n",
      "입력 토큰: 36\n",
      "출력 토큰: 49\n",
      "총 토큰: 85\n"
     ]
    }
   ],
   "source": [
    "# 응답 객체 상세 확인\n",
    "print(\"=== 응답 객체 상세 ===\")\n",
    "print(f\"ID: {response.id}\")\n",
    "print(f\"Model: {response.model}\")\n",
    "print(f\"Finish Reason: {response.choices[0].finish_reason}\")\n",
    "print(f\"\\n--- 토큰 사용량 ---\")\n",
    "print(f\"입력 토큰: {response.usage.prompt_tokens}\")\n",
    "print(f\"출력 토큰: {response.usage.completion_tokens}\")\n",
    "print(f\"총 토큰: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 전체 응답 (JSON) ===\n",
      "{\n",
      "  \"id\": \"chatcmpl-CxiAEiw6HXl9cB8Km3umVtJTVDo84\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"안녕하세요! 저는 AI 어시스턴트입니다. 다양한 주제에 대해 정보를 제공하고, 질문에 답변하며, 사람들의 필요를 지원하기 위해 만들어졌습니다. 언제든지 도움이 필요하시면 말씀해 주세요!\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1768347154,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_c4585b5b9c\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 49,\n",
      "    \"prompt_tokens\": 36,\n",
      "    \"total_tokens\": 85,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 전체 응답을 JSON으로 확인\n",
    "print(\"=== 전체 응답 (JSON) ===\")\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 기본 활용 예시\n",
    "\n",
    "LLM API의 대표적인 활용 사례를 살펴봅니다.\n",
    "\n",
    "### 활용 사례 요약\n",
    "\n",
    "| 활용 사례 | system prompt 역할 | 특징 |\n",
    "|----------|-------------------|------|\n",
    "| 텍스트 요약 | 요약 전문가 역할 | 핵심 내용 추출 |\n",
    "| 번역 | 번역가 역할 | 문맥 유지 |\n",
    "| Q&A | 특정 분야 전문가 | 정확한 답변 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 헬퍼 함수\n",
    "def ask_llm(system_prompt: str, user_message: str, model: str = \"gpt-4o-mini\") -> str:\n",
    "    \"\"\"시스템 프롬프트와 사용자 메시지로 LLM을 호출합니다.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 텍스트 요약\n",
    "\n",
    "긴 텍스트에서 핵심 내용만 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 요약 결과 ===\n",
      "인공지능(AI)은 인간의 여러 인지 능력을 컴퓨터 프로그램으로 구현한 기술로, 최근 딥러닝 발전으로 다양한 분야에서 성능이 향상되었습니다. 특히, 대형 언어 모델(LLM)인 GPT와 Claude의 등장으로 AI는 글쓰기, 코딩, 분석 등 지식 노동 영역에서도 활용되고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 요약\n",
    "summarize_prompt = \"\"\"당신은 텍스트 요약 전문가입니다.\n",
    "주어진 텍스트를 3문장 이내로 핵심만 요약해주세요.\"\"\"\n",
    "\n",
    "long_text = \"\"\"\n",
    "인공지능(AI)은 인간의 학습능력, 추론능력, 지각능력, 자연언어 이해능력 등을 \n",
    "컴퓨터 프로그램으로 실현한 기술입니다. 최근 딥러닝의 발전으로 AI는 이미지 인식, \n",
    "자연어 처리, 게임, 자율주행 등 다양한 분야에서 인간을 능가하는 성능을 보여주고 있습니다.\n",
    "특히 GPT, Claude 등 대형 언어 모델(LLM)의 등장으로 AI는 글쓰기, 코딩, 분석 등 \n",
    "지식 노동 영역에서도 활용되고 있습니다.\n",
    "\"\"\"\n",
    "\n",
    "summary = ask_llm(summarize_prompt, long_text)\n",
    "print(\"=== 요약 결과 ===\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 번역\n",
    "\n",
    "한국어를 영어로 자연스럽게 번역합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 번역 결과 ===\n",
      "원문: 오늘 날씨가 정말 좋네요. 산책하기 딱 좋은 날이에요!\n",
      "번역: The weather is absolutely wonderful today. It's a perfect day for a walk!\n"
     ]
    }
   ],
   "source": [
    "# 번역\n",
    "translate_prompt = \"\"\"당신은 전문 번역가입니다.\n",
    "한국어를 영어로 자연스럽게 번역해주세요.\n",
    "직역보다는 의역을 선호하며, 원문의 뉘앙스를 살려주세요.\"\"\"\n",
    "\n",
    "korean_text = \"오늘 날씨가 정말 좋네요. 산책하기 딱 좋은 날이에요!\"\n",
    "\n",
    "translation = ask_llm(translate_prompt, korean_text)\n",
    "print(\"=== 번역 결과 ===\")\n",
    "print(f\"원문: {korean_text}\")\n",
    "print(f\"번역: {translation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Q&A (질문-답변)\n",
    "\n",
    "특정 분야의 전문가로 설정하여 질문에 답변합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Q&A 결과 ===\n",
      "Q: 파이썬에서 리스트와 튜플의 차이점이 뭔가요?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "리스트(List)와 튜플(Tuple)은 파이썬에서 데이터를 저장하는 두 가지 기본 자료구조입니다. 이 둘은 비슷한 점이 있지만 중요한 차이점도 있습니다. 아래에서 각각의 특징과 차이점을 설명하겠습니다.\n",
       "\n",
       "### 리스트 (List)\n",
       "\n",
       "1. **정의**: 리스트는 여러 개의 값을 담을 수 있는 가변(mutable) 자료형입니다.\n",
       "2. **생성 방법**: 리스트는 대괄호 `[]`로 생성합니다.\n",
       "3. **변경 가능성**: 리스트의 요소는 나중에 변경이 가능합니다. 즉, 리스트에 값을 추가, 삭제, 변경할 수 있습니다.\n",
       "4. **사용 예시**:\n",
       "   ```python\n",
       "   my_list = [1, 2, 3]\n",
       "   my_list[0] = 10  # 첫 번째 요소를 10으로 변경\n",
       "   my_list.append(4)  # 4 추가\n",
       "   print(my_list)  # 출력: [10, 2, 3, 4]\n",
       "   ```\n",
       "\n",
       "### 튜플 (Tuple)\n",
       "\n",
       "1. **정의**: 튜플은 여러 개의 값을 담을 수 있는 불변(immutable) 자료형입니다.\n",
       "2. **생성 방법**: 튜플은 소괄호 `()`로 생성합니다.\n",
       "3. **변경 불가성**: 튜플의 요소는 한 번 생성되면 변경할 수 없습니다. 즉, 튜플 내부의 값을 수정, 추가, 삭제할 수 없습니다.\n",
       "4. **사용 예시**:\n",
       "   ```python\n",
       "   my_tuple = (1, 2, 3)\n",
       "   # my_tuple[0] = 10  # 이 코드는 오류를 발생시킴\n",
       "   print(my_tuple)  # 출력: (1, 2, 3)\n",
       "   ```\n",
       "\n",
       "### 리스트와 튜플의 차이점 요약\n",
       "\n",
       "| 특성      | 리스트 (List)          | 튜플 (Tuple)         |\n",
       "|-----------|-------------------------|-----------------------|\n",
       "| 변경 가능성 | 가변 (mutable)          | 불변 (immutable)      |\n",
       "| 생성 방법   | `[]`                    | `()`                  |\n",
       "| 성능      | 일반적으로 느림        | 일반적으로 빠름       |\n",
       "| 사용 예시   | 데이터 변경이 필요한 경우 | 데이터가 변경되지 않아야 할 경우 |\n",
       "\n",
       "이러한 차이점 때문에 리스트는 주로 데이터의 추가 및 변경이 필요한 경우에 사용하고, 튜플은 변경되지 않아야 하는 고정된 데이터에 적합합니다. 각 상황에 맞게 리스트와 튜플을 활용하면 효과적으로 데이터를 관리할 수 있습니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Q&A\n",
    "qa_prompt = \"\"\"당신은 Python 프로그래밍 튜터입니다.\n",
    "초보자도 이해할 수 있도록 쉽고 명확하게 설명해주세요.\n",
    "필요하면 간단한 예시 코드도 포함해주세요.\"\"\"\n",
    "\n",
    "question = \"파이썬에서 리스트와 튜플의 차이점이 뭔가요?\"\n",
    "\n",
    "answer = ask_llm(qa_prompt, question)\n",
    "print(\"=== Q&A 결과 ===\")\n",
    "print(f\"Q: {question}\\n\")\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. 실습: 나만의 프롬프트 만들기\n",
    "\n",
    "아래 셀을 수정하여 다양한 system prompt를 실험해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습: 나만의 프롬프트\n",
    "my_system_prompt = \"\"\"당신은 _____입니다.\n",
    "_____ 방식으로 답변해주세요.\"\"\"\n",
    "\n",
    "my_question = \"여기에 질문을 입력하세요\"\n",
    "\n",
    "# 실행\n",
    "# result = ask_llm(my_system_prompt, my_question)\n",
    "# display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. 요약\n",
    "\n",
    "이번 노트북에서 학습한 내용:\n",
    "\n",
    "| 주제 | 핵심 내용 |\n",
    "|------|----------|\n",
    "| **LLM API** | HTTP 요청으로 AI 모델에 접근하는 인터페이스 |\n",
    "| **환경 설정** | .env 파일에 API 키 저장, python-dotenv로 로드 |\n",
    "| **메시지 구조** | system/user/assistant 역할로 대화 구성 |\n",
    "| **응답 객체** | choices[0].message.content로 텍스트, usage로 토큰 확인 |\n",
    "| **활용 예시** | 요약, 번역, Q&A 등 system prompt로 역할 지정 |\n",
    "\n",
    "### 다음 단계\n",
    "\n",
    "**Part 2 (중급)** 에서 다룰 내용:\n",
    "- API 파라미터 (temperature, max_tokens 등)\n",
    "- 스트리밍 응답\n",
    "- 에러 처리\n",
    "- 다중 LLM 비교 (OpenAI vs Claude vs Ollama)\n",
    "- 비용 계산"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
