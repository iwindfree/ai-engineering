{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG ì„±ëŠ¥ í‰ê°€ ì§€í‘œ ì™„ì „ ê°€ì´ë“œ\n",
    "\n",
    "## ê°œìš”\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì˜ ê²€ìƒ‰ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ì£¼ìš” ì§€í‘œë“¤ì„ **ì´ë¡ ê³¼ ì‹¤ìŠµ**ì„ í†µí•´ ì™„ë²½í•˜ê²Œ ë§ˆìŠ¤í„°í•©ë‹ˆë‹¤.\n",
    "\n",
    "| ì£¼ì œ | ë‚´ìš© |\n",
    "|------|------|\n",
    "| ê¸°ë³¸ ì§€í‘œ | MRR, nDCG, Precision@K, Recall@K |\n",
    "| ê³ ê¸‰ ì§€í‘œ | F1-Score@K, MAP, Hit Rate |\n",
    "| êµ¬í˜„ | Pythonìœ¼ë¡œ ì§ì ‘ êµ¬í˜„ |\n",
    "| ì‹œê°í™” | ì§€í‘œë³„ ì‹œê°í™” ë° ë¹„êµ |\n",
    "| ì‹¤ì „ | ì‹¤ì œ RAG ì‹œìŠ¤í…œ í‰ê°€ |\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "1. ê° í‰ê°€ ì§€í‘œì˜ ê°œë…ê³¼ ìˆ˜ì‹ ì´í•´í•˜ê¸°\n",
    "2. Pythonìœ¼ë¡œ í‰ê°€ ì§€í‘œ ì§ì ‘ êµ¬í˜„í•˜ê¸°\n",
    "3. ì‹œê°í™”ë¥¼ í†µí•œ ì§ê´€ì  ì´í•´\n",
    "4. ì‹¤ì œ RAG ì‹œìŠ¤í…œ í‰ê°€ì— ì ìš©í•˜ê¸°\n",
    "5. í‰ê°€ ë°ì´í„°ì…‹ êµ¬ì¶• ë°©ë²• ìµíˆê¸°\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install numpy pandas matplotlib plotly scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (matplotlib)\n",
    "plt.rcParams['font.family'] = 'AppleGothic' if plt.rcParams['font.family'] == 'sans-serif' else plt.rcParams['font.family']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. MRR (Mean Reciprocal Rank)\n",
    "\n",
    "### ğŸ“š ê°œë…\n",
    "\n",
    "**í•µì‹¬ ì•„ì´ë””ì–´**: \"ì •ë‹µì´ ëª‡ ë²ˆì§¸ì— ë‚˜ì™”ë‚˜?\"ë¥¼ ì ìˆ˜ë¡œ ë°”ê¾¼ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ“Š ì ìˆ˜ ê³„ì‚° ë°©ì‹\n",
    "\n",
    "| ì •ë‹µ ìœ„ì¹˜ | ì ìˆ˜ |\n",
    "|-----------|------|\n",
    "| 1ë“± | 1/1 = **1.0** |\n",
    "| 2ë“± | 1/2 = **0.5** |\n",
    "| 3ë“± | 1/3 = **0.33** |\n",
    "| 10ë“± | 1/10 = **0.1** |\n",
    "\n",
    "ì •ë‹µì´ ìœ„ì— ìˆì„ìˆ˜ë¡ ì ìˆ˜ê°€ ë†’ìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ”¢ ê³µì‹\n",
    "\n",
    "$$MRR = \\frac{1}{Q} \\times \\sum_{i=1}^{Q} \\frac{1}{rank_i}$$\n",
    "\n",
    "- Q: ì „ì²´ ì¿¼ë¦¬ ìˆ˜\n",
    "- rank_i: ië²ˆì§¸ ì¿¼ë¦¬ì—ì„œ ì²« ë²ˆì§¸ ì •ë‹µì˜ ìˆœìœ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mrr(rankings: List[int]) -> float:\n",
    "    \"\"\"\n",
    "    MRR (Mean Reciprocal Rank) ê³„ì‚°\n",
    "    \n",
    "    Args:\n",
    "        rankings: ê° ì¿¼ë¦¬ì—ì„œ ì²« ë²ˆì§¸ ì •ë‹µì˜ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸\n",
    "                 (ì •ë‹µì´ ì—†ìœ¼ë©´ 0 ë˜ëŠ” í° ìˆ˜)\n",
    "    \n",
    "    Returns:\n",
    "        MRR ì ìˆ˜\n",
    "    \"\"\"\n",
    "    reciprocal_ranks = []\n",
    "    \n",
    "    for rank in rankings:\n",
    "        if rank > 0:  # ì •ë‹µì´ ìˆëŠ” ê²½ìš°\n",
    "            reciprocal_ranks.append(1.0 / rank)\n",
    "        else:  # ì •ë‹µì´ ì—†ëŠ” ê²½ìš°\n",
    "            reciprocal_ranks.append(0.0)\n",
    "    \n",
    "    return np.mean(reciprocal_ranks)\n",
    "\n",
    "# ì˜ˆì œ: RAG ì‹œìŠ¤í…œì— 3ë²ˆ ì§ˆë¬¸í–ˆì„ ë•Œ\n",
    "example_rankings = [\n",
    "    1,  # \"ê¹€ì¹˜ ë§Œë“œëŠ” ë²•\" - ì •ë‹µì´ 1ë“±\n",
    "    3,  # \"ì„œìš¸ ë‚ ì”¨\" - ì •ë‹µì´ 3ë“±\n",
    "    2,  # \"íŒŒì´ì¬ ì„¤ì¹˜\" - ì •ë‹µì´ 2ë“±\n",
    "]\n",
    "\n",
    "mrr_score = calculate_mrr(example_rankings)\n",
    "print(f\"ì˜ˆì œ ì¿¼ë¦¬ë“¤ì˜ ìˆœìœ„: {example_rankings}\")\n",
    "print(f\"ê° ì¿¼ë¦¬ì˜ ì ìˆ˜: {[1/r for r in example_rankings]}\")\n",
    "print(f\"MRR = {mrr_score:.3f}\")\n",
    "print(f\"\\ní•´ì„: {mrr_score:.3f}ëŠ” {'ì¢‹ì€' if mrr_score > 0.5 else 'ê°œì„ ì´ í•„ìš”í•œ'} ì„±ëŠ¥ì…ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRR ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MRR ì ìˆ˜ ê³¡ì„  ì‹œê°í™”\n",
    "ranks = np.arange(1, 21)\n",
    "scores = 1.0 / ranks\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=ranks, y=scores,\n",
    "    mode='lines+markers',\n",
    "    name='MRR ì ìˆ˜',\n",
    "    marker=dict(size=8),\n",
    "    line=dict(width=2)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='MRR ì ìˆ˜ ê³¡ì„ : ìˆœìœ„ë³„ ì ìˆ˜ ë³€í™”',\n",
    "    xaxis_title='ì •ë‹µ ìˆœìœ„',\n",
    "    yaxis_title='MRR ì ìˆ˜',\n",
    "    hovermode='x unified',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# ì£¼ìš” ìˆœìœ„ í‘œì‹œ\n",
    "for i in [1, 2, 3, 5, 10]:\n",
    "    fig.add_annotation(\n",
    "        x=i, y=1/i,\n",
    "        text=f\"{1/i:.2f}\",\n",
    "        showarrow=False,\n",
    "        yshift=10\n",
    "    )\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"ğŸ’¡ ì¸ì‚¬ì´íŠ¸:\")\n",
    "print(\"- 1ë“±ê³¼ 2ë“±ì˜ ì°¨ì´(0.5)ê°€ 2ë“±ê³¼ 3ë“±ì˜ ì°¨ì´(0.17)ë³´ë‹¤ í›¨ì”¬ í½ë‹ˆë‹¤.\")\n",
    "print(\"- ìƒìœ„ ë­í‚¹ì´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. nDCG (Normalized Discounted Cumulative Gain)\n",
    "\n",
    "### ğŸ“š ê°œë…\n",
    "\n",
    "**í•µì‹¬ ì•„ì´ë””ì–´**: \"ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ê°€ ìœ„ì— ìˆì„ìˆ˜ë¡ ì¢‹ë‹¤\"ë¥¼ ì ìˆ˜ë¡œ ë°”ê¾¼ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ†š MRRê³¼ì˜ ì°¨ì´ì \n",
    "\n",
    "| | MRR | nDCG |\n",
    "|---|-----|------|\n",
    "| ì •ë‹µ ê°œìˆ˜ | 1ê°œë§Œ ë´„ | **ì—¬ëŸ¬ ê°œ** ë´„ |\n",
    "| ê´€ë ¨ì„± | ì •ë‹µ/ì˜¤ë‹µ (0 or 1) | **ë“±ê¸‰** (0, 1, 2, 3...) |\n",
    "\n",
    "### ğŸ”¢ ê³„ì‚° ê³¼ì • (3ë‹¨ê³„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dcg(relevances: List[float], k: int = None) -> float:\n",
    "    \"\"\"\n",
    "    DCG (Discounted Cumulative Gain) ê³„ì‚°\n",
    "    \n",
    "    Args:\n",
    "        relevances: ê° ë¬¸ì„œì˜ ê´€ë ¨ì„± ì ìˆ˜ ë¦¬ìŠ¤íŠ¸\n",
    "        k: ìƒìœ„ kê°œë§Œ ê³ ë ¤ (Noneì´ë©´ ì „ì²´)\n",
    "    \n",
    "    Returns:\n",
    "        DCG ì ìˆ˜\n",
    "    \"\"\"\n",
    "    if k is None:\n",
    "        k = len(relevances)\n",
    "    \n",
    "    dcg = 0.0\n",
    "    for i in range(min(k, len(relevances))):\n",
    "        # ìœ„ì¹˜ i+1ì˜ í• ì¸ìœ¨ ì ìš© (iëŠ” 0ë¶€í„° ì‹œì‘)\n",
    "        dcg += relevances[i] / np.log2(i + 2)  # i+2ëŠ” positionì´ 1ë¶€í„° ì‹œì‘í•˜ê¸° ë•Œë¬¸\n",
    "    \n",
    "    return dcg\n",
    "\n",
    "def calculate_ndcg(relevances: List[float], k: int = None) -> float:\n",
    "    \"\"\"\n",
    "    nDCG (Normalized DCG) ê³„ì‚°\n",
    "    \n",
    "    Args:\n",
    "        relevances: ê° ë¬¸ì„œì˜ ê´€ë ¨ì„± ì ìˆ˜ ë¦¬ìŠ¤íŠ¸\n",
    "        k: ìƒìœ„ kê°œë§Œ ê³ ë ¤\n",
    "    \n",
    "    Returns:\n",
    "        nDCG ì ìˆ˜ (0~1)\n",
    "    \"\"\"\n",
    "    # ì‹¤ì œ DCG ê³„ì‚°\n",
    "    dcg = calculate_dcg(relevances, k)\n",
    "    \n",
    "    # ì´ìƒì ì¸ ìˆœì„œë¡œ ì •ë ¬í•˜ì—¬ IDCG ê³„ì‚°\n",
    "    ideal_relevances = sorted(relevances, reverse=True)\n",
    "    idcg = calculate_dcg(ideal_relevances, k)\n",
    "    \n",
    "    # IDCGê°€ 0ì´ë©´ nDCGë„ 0\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dcg / idcg\n",
    "\n",
    "# ì˜ˆì œ: ê²€ìƒ‰ ê²°ê³¼ 5ê°œì˜ ê´€ë ¨ì„± ì ìˆ˜\n",
    "relevances = [3, 1, 2, 0, 1]  # ì‹¤ì œ ìˆœì„œ\n",
    "ideal_order = sorted(relevances, reverse=True)  # [3, 2, 1, 1, 0]\n",
    "\n",
    "dcg = calculate_dcg(relevances)\n",
    "idcg = calculate_dcg(ideal_order)\n",
    "ndcg = calculate_ndcg(relevances)\n",
    "\n",
    "print(\"ğŸ“Š nDCG ê³„ì‚° ê³¼ì •:\")\n",
    "print(f\"\\n1. ì‹¤ì œ ê´€ë ¨ì„± ìˆœì„œ: {relevances}\")\n",
    "print(f\"2. ì´ìƒì ì¸ ìˆœì„œ: {ideal_order}\")\n",
    "print(f\"\\n3. DCG = {dcg:.3f}\")\n",
    "print(f\"4. IDCG = {idcg:.3f}\")\n",
    "print(f\"5. nDCG = DCG/IDCG = {ndcg:.3f}\")\n",
    "print(f\"\\ní•´ì„: {ndcg:.3f}ëŠ” {'ì¢‹ì€' if ndcg > 0.8 else 'ê°œì„ ì´ í•„ìš”í•œ'} ìˆœì„œì…ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nDCG ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ì˜ nDCG ë¹„êµ\n",
    "scenarios = {\n",
    "    'ì™„ë²½í•œ ìˆœì„œ': [3, 2, 1, 1, 0],\n",
    "    'ì¢‹ì€ ìˆœì„œ': [3, 1, 2, 0, 1],\n",
    "    'ë‚˜ìœ ìˆœì„œ': [0, 1, 1, 2, 3],\n",
    "    'ëœë¤ ìˆœì„œ': [1, 0, 3, 1, 2]\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, rels in scenarios.items():\n",
    "    ndcg = calculate_ndcg(rels)\n",
    "    results.append({'ì‹œë‚˜ë¦¬ì˜¤': name, 'nDCG': ndcg, 'ê´€ë ¨ì„± ìˆœì„œ': str(rels)})\n",
    "\n",
    "df_ndcg = pd.DataFrame(results)\n",
    "\n",
    "# ë§‰ëŒ€ ê·¸ë˜í”„\n",
    "fig = px.bar(df_ndcg, x='ì‹œë‚˜ë¦¬ì˜¤', y='nDCG', \n",
    "             hover_data=['ê´€ë ¨ì„± ìˆœì„œ'],\n",
    "             title='ì‹œë‚˜ë¦¬ì˜¤ë³„ nDCG ì ìˆ˜ ë¹„êµ',\n",
    "             color='nDCG',\n",
    "             color_continuous_scale='RdYlGn')\n",
    "\n",
    "fig.update_layout(yaxis_range=[0, 1.1])\n",
    "fig.add_hline(y=0.8, line_dash=\"dash\", line_color=\"green\", \n",
    "              annotation_text=\"ì¢‹ì€ ì„±ëŠ¥ (0.8)\")\n",
    "fig.add_hline(y=0.5, line_dash=\"dash\", line_color=\"orange\", \n",
    "              annotation_text=\"ê°œì„  í•„ìš” (0.5)\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nğŸ“Š ê²°ê³¼ í…Œì´ë¸”:\")\n",
    "print(df_ndcg.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Precision@Kì™€ Recall@K\n",
    "\n",
    "### ğŸ“š ê°œë…\n",
    "\n",
    "- **Precision@K**: \"ê°€ì ¸ì˜¨ Kê°œ ì¤‘ì— ì •ë‹µì´ ëª‡ ê°œ?\"\n",
    "- **Recall@K**: \"ì „ì²´ ì •ë‹µ ì¤‘ì— Kê°œ ì•ˆì— ëª‡ ê°œ ë“¤ì–´ì™”ë‚˜?\"\n",
    "\n",
    "### ğŸ”¢ ê³µì‹\n",
    "\n",
    "$$Precision@K = \\frac{\\text{ìƒìœ„ Kê°œ ì¤‘ ì •ë‹µ ìˆ˜}}{K}$$\n",
    "\n",
    "$$Recall@K = \\frac{\\text{ìƒìœ„ Kê°œ ì¤‘ ì •ë‹µ ìˆ˜}}{\\text{ì „ì²´ ì •ë‹µ ìˆ˜}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_at_k(retrieved: List[int], relevant: List[int], k: int) -> float:\n",
    "    \"\"\"\n",
    "    Precision@K ê³„ì‚°\n",
    "    \n",
    "    Args:\n",
    "        retrieved: ê²€ìƒ‰ëœ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸ (ìˆœì„œëŒ€ë¡œ)\n",
    "        relevant: ê´€ë ¨ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸\n",
    "        k: ìƒìœ„ kê°œ ê³ ë ¤\n",
    "    \n",
    "    Returns:\n",
    "        Precision@K ì ìˆ˜\n",
    "    \"\"\"\n",
    "    retrieved_k = retrieved[:k]\n",
    "    relevant_set = set(relevant)\n",
    "    \n",
    "    # ìƒìœ„ kê°œ ì¤‘ ê´€ë ¨ ë¬¸ì„œ ê°œìˆ˜\n",
    "    relevant_in_k = sum(1 for doc in retrieved_k if doc in relevant_set)\n",
    "    \n",
    "    return relevant_in_k / k if k > 0 else 0\n",
    "\n",
    "def calculate_recall_at_k(retrieved: List[int], relevant: List[int], k: int) -> float:\n",
    "    \"\"\"\n",
    "    Recall@K ê³„ì‚°\n",
    "    \n",
    "    Args:\n",
    "        retrieved: ê²€ìƒ‰ëœ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸ (ìˆœì„œëŒ€ë¡œ)\n",
    "        relevant: ê´€ë ¨ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸\n",
    "        k: ìƒìœ„ kê°œ ê³ ë ¤\n",
    "    \n",
    "    Returns:\n",
    "        Recall@K ì ìˆ˜\n",
    "    \"\"\"\n",
    "    retrieved_k = retrieved[:k]\n",
    "    relevant_set = set(relevant)\n",
    "    \n",
    "    # ìƒìœ„ kê°œ ì¤‘ ê´€ë ¨ ë¬¸ì„œ ê°œìˆ˜\n",
    "    relevant_in_k = sum(1 for doc in retrieved_k if doc in relevant_set)\n",
    "    \n",
    "    return relevant_in_k / len(relevant_set) if len(relevant_set) > 0 else 0\n",
    "\n",
    "# ì˜ˆì œ: RAG ê²€ìƒ‰ ê²°ê³¼\n",
    "retrieved_docs = [1, 3, 5, 7, 9, 2, 4, 6, 8, 10]  # ê²€ìƒ‰ëœ ë¬¸ì„œ ID (ìˆœì„œëŒ€ë¡œ)\n",
    "relevant_docs = [1, 2, 5, 8, 11, 13, 15, 17]  # ì‹¤ì œ ê´€ë ¨ ë¬¸ì„œ ID\n",
    "\n",
    "# K=5ì¼ ë•Œ ê³„ì‚°\n",
    "k = 5\n",
    "precision_5 = calculate_precision_at_k(retrieved_docs, relevant_docs, k)\n",
    "recall_5 = calculate_recall_at_k(retrieved_docs, relevant_docs, k)\n",
    "\n",
    "print(f\"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ (K={k}):\")\n",
    "print(f\"\\nê²€ìƒ‰ëœ ìƒìœ„ {k}ê°œ: {retrieved_docs[:k]}\")\n",
    "print(f\"ì „ì²´ ê´€ë ¨ ë¬¸ì„œ: {relevant_docs}\")\n",
    "print(f\"ìƒìœ„ {k}ê°œ ì¤‘ ì •ë‹µ: {[doc for doc in retrieved_docs[:k] if doc in relevant_docs]}\")\n",
    "print(f\"\\nPrecision@{k} = {precision_5:.2f} ({precision_5*100:.0f}%)\")\n",
    "print(f\"  â†’ ê°€ì ¸ì˜¨ {k}ê°œ ì¤‘ {precision_5*k:.0f}ê°œê°€ ì •ë‹µ\")\n",
    "print(f\"\\nRecall@{k} = {recall_5:.2f} ({recall_5*100:.0f}%)\")\n",
    "print(f\"  â†’ ì „ì²´ ì •ë‹µ {len(relevant_docs)}ê°œ ì¤‘ {recall_5*len(relevant_docs):.0f}ê°œë¥¼ ì°¾ìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall íŠ¸ë ˆì´ë“œì˜¤í”„ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kê°’ ë³€í™”ì— ë”°ë¥¸ Precisionê³¼ Recall ë³€í™”\n",
    "k_values = range(1, 11)\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for k in k_values:\n",
    "    p = calculate_precision_at_k(retrieved_docs, relevant_docs, k)\n",
    "    r = calculate_recall_at_k(retrieved_docs, relevant_docs, k)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒì„±\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(k_values), y=precisions,\n",
    "    mode='lines+markers',\n",
    "    name='Precision@K',\n",
    "    marker=dict(size=8)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(k_values), y=recalls,\n",
    "    mode='lines+markers',\n",
    "    name='Recall@K',\n",
    "    marker=dict(size=8)\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Precision@K vs Recall@K: íŠ¸ë ˆì´ë“œì˜¤í”„',\n",
    "    xaxis_title='K (ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜)',\n",
    "    yaxis_title='ì ìˆ˜',\n",
    "    hovermode='x unified',\n",
    "    yaxis_range=[0, 1]\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"ğŸ’¡ ì¸ì‚¬ì´íŠ¸:\")\n",
    "print(\"- Kê°€ ì¦ê°€í•˜ë©´ Recallì€ ì˜¬ë¼ê°€ì§€ë§Œ Precisionì€ ë–¨ì–´ì§‘ë‹ˆë‹¤.\")\n",
    "print(\"- ì ì ˆí•œ Kê°’ ì„ íƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. F1-Score@K\n",
    "\n",
    "### ğŸ“š ê°œë…\n",
    "\n",
    "Precisionê³¼ Recallì˜ ì¡°í™”í‰ê· ìœ¼ë¡œ, ë‘ ì§€í‘œì˜ ê· í˜•ì„ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ”¢ ê³µì‹\n",
    "\n",
    "$$F1@K = 2 \\times \\frac{Precision@K \\times Recall@K}{Precision@K + Recall@K}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_at_k(retrieved: List[int], relevant: List[int], k: int) -> float:\n",
    "    \"\"\"\n",
    "    F1-Score@K ê³„ì‚°\n",
    "    \n",
    "    Args:\n",
    "        retrieved: ê²€ìƒ‰ëœ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸\n",
    "        relevant: ê´€ë ¨ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸\n",
    "        k: ìƒìœ„ kê°œ ê³ ë ¤\n",
    "    \n",
    "    Returns:\n",
    "        F1@K ì ìˆ˜\n",
    "    \"\"\"\n",
    "    precision = calculate_precision_at_k(retrieved, relevant, k)\n",
    "    recall = calculate_recall_at_k(retrieved, relevant, k)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    \n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Kê°’ë³„ F1-Score ê³„ì‚°\n",
    "f1_scores = []\n",
    "for k in k_values:\n",
    "    f1 = calculate_f1_at_k(retrieved_docs, relevant_docs, k)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# ëª¨ë“  ì§€í‘œ í•¨ê»˜ ì‹œê°í™”\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(k_values), y=precisions, mode='lines+markers', name='Precision@K'))\n",
    "fig.add_trace(go.Scatter(x=list(k_values), y=recalls, mode='lines+markers', name='Recall@K'))\n",
    "fig.add_trace(go.Scatter(x=list(k_values), y=f1_scores, mode='lines+markers', name='F1-Score@K',\n",
    "                        line=dict(width=3)))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ê²€ìƒ‰ ì„±ëŠ¥ ì§€í‘œ ì¢…í•© ë¹„êµ',\n",
    "    xaxis_title='K (ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜)',\n",
    "    yaxis_title='ì ìˆ˜',\n",
    "    hovermode='x unified',\n",
    "    yaxis_range=[0, 1]\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# ìµœì  K ì°¾ê¸°\n",
    "best_k = k_values[np.argmax(f1_scores)]\n",
    "best_f1 = max(f1_scores)\n",
    "\n",
    "print(f\"\\nğŸ¯ ìµœì  Kê°’: {best_k} (F1-Score: {best_f1:.3f})\")\n",
    "print(f\"   - Precision@{best_k}: {precisions[best_k-1]:.3f}\")\n",
    "print(f\"   - Recall@{best_k}: {recalls[best_k-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. MAP (Mean Average Precision)\n",
    "\n",
    "### ğŸ“š ê°œë…\n",
    "\n",
    "Average Precisionì˜ í‰ê· ìœ¼ë¡œ, ìˆœì„œë¥¼ ê³ ë ¤í•œ Precisionì˜ ì¢…í•© ì§€í‘œì…ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ”¢ ê³µì‹\n",
    "\n",
    "$$AP = \\frac{1}{|R|} \\sum_{k=1}^{n} P(k) \\times rel(k)$$\n",
    "\n",
    "- P(k): kë²ˆì§¸ê¹Œì§€ì˜ Precision\n",
    "- rel(k): kë²ˆì§¸ ë¬¸ì„œê°€ ê´€ë ¨ìˆìœ¼ë©´ 1, ì•„ë‹ˆë©´ 0\n",
    "- |R|: ì „ì²´ ê´€ë ¨ ë¬¸ì„œ ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_precision(retrieved: List[int], relevant: List[int]) -> float:\n",
    "    \"\"\"\n",
    "    Average Precision ê³„ì‚°\n",
    "    \n",
    "    Args:\n",
    "        retrieved: ê²€ìƒ‰ëœ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸\n",
    "        relevant: ê´€ë ¨ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        Average Precision ì ìˆ˜\n",
    "    \"\"\"\n",
    "    relevant_set = set(relevant)\n",
    "    if not relevant_set:\n",
    "        return 0.0\n",
    "    \n",
    "    ap_sum = 0.0\n",
    "    relevant_found = 0\n",
    "    \n",
    "    for i, doc_id in enumerate(retrieved, 1):\n",
    "        if doc_id in relevant_set:\n",
    "            relevant_found += 1\n",
    "            precision_at_i = relevant_found / i\n",
    "            ap_sum += precision_at_i\n",
    "    \n",
    "    return ap_sum / len(relevant_set)\n",
    "\n",
    "def calculate_map(queries_results: List[Tuple[List[int], List[int]]]) -> float:\n",
    "    \"\"\"\n",
    "    MAP (Mean Average Precision) ê³„ì‚°\n",
    "    \n",
    "    Args:\n",
    "        queries_results: [(retrieved, relevant)] íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        MAP ì ìˆ˜\n",
    "    \"\"\"\n",
    "    aps = []\n",
    "    for retrieved, relevant in queries_results:\n",
    "        ap = calculate_average_precision(retrieved, relevant)\n",
    "        aps.append(ap)\n",
    "    \n",
    "    return np.mean(aps)\n",
    "\n",
    "# ì˜ˆì œ: 3ê°œ ì¿¼ë¦¬ì˜ ê²°ê³¼\n",
    "queries = [\n",
    "    # (ê²€ìƒ‰ ê²°ê³¼, ì •ë‹µ ë¬¸ì„œ)\n",
    "    ([1, 3, 5, 2, 4], [1, 2, 5]),        # ì¿¼ë¦¬ 1\n",
    "    ([10, 11, 12, 13, 14], [11, 13, 15]), # ì¿¼ë¦¬ 2\n",
    "    ([20, 21, 22, 23, 24], [20, 21, 22])  # ì¿¼ë¦¬ 3\n",
    "]\n",
    "\n",
    "# ê° ì¿¼ë¦¬ì˜ AP ê³„ì‚°\n",
    "print(\"ğŸ“Š ê° ì¿¼ë¦¬ì˜ Average Precision:\\n\")\n",
    "aps = []\n",
    "for i, (retrieved, relevant) in enumerate(queries, 1):\n",
    "    ap = calculate_average_precision(retrieved, relevant)\n",
    "    aps.append(ap)\n",
    "    print(f\"ì¿¼ë¦¬ {i}:\")\n",
    "    print(f\"  ê²€ìƒ‰ ê²°ê³¼: {retrieved}\")\n",
    "    print(f\"  ì •ë‹µ ë¬¸ì„œ: {relevant}\")\n",
    "    print(f\"  AP = {ap:.3f}\\n\")\n",
    "\n",
    "# MAP ê³„ì‚°\n",
    "map_score = calculate_map(queries)\n",
    "print(f\"\\nğŸ¯ MAP (Mean Average Precision) = {map_score:.3f}\")\n",
    "print(f\"\\ní•´ì„: MAP {map_score:.3f}ëŠ” {'ìš°ìˆ˜í•œ' if map_score > 0.7 else 'ê°œì„ ì´ í•„ìš”í•œ'} ì„±ëŠ¥ì…ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Hit Rate (Success Rate)\n",
    "\n",
    "### ğŸ“š ê°œë…\n",
    "\n",
    "ìƒìœ„ Kê°œ ì¤‘ì— ìµœì†Œ 1ê°œ ì´ìƒì˜ ì •ë‹µì´ ìˆëŠ” ì¿¼ë¦¬ì˜ ë¹„ìœ¨ì…ë‹ˆë‹¤.\n",
    "ê°€ì¥ ë‹¨ìˆœí•˜ì§€ë§Œ ì§ê´€ì ì¸ ì§€í‘œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hit_rate(queries_results: List[Tuple[List[int], List[int]]], k: int) -> float:\n",
    "    \"\"\"\n",
    "    Hit Rate@K ê³„ì‚°\n",
    "    \n",
    "    Args:\n",
    "        queries_results: [(retrieved, relevant)] íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸\n",
    "        k: ìƒìœ„ kê°œ ê³ ë ¤\n",
    "    \n",
    "    Returns:\n",
    "        Hit Rate ì ìˆ˜\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    \n",
    "    for retrieved, relevant in queries_results:\n",
    "        retrieved_k = set(retrieved[:k])\n",
    "        relevant_set = set(relevant)\n",
    "        \n",
    "        if retrieved_k & relevant_set:  # êµì§‘í•©ì´ ìˆìœ¼ë©´ hit\n",
    "            hits += 1\n",
    "    \n",
    "    return hits / len(queries_results)\n",
    "\n",
    "# Hit Rate ê³„ì‚°\n",
    "k_values = [1, 3, 5, 10]\n",
    "hit_rates = []\n",
    "\n",
    "print(\"ğŸ“Š Hit Rate@K ë¶„ì„:\\n\")\n",
    "for k in k_values:\n",
    "    hit_rate = calculate_hit_rate(queries, k)\n",
    "    hit_rates.append(hit_rate)\n",
    "    print(f\"Hit Rate@{k}: {hit_rate:.2f} ({hit_rate*100:.0f}%)\")\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig = go.Figure(data=[go.Bar(x=[f\"@{k}\" for k in k_values], y=hit_rates)])\n",
    "fig.update_layout(\n",
    "    title='Hit Rate@K: Kê°’ì— ë”°ë¥¸ ì„±ê³µë¥ ',\n",
    "    xaxis_title='K',\n",
    "    yaxis_title='Hit Rate',\n",
    "    yaxis_range=[0, 1.1]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. ì‹¤ì œ RAG ì‹œìŠ¤í…œ í‰ê°€ ì˜ˆì œ\n",
    "\n",
    "ì‹¤ì œ RAG ì‹œìŠ¤í…œì„ í‰ê°€í•˜ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGEvaluator:\n",
    "    \"\"\"\n",
    "    RAG ì‹œìŠ¤í…œ í‰ê°€ í´ë˜ìŠ¤\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name: str = \"RAG System\"):\n",
    "        self.name = name\n",
    "        self.results = []\n",
    "    \n",
    "    def add_query_result(self, query: str, retrieved: List[int], relevant: List[int]):\n",
    "        \"\"\"\n",
    "        ì¿¼ë¦¬ ê²°ê³¼ ì¶”ê°€\n",
    "        \"\"\"\n",
    "        self.results.append({\n",
    "            'query': query,\n",
    "            'retrieved': retrieved,\n",
    "            'relevant': relevant\n",
    "        })\n",
    "    \n",
    "    def evaluate(self, k: int = 5) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        ëª¨ë“  ì§€í‘œ ê³„ì‚°\n",
    "        \"\"\"\n",
    "        if not self.results:\n",
    "            return {}\n",
    "        \n",
    "        metrics = {\n",
    "            'MRR': [],\n",
    "            'nDCG': [],\n",
    "            'Precision': [],\n",
    "            'Recall': [],\n",
    "            'F1': [],\n",
    "            'AP': []\n",
    "        }\n",
    "        \n",
    "        for result in self.results:\n",
    "            retrieved = result['retrieved']\n",
    "            relevant = result['relevant']\n",
    "            \n",
    "            # MRR ê³„ì‚°\n",
    "            first_relevant = None\n",
    "            for i, doc in enumerate(retrieved, 1):\n",
    "                if doc in relevant:\n",
    "                    first_relevant = i\n",
    "                    break\n",
    "            mrr = 1/first_relevant if first_relevant else 0\n",
    "            metrics['MRR'].append(mrr)\n",
    "            \n",
    "            # ë‹¤ë¥¸ ì§€í‘œë“¤\n",
    "            metrics['Precision'].append(calculate_precision_at_k(retrieved, relevant, k))\n",
    "            metrics['Recall'].append(calculate_recall_at_k(retrieved, relevant, k))\n",
    "            metrics['F1'].append(calculate_f1_at_k(retrieved, relevant, k))\n",
    "            metrics['AP'].append(calculate_average_precision(retrieved, relevant))\n",
    "            \n",
    "            # nDCG (ê°„ë‹¨íˆ binary relevanceë¡œ)\n",
    "            relevances = [1 if doc in relevant else 0 for doc in retrieved[:k]]\n",
    "            metrics['nDCG'].append(calculate_ndcg(relevances, k))\n",
    "        \n",
    "        # í‰ê·  ê³„ì‚°\n",
    "        avg_metrics = {}\n",
    "        for metric_name, values in metrics.items():\n",
    "            avg_metrics[metric_name] = np.mean(values)\n",
    "        \n",
    "        # Hit Rate\n",
    "        queries_data = [(r['retrieved'], r['relevant']) for r in self.results]\n",
    "        avg_metrics['Hit_Rate'] = calculate_hit_rate(queries_data, k)\n",
    "        \n",
    "        return avg_metrics\n",
    "    \n",
    "    def print_report(self, k: int = 5):\n",
    "        \"\"\"\n",
    "        í‰ê°€ ë¦¬í¬íŠ¸ ì¶œë ¥\n",
    "        \"\"\"\n",
    "        metrics = self.evaluate(k)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ğŸ“Š {self.name} í‰ê°€ ë¦¬í¬íŠ¸ (K={k})\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        for metric, value in metrics.items():\n",
    "            bar = 'â–ˆ' * int(value * 20)\n",
    "            print(f\"{metric:12} : {value:.3f}  {bar}\")\n",
    "        \n",
    "        print(f\"\\nì´ {len(self.results)}ê°œ ì¿¼ë¦¬ í‰ê°€ ì™„ë£Œ\")\n",
    "\n",
    "# ì‹¤ì œ RAG ì‹œìŠ¤í…œ ì‹œë®¬ë ˆì´ì…˜\n",
    "evaluator = RAGEvaluator(\"My RAG System\")\n",
    "\n",
    "# ìƒ˜í”Œ ì¿¼ë¦¬ ê²°ê³¼ë“¤ (ì‹¤ì œë¡œëŠ” RAG ì‹œìŠ¤í…œì—ì„œ ê°€ì ¸ì˜´)\n",
    "sample_queries = [\n",
    "    {\n",
    "        'query': \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ ì •ë ¬í•˜ëŠ” ë°©ë²•?\",\n",
    "        'retrieved': [1, 5, 3, 7, 9, 2, 4, 6, 8, 10],\n",
    "        'relevant': [1, 3, 5, 8]\n",
    "    },\n",
    "    {\n",
    "        'query': \"ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í‰ê°€ ì§€í‘œëŠ”?\",\n",
    "        'retrieved': [12, 14, 11, 15, 13, 16, 17, 18, 19, 20],\n",
    "        'relevant': [11, 12, 15, 17, 21]\n",
    "    },\n",
    "    {\n",
    "        'query': \"ë”¥ëŸ¬ë‹ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì¢…ë¥˜?\",\n",
    "        'retrieved': [22, 25, 23, 24, 21, 26, 27, 28, 29, 30],\n",
    "        'relevant': [22, 23, 25, 26, 31, 32]\n",
    "    }\n",
    "]\n",
    "\n",
    "# ê²°ê³¼ ì¶”ê°€\n",
    "for q in sample_queries:\n",
    "    evaluator.add_query_result(q['query'], q['retrieved'], q['relevant'])\n",
    "\n",
    "# í‰ê°€ ë¦¬í¬íŠ¸ ì¶œë ¥\n",
    "evaluator.print_report(k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. í‰ê°€ ì§€í‘œ ì¢…í•© ë¹„êµ\n",
    "\n",
    "ëª¨ë“  ì§€í‘œë¥¼ í•œëˆˆì— ë¹„êµí•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‘ ê°€ì§€ RAG ì‹œìŠ¤í…œ ë¹„êµ\n",
    "system_a = RAGEvaluator(\"System A (Baseline)\")\n",
    "system_b = RAGEvaluator(\"System B (Improved)\")\n",
    "\n",
    "# System A ê²°ê³¼ (ê¸°ë³¸ ì‹œìŠ¤í…œ)\n",
    "for q in sample_queries:\n",
    "    # ëœë¤í•˜ê²Œ ì„ì¸ ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜\n",
    "    retrieved = list(range(1, 31))\n",
    "    np.random.shuffle(retrieved)\n",
    "    system_a.add_query_result(q['query'], retrieved[:10], q['relevant'])\n",
    "\n",
    "# System B ê²°ê³¼ (ê°œì„ ëœ ì‹œìŠ¤í…œ)\n",
    "for q in sample_queries:\n",
    "    # ê´€ë ¨ ë¬¸ì„œë¥¼ ë” ì•ìª½ì— ë°°ì¹˜\n",
    "    relevant_docs = q['relevant']\n",
    "    other_docs = [i for i in range(1, 31) if i not in relevant_docs]\n",
    "    retrieved = relevant_docs[:3] + other_docs[:7]\n",
    "    np.random.shuffle(retrieved[:5])  # ìƒìœ„ 5ê°œë§Œ ì•½ê°„ ì„ê¸°\n",
    "    system_b.add_query_result(q['query'], retrieved, q['relevant'])\n",
    "\n",
    "# ë¹„êµ ê·¸ë˜í”„\n",
    "metrics_a = system_a.evaluate(k=5)\n",
    "metrics_b = system_b.evaluate(k=5)\n",
    "\n",
    "metric_names = list(metrics_a.keys())\n",
    "values_a = list(metrics_a.values())\n",
    "values_b = list(metrics_b.values())\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(name='System A (Baseline)', x=metric_names, y=values_a))\n",
    "fig.add_trace(go.Bar(name='System B (Improved)', x=metric_names, y=values_b))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¹„êµ',\n",
    "    yaxis_title='ì ìˆ˜',\n",
    "    barmode='group',\n",
    "    yaxis_range=[0, 1]\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# ê°œì„ ìœ¨ ê³„ì‚°\n",
    "print(\"\\nğŸ“ˆ ê°œì„ ìœ¨ ë¶„ì„:\")\n",
    "for metric in metric_names:\n",
    "    improvement = (metrics_b[metric] - metrics_a[metric]) / metrics_a[metric] * 100 if metrics_a[metric] > 0 else 0\n",
    "    arrow = \"â†‘\" if improvement > 0 else \"â†“\" if improvement < 0 else \"=\"\n",
    "    print(f\"{metric:12}: {improvement:+.1f}% {arrow}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. í‰ê°€ ë°ì´í„°ì…‹ êµ¬ì¶• ë°©ë²•\n",
    "\n",
    "ì‹¤ì œ RAG ì‹œìŠ¤í…œì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë°ì´í„°ì…‹ êµ¬ì¶• ë°©ë²•ì„ ì•Œì•„ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGTestDataset:\n",
    "    \"\"\"\n",
    "    RAG í‰ê°€ìš© ë°ì´í„°ì…‹ í´ë˜ìŠ¤\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.queries = []\n",
    "        self.documents = {}\n",
    "        self.relevance_judgments = {}\n",
    "    \n",
    "    def add_document(self, doc_id: int, content: str, metadata: dict = None):\n",
    "        \"\"\"\n",
    "        ë¬¸ì„œ ì¶”ê°€\n",
    "        \"\"\"\n",
    "        self.documents[doc_id] = {\n",
    "            'content': content,\n",
    "            'metadata': metadata or {}\n",
    "        }\n",
    "    \n",
    "    def add_query(self, query_id: int, query_text: str, relevant_docs: List[int], \n",
    "                  relevance_scores: Dict[int, float] = None):\n",
    "        \"\"\"\n",
    "        ì¿¼ë¦¬ì™€ ê´€ë ¨ ë¬¸ì„œ ì¶”ê°€\n",
    "        \n",
    "        Args:\n",
    "            query_id: ì¿¼ë¦¬ ID\n",
    "            query_text: ì¿¼ë¦¬ í…ìŠ¤íŠ¸\n",
    "            relevant_docs: ê´€ë ¨ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸\n",
    "            relevance_scores: ë¬¸ì„œë³„ ê´€ë ¨ì„± ì ìˆ˜ (ì„ íƒì )\n",
    "        \"\"\"\n",
    "        self.queries.append({\n",
    "            'id': query_id,\n",
    "            'text': query_text\n",
    "        })\n",
    "        \n",
    "        self.relevance_judgments[query_id] = {\n",
    "            'relevant_docs': relevant_docs,\n",
    "            'scores': relevance_scores or {doc_id: 1.0 for doc_id in relevant_docs}\n",
    "        }\n",
    "    \n",
    "    def get_statistics(self) -> dict:\n",
    "        \"\"\"\n",
    "        ë°ì´í„°ì…‹ í†µê³„\n",
    "        \"\"\"\n",
    "        total_relevant = sum(len(j['relevant_docs']) \n",
    "                           for j in self.relevance_judgments.values())\n",
    "        \n",
    "        return {\n",
    "            'num_queries': len(self.queries),\n",
    "            'num_documents': len(self.documents),\n",
    "            'avg_relevant_per_query': total_relevant / len(self.queries) if self.queries else 0,\n",
    "            'total_relevance_judgments': total_relevant\n",
    "        }\n",
    "    \n",
    "    def export_to_json(self, filepath: str):\n",
    "        \"\"\"\n",
    "        JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°\n",
    "        \"\"\"\n",
    "        import json\n",
    "        \n",
    "        data = {\n",
    "            'queries': self.queries,\n",
    "            'documents': self.documents,\n",
    "            'relevance_judgments': self.relevance_judgments\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# í‰ê°€ ë°ì´í„°ì…‹ êµ¬ì¶• ì˜ˆì œ\n",
    "dataset = RAGTestDataset()\n",
    "\n",
    "# ë¬¸ì„œ ì¶”ê°€\n",
    "documents = [\n",
    "    (1, \"Pythonì€ ê°„ë‹¨í•˜ê³  ì½ê¸° ì‰¬ìš´ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\"),\n",
    "    (2, \"ë¦¬ìŠ¤íŠ¸ëŠ” Pythonì˜ ê¸°ë³¸ ìë£Œêµ¬ì¡° ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\"),\n",
    "    (3, \"ì •ë ¬ ì•Œê³ ë¦¬ì¦˜ì—ëŠ” í€µì†ŒíŠ¸, ë¨¸ì§€ì†ŒíŠ¸, í™ì†ŒíŠ¸ ë“±ì´ ìˆìŠµë‹ˆë‹¤.\"),\n",
    "    (4, \"ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\"),\n",
    "    (5, \"ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì„ ì—¬ëŸ¬ ì¸µìœ¼ë¡œ ìŒ“ì€ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì…ë‹ˆë‹¤.\"),\n",
    "]\n",
    "\n",
    "for doc_id, content in documents:\n",
    "    dataset.add_document(doc_id, content)\n",
    "\n",
    "# ì¿¼ë¦¬ì™€ ê´€ë ¨ì„± íŒë‹¨ ì¶”ê°€\n",
    "dataset.add_query(\n",
    "    query_id=1,\n",
    "    query_text=\"Python ë¦¬ìŠ¤íŠ¸ ì •ë ¬ ë°©ë²•\",\n",
    "    relevant_docs=[2, 3],\n",
    "    relevance_scores={2: 1.0, 3: 0.8}\n",
    ")\n",
    "\n",
    "dataset.add_query(\n",
    "    query_id=2,\n",
    "    query_text=\"ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´\",\n",
    "    relevant_docs=[4, 5],\n",
    "    relevance_scores={4: 1.0, 5: 1.0}\n",
    ")\n",
    "\n",
    "# í†µê³„ ì¶œë ¥\n",
    "stats = dataset.get_statistics()\n",
    "print(\"ğŸ“Š í‰ê°€ ë°ì´í„°ì…‹ í†µê³„:\\n\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ í‰ê°€ ë°ì´í„°ì…‹ êµ¬ì¶• íŒ:\")\n",
    "print(\"1. ë‹¤ì–‘í•œ ë‚œì´ë„ì˜ ì¿¼ë¦¬ í¬í•¨\")\n",
    "print(\"2. ì‹¤ì œ ì‚¬ìš©ì ì§ˆë¬¸ ê¸°ë°˜\")\n",
    "print(\"3. ì „ë¬¸ê°€ì˜ ê´€ë ¨ì„± íŒë‹¨\")\n",
    "print(\"4. ì •ê¸°ì ì¸ ì—…ë°ì´íŠ¸\")\n",
    "print(\"5. í¸í–¥ ì œê±°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. ì§€í‘œ ì„ íƒ ê°€ì´ë“œ\n",
    "\n",
    "### ìƒí™©ë³„ ì¶”ì²œ ì§€í‘œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§€í‘œ ì„ íƒ ê°€ì´ë“œ í…Œì´ë¸”\n",
    "guide_data = [\n",
    "    {\n",
    "        'ìƒí™©': 'ë‹¨ì¼ ì •ë‹µì„ ë¹ ë¥´ê²Œ ì°¾ê¸°',\n",
    "        'ì¶”ì²œ ì§€í‘œ': 'MRR',\n",
    "        'ì´ìœ ': 'ì²« ë²ˆì§¸ ì •ë‹µì˜ ìœ„ì¹˜ê°€ ì¤‘ìš”',\n",
    "        'ì˜ˆì‹œ': 'FAQ ê²€ìƒ‰, ì •ì˜ ì°¾ê¸°'\n",
    "    },\n",
    "    {\n",
    "        'ìƒí™©': 'ì—¬ëŸ¬ ê´€ë ¨ ë¬¸ì„œì˜ ìˆœì„œ ì¤‘ìš”',\n",
    "        'ì¶”ì²œ ì§€í‘œ': 'nDCG',\n",
    "        'ì´ìœ ': 'ê´€ë ¨ì„± ë“±ê¸‰ê³¼ ìˆœì„œë¥¼ í•¨ê»˜ ê³ ë ¤',\n",
    "        'ì˜ˆì‹œ': 'ì œí’ˆ ì¶”ì²œ, ë‰´ìŠ¤ ê²€ìƒ‰'\n",
    "    },\n",
    "    {\n",
    "        'ìƒí™©': 'ì •í™•í•œ ê²°ê³¼ë§Œ í•„ìš”',\n",
    "        'ì¶”ì²œ ì§€í‘œ': 'Precision@K',\n",
    "        'ì´ìœ ': 'ë…¸ì´ì¦ˆë¥¼ ìµœì†Œí™”í•´ì•¼ í•¨',\n",
    "        'ì˜ˆì‹œ': 'ì˜ë£Œ ì •ë³´, ë²•ë¥  ë¬¸ì„œ'\n",
    "    },\n",
    "    {\n",
    "        'ìƒí™©': 'ëª¨ë“  ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•„ì•¼ í•¨',\n",
    "        'ì¶”ì²œ ì§€í‘œ': 'Recall@K',\n",
    "        'ì´ìœ ': 'ë†“ì¹˜ëŠ” ì •ë³´ê°€ ì—†ì–´ì•¼ í•¨',\n",
    "        'ì˜ˆì‹œ': 'íŠ¹í—ˆ ê²€ìƒ‰, ì—°êµ¬ ë…¼ë¬¸'\n",
    "    },\n",
    "    {\n",
    "        'ìƒí™©': 'ê· í˜•ì¡íŒ ì„±ëŠ¥ í•„ìš”',\n",
    "        'ì¶”ì²œ ì§€í‘œ': 'F1-Score@K',\n",
    "        'ì´ìœ ': 'Precisionê³¼ Recallì˜ ê· í˜•',\n",
    "        'ì˜ˆì‹œ': 'ì¼ë°˜ì ì¸ RAG ì‹œìŠ¤í…œ'\n",
    "    },\n",
    "    {\n",
    "        'ìƒí™©': 'ì „ì²´ ë­í‚¹ í’ˆì§ˆ í‰ê°€',\n",
    "        'ì¶”ì²œ ì§€í‘œ': 'MAP',\n",
    "        'ì´ìœ ': 'ìˆœì„œë¥¼ ê³ ë ¤í•œ ì¢…í•© í‰ê°€',\n",
    "        'ì˜ˆì‹œ': 'ê²€ìƒ‰ ì—”ì§„ í‰ê°€'\n",
    "    },\n",
    "]\n",
    "\n",
    "df_guide = pd.DataFrame(guide_data)\n",
    "\n",
    "# í…Œì´ë¸” ì‹œê°í™”\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(\n",
    "        values=['<b>ìƒí™©</b>', '<b>ì¶”ì²œ ì§€í‘œ</b>', '<b>ì´ìœ </b>', '<b>ì˜ˆì‹œ</b>'],\n",
    "        fill_color='#4CAF50',\n",
    "        align='left',\n",
    "        font=dict(color='white', size=12)\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[df_guide[col] for col in df_guide.columns],\n",
    "        fill_color=['#f1f1f1', '#e8f5e9', '#f1f1f1', '#e8f5e9'],\n",
    "        align='left',\n",
    "        height=30\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='RAG í‰ê°€ ì§€í‘œ ì„ íƒ ê°€ì´ë“œ',\n",
    "    height=400,\n",
    "    margin=dict(l=0, r=0, t=30, b=0)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. ì‹¤ì „ íŒê³¼ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤\n",
    "\n",
    "### ğŸ¯ RAG í‰ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "âœ… RAG í‰ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "========================\n",
    "\n",
    "ğŸ“Š í‰ê°€ ì¤€ë¹„\n",
    "â–¡ ëŒ€í‘œì„± ìˆëŠ” ì¿¼ë¦¬ ì„¸íŠ¸ ì¤€ë¹„ (ìµœì†Œ 50ê°œ)\n",
    "â–¡ ì „ë¬¸ê°€ì˜ ê´€ë ¨ì„± íŒë‹¨ í™•ë³´\n",
    "â–¡ ë‹¤ì–‘í•œ ë‚œì´ë„ì™€ ìœ í˜•ì˜ ì¿¼ë¦¬ í¬í•¨\n",
    "â–¡ ì‹¤ì œ ì‚¬ìš© í™˜ê²½ê³¼ ìœ ì‚¬í•œ ì¡°ê±´ ì„¤ì •\n",
    "\n",
    "ğŸ“ˆ ì§€í‘œ ì„ íƒ\n",
    "â–¡ ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì— ë§ëŠ” ì£¼ìš” ì§€í‘œ ì„ ì •\n",
    "â–¡ ë³´ì¡° ì§€í‘œ 2-3ê°œ ì¶”ê°€ ì„ ì •\n",
    "â–¡ ì‚¬ìš©ì ë§Œì¡±ë„ì™€ì˜ ìƒê´€ê´€ê³„ ê²€ì¦\n",
    "\n",
    "ğŸ”¬ ì‹¤í—˜ ì„¤ê³„\n",
    "â–¡ A/B í…ŒìŠ¤íŠ¸ ì„¤ì •\n",
    "â–¡ í†µê³„ì  ìœ ì˜ì„± ê²€ì¦ ê³„íš\n",
    "â–¡ ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ í‰ê°€ ë³‘í–‰\n",
    "\n",
    "ğŸ“ ê²°ê³¼ ë¶„ì„\n",
    "â–¡ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„ (Error Analysis)\n",
    "â–¡ ê°œì„  í¬ì¸íŠ¸ ë„ì¶œ\n",
    "â–¡ ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘\n",
    "\n",
    "ğŸš€ ìµœì í™”\n",
    "â–¡ ì²­í‚¹ ì „ëµ ì¡°ì •\n",
    "â–¡ ì„ë² ë”© ëª¨ë¸ ë¹„êµ\n",
    "â–¡ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ê°œì„ \n",
    "â–¡ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì ìš©\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nğŸ’¡ ì¶”ê°€ ê°œì„  ì•„ì´ë””ì–´:\\n\")\n",
    "\n",
    "improvements = [\n",
    "    \"1. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: BM25 + Vector Search ì¡°í•©\",\n",
    "    \"2. **ì¬ìˆœìœ„í™”**: Cross-Encoderë¡œ ìƒìœ„ ê²°ê³¼ ì¬ì •ë ¬\",\n",
    "    \"3. **ì¿¼ë¦¬ í™•ì¥**: ë™ì˜ì–´/ê´€ë ¨ì–´ ì¶”ê°€\",\n",
    "    \"4. **ì ì‘í˜• K**: ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¼ Kê°’ ë™ì  ì¡°ì •\",\n",
    "    \"5. **ìºì‹±**: ìì£¼ ê²€ìƒ‰ë˜ëŠ” ì¿¼ë¦¬ ê²°ê³¼ ìºì‹±\",\n",
    "    \"6. **í”¼ë“œë°± ë£¨í”„**: ì‚¬ìš©ì í´ë¦­ ë°ì´í„°ë¡œ ì§€ì† ê°œì„ \"\n",
    "]\n",
    "\n",
    "for improvement in improvements:\n",
    "    print(f\"  {improvement}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. ìš”ì•½ ë° ê²°ë¡ \n",
    "\n",
    "### ğŸ“Œ í•µì‹¬ ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ìš”ì•½ í…Œì´ë¸”\n",
    "summary_data = {\n",
    "    'ì§€í‘œ': ['MRR', 'nDCG', 'Precision@K', 'Recall@K', 'F1@K', 'MAP', 'Hit Rate'],\n",
    "    'í•µì‹¬ ì§ˆë¬¸': [\n",
    "        'ì²« ì •ë‹µì´ ëª‡ ë²ˆì§¸?',\n",
    "        'ê´€ë ¨ì„± ë†’ì€ ê²Œ ìœ„ì—?',\n",
    "        'Kê°œ ì¤‘ ì •ë‹µ ë¹„ìœ¨?',\n",
    "        'ì „ì²´ ì •ë‹µ ì¤‘ ì°¾ì€ ë¹„ìœ¨?',\n",
    "        'Pì™€ Rì˜ ê· í˜•ì€?',\n",
    "        'ì „ì²´ ìˆœìœ„ í’ˆì§ˆì€?',\n",
    "        'ìµœì†Œ 1ê°œëŠ” ì°¾ì•˜ë‚˜?'\n",
    "    ],\n",
    "    'ë²”ìœ„': ['0~1', '0~1', '0~1', '0~1', '0~1', '0~1', '0~1'],\n",
    "    'ë³µì¡ë„': ['ë‚®ìŒ', 'ë†’ìŒ', 'ë‚®ìŒ', 'ë‚®ìŒ', 'ë‚®ìŒ', 'ì¤‘ê°„', 'ë‚®ìŒ'],\n",
    "    'ìš°ì„  ì‚¬ìš©': [\n",
    "        'ë‹¨ì¼ ì •ë‹µ',\n",
    "        'ë­í‚¹ í’ˆì§ˆ',\n",
    "        'ì •í™•ë„ ì¤‘ì‹œ',\n",
    "        'ì™„ì „ì„± ì¤‘ì‹œ',\n",
    "        'ê· í˜•',\n",
    "        'ì¢…í•© í‰ê°€',\n",
    "        'ê¸°ë³¸ ì²´í¬'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"ğŸ“Š RAG í‰ê°€ ì§€í‘œ ì´ì •ë¦¬\\n\")\n",
    "print(df_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\"\"\n",
    "ğŸ¯ í•µì‹¬ ë©”ì‹œì§€:\n",
    "\n",
    "1. **í•˜ë‚˜ì˜ ì§€í‘œë¡œëŠ” ë¶€ì¡±í•©ë‹ˆë‹¤**\n",
    "   - ì—¬ëŸ¬ ì§€í‘œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë´ì•¼ í•©ë‹ˆë‹¤\n",
    "   \n",
    "2. **ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œê°€ ìš°ì„ ì…ë‹ˆë‹¤**\n",
    "   - ì‚¬ìš©ì ë§Œì¡±ë„ì™€ ì—°ê²°ë˜ëŠ” ì§€í‘œë¥¼ ì„ íƒí•˜ì„¸ìš”\n",
    "   \n",
    "3. **ì§€ì†ì ì¸ í‰ê°€ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤**\n",
    "   - ì •ê¸°ì ìœ¼ë¡œ í‰ê°€í•˜ê³  ê°œì„ í•˜ì„¸ìš”\n",
    "   \n",
    "4. **ì‹¤ì œ ë°ì´í„°ë¡œ í‰ê°€í•˜ì„¸ìš”**\n",
    "   - í•©ì„± ë°ì´í„°ë³´ë‹¤ ì‹¤ì œ ì‚¬ìš©ì ì¿¼ë¦¬ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤\n",
    "\n",
    "ëª¨ë“  ì§€í‘œëŠ” 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ì€ ì„±ëŠ¥ì„ ì˜ë¯¸í•©ë‹ˆë‹¤! ğŸš€\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì°¸ê³  ìë£Œ\n",
    "\n",
    "- [Information Retrieval êµê³¼ì„œ](https://nlp.stanford.edu/IR-book/)\n",
    "- [TREC (Text REtrieval Conference)](https://trec.nist.gov/)\n",
    "- [MS MARCO ë°ì´í„°ì…‹](https://microsoft.github.io/msmarco/)\n",
    "- [BEIR Benchmark](https://github.com/beir-cellar/beir)\n",
    "- [LangChain Evaluation](https://python.langchain.com/docs/guides/evaluation)\n",
    "- [Ragas: RAG í‰ê°€ í”„ë ˆì„ì›Œí¬](https://github.com/explodinggradients/ragas)\n",
    "\n",
    "---\n",
    "\n",
    "**ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰**\n",
    "\n",
    "RAG ì‹œìŠ¤í…œ í‰ê°€ ì§€í‘œë¥¼ ì™„ë²½í•˜ê²Œ ë§ˆìŠ¤í„°í–ˆìŠµë‹ˆë‹¤.\n",
    "ì´ì œ ì—¬ëŸ¬ë¶„ì˜ RAG ì‹œìŠ¤í…œì„ ì •í™•í•˜ê²Œ í‰ê°€í•˜ê³  ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}