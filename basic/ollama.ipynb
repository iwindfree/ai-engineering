{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87812c9",
   "metadata": {},
   "source": [
    "# Ollama 개요 및 설치 / 모델 다운로드 가이드\n",
    "\n",
    "## 1. Ollama란?\n",
    "\n",
    "**Ollama**는 로컬 환경에서 대규모 언어 모델(LLM)을  \n",
    "아주 간단하게 실행할 수 있도록 도와주는 도구입니다.\n",
    "\n",
    "주요 특징:\n",
    "\n",
    "- 💻 **로컬 실행**: 인터넷 연결 없이도 모델 실행 가능\n",
    "- ⚡ **간단한 설치**: 별도 CUDA 설정 없이 바로 사용 가능\n",
    "- 📦 **모델 관리 자동화**: 다운로드·버전 관리가 매우 쉬움\n",
    "- 🔌 **API 제공**: REST API 형태로 외부 프로그램과 연동 가능\n",
    "- 🧩 **다양한 모델 지원**: LLaMA, Mistral, Gemma, Code LLM 등\n",
    "\n",
    "> OpenAI API, Claude API를 쓰는 구조와 유사하게  \n",
    "> 로컬 LLM 서버를 띄운다고 생각하면 이해가 쉽습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 지원 운영체제\n",
    "\n",
    "- ✅ macOS (Apple Silicon / Intel)\n",
    "- ✅ Linux\n",
    "- ⚠️ Windows \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Ollama 설치 방법\n",
    "\n",
    "### 공식 설치 파일 (권장)\n",
    "\n",
    "1. 아래 사이트 접속  \n",
    "   👉 https://ollama.com\n",
    "2. 사용자 운영체제에 맞는 ollma 설치파일 다운로드 후 설치\n",
    " \n",
    "\n",
    "### 설치 확인:\n",
    "```bash\n",
    "ollama --version\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c1d3ec",
   "metadata": {},
   "source": [
    "## 4. 기본 사용법\n",
    "모델 실행 (다운로드 포함)\n",
    "* ollama run llama3\n",
    "\n",
    "모델 미리 다운로드\n",
    "* ollama pull llama3\n",
    "\n",
    "설치된 모델 확인\n",
    "* ollama list\n",
    "\n",
    "모델 삭제\n",
    "* ollama rm llama3\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
