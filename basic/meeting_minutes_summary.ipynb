{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d29bae",
   "metadata": {},
   "source": [
    "# LLMì„ í™œìš©í•œ íšŒì˜ë¡ ìë™ ìš”ì•½ ì‹œìŠ¤í…œ\n",
    "\n",
    "## ì†Œê°œ\n",
    "\n",
    "íšŒì˜ë¡ ì‘ì„±ì€ ë§ì€ ì¡°ì§ì—ì„œ í•„ìˆ˜ì ì´ì§€ë§Œ ì‹œê°„ì´ ë§ì´ ì†Œìš”ë˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤. íšŒì˜ ë‚´ìš©ì„ ì •í™•í•˜ê²Œ ê¸°ë¡í•˜ê³ , í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ë©°, ì•¡ì…˜ ì•„ì´í…œì„ ì •ë¦¬í•˜ëŠ” ë° íšŒì˜ ì‹œê°„ë§Œí¼ì˜ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ë¬¸ì œì \n",
    "\n",
    "- â° **ì‹œê°„ ì†Œëª¨**: 1ì‹œê°„ íšŒì˜ = 30ë¶„~1ì‹œê°„ì˜ íšŒì˜ë¡ ì‘ì„±\n",
    "- ğŸ“ **ì¼ê´€ì„± ë¶€ì¡±**: ì‘ì„±ìë§ˆë‹¤ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ê³¼ í¬ë§·\n",
    "- ğŸ¯ **í•µì‹¬ ëˆ„ë½**: ì¤‘ìš”í•œ ê²°ì • ì‚¬í•­ì´ë‚˜ ì•¡ì…˜ ì•„ì´í…œ ëˆ„ë½ ê°€ëŠ¥\n",
    "- ğŸ”„ **ë°˜ë³µ ì‘ì—…**: ë§¤ë²ˆ ìœ ì‚¬í•œ êµ¬ì¡°ì˜ ë¬¸ì„œ ì‘ì„±\n",
    "\n",
    "### AI ì†”ë£¨ì…˜\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” LLM(Large Language Model)ì„ í™œìš©í•˜ì—¬ ìŒì„± íšŒì˜ë¥¼ ìë™ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³ , êµ¬ì¡°í™”ëœ íšŒì˜ë¡ì„ ìƒì„±í•˜ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ë‹¤ë£° ë‚´ìš©\n",
    "\n",
    "1. ğŸ¤ **Speech-to-Text**: OpenAI Whisperë¥¼ ì‚¬ìš©í•œ ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜\n",
    "2. ğŸ¤– **LLM í™œìš©**: ë‹¤ì–‘í•œ LLMì„ ì‚¬ìš©í•œ íšŒì˜ë¡ ìš”ì•½\n",
    "3. ğŸ“Š **êµ¬ì¡°í™”**: ìš”ì•½, ë…¼ì˜ ì‚¬í•­, í•µì‹¬ í¬ì¸íŠ¸, ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ\n",
    "4. âš–ï¸ **ëª¨ë¸ ë¹„êµ**: Ollama(ë¡œì»¬) vs OpenAI(í´ë¼ìš°ë“œ)\n",
    "5. ğŸ’¡ **ì‹¤ì „ í™œìš©**: í”„ë¡¬í”„íŠ¸ ìµœì í™” ë° ìë™í™” íŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7087b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vm5juq34rba",
   "metadata": {},
   "source": [
    "## í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° Import\n",
    "\n",
    "ë¨¼ì € í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ importí•©ë‹ˆë‹¤:\n",
    "- `openai`: OpenAI API ì‚¬ìš© (Whisper, GPT)\n",
    "- `dotenv`: í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬\n",
    "- `IPython.display`: Jupyterì—ì„œ Markdown ë Œë”ë§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916a585",
   "metadata": {},
   "source": [
    "## 1ë‹¨ê³„: Speech to Text\n",
    "\n",
    "### OpenAI Whisper ëª¨ë¸\n",
    "\n",
    "**Whisper**ëŠ” OpenAIê°€ ê°œë°œí•œ ë²”ìš© ìŒì„± ì¸ì‹ ëª¨ë¸ì…ë‹ˆë‹¤:\n",
    "\n",
    "#### ì£¼ìš” íŠ¹ì§•\n",
    "- ğŸŒ **ë‹¤êµ­ì–´ ì§€ì›**: 99ê°œ ì–¸ì–´ ì§€ì›\n",
    "- ğŸ¯ **ë†’ì€ ì •í™•ë„**: ë‹¤ì–‘í•œ ì–µì–‘ê³¼ ë°°ê²½ ì†ŒìŒ ì²˜ë¦¬\n",
    "- âš¡ **ë¹ ë¥¸ ì²˜ë¦¬**: APIë¥¼ í†µí•œ ì‹¤ì‹œê°„ ë³€í™˜\n",
    "- ğŸ’° **í•©ë¦¬ì ì¸ ê°€ê²©**: 1ë¶„ë‹¹ $0.006\n",
    "\n",
    "#### ì§€ì› í˜•ì‹\n",
    "- íŒŒì¼ í˜•ì‹: mp3, mp4, mpeg, mpga, m4a, wav, webm\n",
    "- ìµœëŒ€ í¬ê¸°: 25MB\n",
    "- ê¸´ ì˜¤ë””ì˜¤ëŠ” ì²­í‚¹(chunking) í•„ìš”\n",
    "\n",
    "ì´ì œ ì‹¤ì œ ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb387285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³€í™˜ ì™„ë£Œ! ê²°ê³¼:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "kind of the confluence of this whole idea of the Confluence Week, the merging of two rivers, and as we've kind of seen recently in politics and in the world, there's a lot of situations where water is very important right now and it's a very big issue. So that is the reason that the back of the logo is considered water. So let you see the creation of the logo here. Yes, so that basically kind of sums up the reason behind the logo and all the meanings behind the symbolism. And you'll hear a little bit more about our Confluence Week is basically highlighting all of these indigenous events and things that are happening around Denver so that we can kind of bring more people together and kind of share this whole idea of Indigenous Peoples Day. So thank you. Thank you so much and thanks for your leadership. All right. Welcome to the Denver City Council meeting of Monday, October 9th. Please rise with the Pledge of Allegiance by Councilman Lopez. I pledge allegiance to the flag of the United States of America and to the republic for which it stands, one nation under God, indivisible, with liberty and justice for all. All right, thank you Councilman Lopez. Madam Secretary, roll call. Black? Clerk? Here. Espinosa? Here. Flynn? Gilmore? Here. Cashman? Here. Kanish? Here. Lopez? Here. Nu? Here. Ortega? Here. Sussman? Here. Mr. President? Here. 11 present. 11 members present. We do have a quorum. Approval of the minutes. Are there any corrections to the minutes of October 2nd? Seeing none, minutes of October 2nd stand approved. Council announcements. Are there any announcements by members of council? Councilman Clark? Thank you Mr. President. I just wanted to invite everyone down to the first ever Halloween parade on Broadway in Lucky District 7. It will happen on Saturday, October 21st at 6 o'clock p.m. It will move along Broadway from 3rd to Alameda. It's going to be a fun, family-friendly event. Everyone's invited to come down, wear a costume. There will be candy for the kids and there are tiki zombies and 29 hearses and all kinds of fun and funky stuff on the fun and funky part of Broadway. So please join us October 21st at 6 o'clock for the Broadway Halloween Parade. Thank you Mr. President. All right. Thank you Councilman Clark. I will be there. All right. Presentations. Madam Secretary, do we have any presentations? None, Mr. President. Communications. Do we have any communications? None, Mr. President. We do have one proclamation this evening. Proclamation 1127 in observance of the annual Indigenous Peoples Day in the City and County of Denver. Councilman Lopez, will you please read it? Thank you, Mr. President. With pride. Proclamation number 17. Well, let me just say this differently. Proclamation number 1127 series of 2017 in observance of the second annual Indigenous Peoples Day in the City and County of Denver. Whereas the Council of the City and County of Denver recognizes that the Indigenous Peoples have lived and flourished on the lands known as the Americas since time immemorial and that Denver and the surrounding communities are built upon the ancestral homelands of numerous Indigenous tribes which include the Southern Ute, the Ute Mountain, Ute tribes of Colorado. And whereas the tribal homelands and seasonal encampments of the Arapaho and Cheyenne people along the banks of the Cherry Creek and South Platte River confluence gave bearing to the future settlements that would become the birthplace of the Mile High City. And whereas Colorado encompasses the ancestral homelands of 48 tribes and the City and County of Denver and surrounding communities are home to the descendants of approximately 100 tribal nations. And whereas on October 3, 2016, the City and County of Denver unanimously passed Council Bill 801 series of 2016 officially designating the second Monday of October of each year as Indigenous Peoples Day in Denver, Colorado. And whereas the Council of the City and County of Denver continues to recognize and value the vast contributions made to the community through Indigenous Peoples knowledge, science, philosophy, arts, and culture. And through these contributions, the City of Denver has developed and thrived. Whereas the Indigenous community, especially youth, have made great efforts this year to draw attention to the contributions of Indigenous people, including Confluence Week, drawing record attendance to a National Indigenous Youth Leadership Conference, leading conversations on inclusion with their peers, and supporting increased Indigenous youth participation in science and engineering. Now, therefore, be it proclaimed by the Council of the City and County of Denver, Section 1, that the Council of the City and County of Denver celebrates and honors the cultural and foundational contributions of Indigenous people to our history, our past, our present, and future, and continues to promote the education of the Denver community about these historic and contemporary contributions of Indigenous people. Section 2, that the City and County of Denver, Colorado, does hereby observe October 9, 2017, as Indigenous Peoples Day. Section 3, that the Clerk of the City and County of Denver shall attest and affix the seal of the City and County of Denver to this proclamation, and that a copy be transmitted to the Denver American Indian Commission, the City and County of Denver School District No. 1, and the Colorado Commission on Indian Affairs. Thank you, Councilman Lopez. Your motion to adopt. Mr. President, I move that Proclamation No. 1127, Series of 2017, be adopted. All right, it has been moved and seconded. Councilmembers of Council, Councilman Lopez. Thank you, Mr. President. It gives me a lot of pleasure and pride to read this proclamation officially for the third time, but as Indigenous Peoples Day in Denver, officially for the second time. It's always awesome to be able to see not just this proclamation come by my desk, but to see so many different people from our community in our council chambers. It was a very beautiful piece of artwork that you presented to us earlier, and it is exactly the spirit that we drafted this proclamation, and this actual ordinance that created Indigenous Peoples Day, when we sat down and wrote it as a community, we couldn't think of anything else to begin except for the confluence of the two rivers, and those confluence of the two rivers created such a great city, and we live in such an amazing city, and we're all proud of it, and sometimes we, and a lot of people from all over the country or all over the world are proud of it, and sometimes a little too proud of it, just tell them to go back home. But I'm kidding when I say that. But the really nice thing about this is that we are celebrating Indigenous Peoples Day out of pride for who we are, who we are as a city, and the contributions of Indigenous people to the city, not out of spite, not out of a replacement of one culture over the other, or out of contempt, or disrespect. You know, I think of a quote that Cesar Chavez made very popular, and it stuck with me for a very long time, and anytime I have the opportunity, I speak in front of children, and especially children in our community that, you know, they often second guess themselves on where they're coming from, who they are, and I always say that, you know, it's very important to be proud of who you're from, and the quote that I use from Cesar Chavez is, you know, pride in one's own culture does not require contempt or disrespect of another, right? And that's very important. It's very important for us to recognize that no matter who we are, where we come from in this society, that your pride in your own culture doesn't require, should not require the contempt or disrespect of another. And man, what a year for that to just sit on our shoulders for a while, for us to think about, right? And so I wanted to just thank you all, thank the commission. There's going to be a couple individuals that are going to come speak. Thank you for your art, your lovely artwork for us to see what's in your heart and what now has become, probably is going to be a very important symbol for the community. And also just for the work, the daily work every single day. We still have a lot of brothers and sisters whose ancestors once lived in these lands freely now stand on street corners, right, in poverty, without access to services, right, without access to sobriety or even housing or jobs. And what a cruel way to pay back a culture that has paved the way for the city to be built upon its shores, right? So we have a lot of work to do. And these kind of proclamations and this day is not a day off, it's a day on in Denver, right, in addressing those critical issues. So I know that my colleagues are very supportive. I'm going to ask you to support this proclamation as I know you always have done in the past. I'm very proud of today. Oh, and we made Time Magazine and Newsweek once again today as being a leader in terms of the cities that are celebrating Indigenous Peoples Day. I wanted to make a point out of that. Thank you, Councilman Lopez, and thank you for sponsoring this. Councilwoman Ortega. Mr. President, I want to ask my name be added. I don't think I could add much more to what Councilman Lopez has shared with us. I want to thank him for bringing this forward and really just appreciate all the contributions that our Native American community has contributed to this great city and great state. I worked in the Lieutenant Governor's office when the Commission on Indian Affairs was created and had the benefit of being able to go down to the Four Corners for a peace treaty signing ceremony between the Utes and the Comanches\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OpenAI Whisperë¥¼ ì‚¬ìš©í•œ ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜\n",
    "AUDIO_MODEL = \"gpt-4o-mini-transcribe\"  # Whisper ëª¨ë¸\n",
    "audio_file_path = \"./denver_extract.mp3\"  # ë³€í™˜í•  ì˜¤ë””ì˜¤ íŒŒì¼\n",
    "audio_file = open(audio_file_path, \"rb\")\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ\n",
    "load_dotenv(override=True) \n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜\n",
    "transcription = openai.audio.transcriptions.create(\n",
    "    model=AUDIO_MODEL, \n",
    "    file=audio_file, \n",
    "    response_format=\"text\"  # text, json, srt, verbose_json, vtt ì¤‘ ì„ íƒ\n",
    ")\n",
    "\n",
    "print(\"ë³€í™˜ ì™„ë£Œ! ê²°ê³¼:\")\n",
    "display(Markdown(transcription))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc43e0b",
   "metadata": {},
   "source": [
    "## 2ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ìœ¼ë¡œ íšŒì˜ë¡ ìƒì„±\n",
    "\n",
    "ì´ì œ ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¡œ ì „í™˜ëœ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ **êµ¬ì¡°í™”ëœ íšŒì˜ë¡**ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í”„ë¡¬í”„íŠ¸ ì„¤ê³„ ì›ì¹™\n",
    "\n",
    "íš¨ê³¼ì ì¸ íšŒì˜ë¡ ìƒì„±ì„ ìœ„í•œ í•µì‹¬ ìš”ì†Œ:\n",
    "\n",
    "#### 1. ëª…í™•í•œ ì—­í•  ì •ì˜ (System Message)\n",
    "- LLMì˜ ì—­í• ê³¼ ëª©í‘œë¥¼ ëª…í™•íˆ ì •ì˜\n",
    "- ì¶œë ¥ í˜•ì‹ ì§€ì • (ë§ˆí¬ë‹¤ìš´, JSON ë“±)\n",
    "- ì¼ê´€ëœ í’ˆì§ˆ ìœ ì§€\n",
    "\n",
    "#### 2. êµ¬ì²´ì ì¸ ìš”êµ¬ì‚¬í•­ (User Prompt)\n",
    "- ì›í•˜ëŠ” ì •ë³´ ëª…ì‹œ (ì°¸ì„ì, ì¼ì‹œ, ì¥ì†Œ)\n",
    "- ì„¹ì…˜ êµ¬ì¡° ì§€ì • (ìš”ì•½, í† ë¡ , ì•¡ì…˜ ì•„ì´í…œ)\n",
    "- ì˜ˆì‹œ ì œê³µìœ¼ë¡œ ì¶œë ¥ í’ˆì§ˆ í–¥ìƒ\n",
    "\n",
    "#### 3. ì»¨í…ìŠ¤íŠ¸ ì œê³µ\n",
    "- íšŒì˜ ìœ í˜• (ì¼ë°˜, ê¸°ìˆ , ê²½ì˜ì§„ ë“±)\n",
    "- ì¡°ì§ ì •ë³´ (í•„ìš” ì‹œ)\n",
    "- íŠ¹ë³„ ìš”êµ¬ì‚¬í•­\n",
    "\n",
    "### í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "\n",
    "ì•„ë˜ëŠ” ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì…ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48cb1223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„ ì™„ë£Œ!\n",
      "  - ì‹œìŠ¤í…œ ë©”ì‹œì§€ ê¸¸ì´: 168 ë¬¸ì\n",
      "  - ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ê¸¸ì´: 9984 ë¬¸ì\n"
     ]
    }
   ],
   "source": [
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€: LLMì˜ ì—­í• ê³¼ ì¶œë ¥ í˜•ì‹ ì •ì˜\n",
    "system_message = \"\"\"\n",
    "You produce minutes of meetings from transcripts, with summary, key discussion points,\n",
    "takeaways and action items with owners, in markdown format without code blocks.\n",
    "\"\"\"\n",
    "\n",
    "# ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸: êµ¬ì²´ì ì¸ ìš”êµ¬ì‚¬í•­ê³¼ ì»¨í…ìŠ¤íŠ¸\n",
    "user_prompt = f\"\"\"\n",
    "Below is an extract transcript of a Denver council meeting.\n",
    "Please write minutes in markdown without code blocks, including:\n",
    "- a summary with attendees, location and date\n",
    "- discussion points\n",
    "- takeaways\n",
    "- action items with owners\n",
    "\n",
    "Transcription:\n",
    "{transcription}\n",
    "\"\"\"\n",
    "\n",
    "# OpenAI Chat API í˜•ì‹ìœ¼ë¡œ ë©”ì‹œì§€ êµ¬ì„±\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},  # LLMì˜ ì—­í• \n",
    "    {\"role\": \"user\", \"content\": user_prompt}  # ì‚¬ìš©ì ìš”ì²­\n",
    "]\n",
    "\n",
    "print(\"âœ“ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(f\"  - ì‹œìŠ¤í…œ ë©”ì‹œì§€ ê¸¸ì´: {len(system_message)} ë¬¸ì\")\n",
    "print(f\"  - ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(user_prompt)} ë¬¸ì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twisvr5o1dp",
   "metadata": {},
   "source": [
    "### í”„ë¡¬í”„íŠ¸ ìµœì í™” íŒ\n",
    "\n",
    "**System Message ì‘ì„± íŒ:**\n",
    "- ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ\n",
    "- ì¶œë ¥ í˜•ì‹ì„ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì •\n",
    "- ì—­í•  ê¸°ë°˜ ì§€ì‹œ (\"You are a meeting secretary...\")\n",
    "\n",
    "**User Prompt ì‘ì„± íŒ:**\n",
    "- í•„ìš”í•œ ëª¨ë“  ì •ë³´ë¥¼ ë‚˜ì—´\n",
    "- ì˜ˆì‹œë¥¼ ì œê³µí•˜ë©´ ë” ì¢‹ì€ ê²°ê³¼\n",
    "- ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¶©ë¶„íˆ ì œê³µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c6e3fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ollama (Llama 3.2) ê²°ê³¼ ===\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Denver City Council Meeting Minutes\n",
       "## Summary\n",
       "Attendees: Councilman Black, Councilwoman Espinosa, Councilman Flynn, Councilman Gilmore, Councilor Kanish, Councilman Lopez, Mayor Nu, Councilman Ortega, Councilman Sussman, President Clark Date: Monday, October 9th, Year\n",
       "\n",
       "Location: Denver City Council Meeting Room\n",
       "\n",
       "## Discussion Points\n",
       "- Confluence Week and indigenous events\n",
       "- Logan Square project update not discussed at this meeting.\n",
       "\n",
       "## Takeaways\n",
       "No notable discussion points other than the proclamation of Indigenous Peoples Day.\n",
       "\n",
       "## Action Items\n",
       "* No action items assigned to attendees.\n",
       "All \n",
       "## Next Steps None"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ollamaë¥¼ OpenAI API í˜•ì‹ìœ¼ë¡œ ì‚¬ìš©\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1',  # Ollama ë¡œì»¬ ì„œë²„\n",
    "    api_key='ollama'  # ë”ë¯¸ í‚¤ (í˜•ì‹ ë§ì¶”ê¸°ìš©)\n",
    ")\n",
    "\n",
    "# Llama 3.2ë¡œ íšŒì˜ë¡ ìƒì„±\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama3.2\",  # Ollamaì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"=== Ollama (Llama 3.2) ê²°ê³¼ ===\")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbyfqhx2bv5",
   "metadata": {},
   "source": [
    "## 3ë‹¨ê³„: ë‹¤ì–‘í•œ LLMìœ¼ë¡œ íšŒì˜ë¡ ìƒì„±\n",
    "\n",
    "ì´ì œ ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ LLMì˜ ì„±ëŠ¥ì„ ë¹„êµí•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ì˜µì…˜ 1: Ollama (ë¡œì»¬ LLM)\n",
    "\n",
    "**Ollama**ëŠ” ë¡œì»¬ì—ì„œ LLMì„ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì˜¤í”ˆì†ŒìŠ¤ ë„êµ¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ì¥ì \n",
    "- ğŸ’° **ë¬´ë£Œ**: API ë¹„ìš© ì—†ìŒ\n",
    "- ğŸ”’ **í”„ë¼ì´ë²„ì‹œ**: ë°ì´í„°ê°€ ì™¸ë¶€ë¡œ ë‚˜ê°€ì§€ ì•ŠìŒ\n",
    "- âš¡ **ë‚®ì€ ì§€ì—°ì‹œê°„**: ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¶ˆí•„ìš”\n",
    "- ğŸ¯ **ì»¤ìŠ¤í„°ë§ˆì´ì§•**: ëª¨ë¸ ë¯¸ì„¸ ì¡°ì • ê°€ëŠ¥\n",
    "\n",
    "#### ë‹¨ì \n",
    "- ğŸ’» **í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­**: GPU í•„ìš” (8GB+ VRAM)\n",
    "- ğŸ“Š **ì„±ëŠ¥**: í´ë¼ìš°ë“œ ëª¨ë¸ ëŒ€ë¹„ ë‚®ì€ í’ˆì§ˆ ê°€ëŠ¥\n",
    "- ğŸ”§ **ì„¤ì • í•„ìš”**: ì´ˆê¸° ì„¤ì¹˜ ë° êµ¬ì„±\n",
    "\n",
    "#### ì„¤ì¹˜ ë°©ë²•\n",
    "```bash\n",
    "# macOS/Linux\n",
    "curl https://ollama.ai/install.sh | sh\n",
    "\n",
    "# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n",
    "ollama pull llama3.2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f931c31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OpenAI GPT-4 ê²°ê³¼ ===\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Denver City Council Meeting Minutes\n",
       "\n",
       "**Date:** Monday, October 9th, 2017  \n",
       "**Location:** Denver Council Chambers  \n",
       "**Attendees:** Councilmembers Black, Clark, Espinoza, Flynn, Gilmore, Cashman, Kneich, Lopez, New, Ortega, Sussman, Council President\n",
       "\n",
       "## Summary\n",
       "\n",
       "The meeting started with a discussion about the Confluence Week logo, highlighting the importance of water and indigenous events in Denver. This provided context for the celebration of Indigenous Peoples Day in Denver. The meeting progressed to the Council's regular order of business, including the approval of previous minutes, current council announcements, the lack of presentations and communications. Proclamation 1127, the observance of Indigenous Peoples Day, was then read and discussed. The theme of Indigenous rights and contributions such as â€œConfluence Weekâ€ were at the heart of the meeting.\n",
       "\n",
       "## Discussion points\n",
       "\n",
       "1. Explanation of the Confluence Week logo, which represents rivers merging, highlighting the importance of water.\n",
       "2. Description of objectives for Confluence Week and Indigenous Peoples Day.\n",
       "3. Announcement of the first-ever Halloween parade on Broadway in District 7.\n",
       "4. Reading, discussion, and approval of Proclamation 1127, observance of Indigenous Peoples Day in Denver.\n",
       "\n",
       "## Takeaways\n",
       "\n",
       "The council has a deep respect for the indigenous peoples that originally lived in the area now known as Denver. They are taking steps to ensure these peoples are recognized and celebrated, as highlighted by Proclamation 1127. They hope to continue this respect and recognition moving forward. \n",
       "\n",
       "## Action items\n",
       "\n",
       "1. Halloween Parade: Councilman Clark invited everyone to the Halloween parade on Broadway in District 7, on Saturday, October 21st at 6 p.m.\n",
       "2. Proclamation 1127: Following the reading and the discussion of Proclamation 1127 by Councilman Lopez, the Council approved the observance of Indigenous Peoples Day in Denver unanimously. A copy of the Proclamation will be transmitted to the Denver American Indian Commission, the City and County of Denver School District No. 1, and the Colorado Commission on Indian Affairs.\n",
       "\n",
       "Note: The attendees were determined from present councilmembers via roll call.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OpenAI GPT-4 ì‚¬ìš©\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",  # ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"=== OpenAI GPT-4 ê²°ê³¼ ===\")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m8yo8hwgx7s",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ë¹„êµ ìš”ì•½\n",
    "\n",
    "| íŠ¹ì§• | Ollama (ë¡œì»¬) | OpenAI GPT-4 |\n",
    "|------|---------------|--------------|\n",
    "| **ë¹„ìš©** | ë¬´ë£Œ (í•˜ë“œì›¨ì–´ ë¹„ìš©ë§Œ) | ~$0.09/íšŒì˜ |\n",
    "| **í’ˆì§ˆ** | ì¢‹ìŒ | ìµœê³  |\n",
    "| **ì†ë„** | ë¹ ë¦„ (ë¡œì»¬) | ë³´í†µ (ë„¤íŠ¸ì›Œí¬) |\n",
    "| **í”„ë¼ì´ë²„ì‹œ** | ì™„ì „ ë³´ì•ˆ | ë°ì´í„° ì™¸ë¶€ ì „ì†¡ |\n",
    "| **ì„¤ì •** | ë³µì¡ | ê°„ë‹¨ |\n",
    "| **í•˜ë“œì›¨ì–´** | GPU í•„ìš” | ë¶ˆí•„ìš” |\n",
    "| **ì¶”ì²œ ìš©ë„** | ë¯¼ê°í•œ ì •ë³´, ëŒ€ëŸ‰ ì²˜ë¦¬ | ìµœê³  í’ˆì§ˆ í•„ìš”, ì†ŒëŸ‰ ì²˜ë¦¬ |\n",
    "\n",
    "### ì„ íƒ ê¸°ì¤€\n",
    "\n",
    "**Ollamaë¥¼ ì„ íƒí•˜ì„¸ìš”:**\n",
    "- ë¯¼ê°í•œ ì •ë³´ë¥¼ ë‹¤ë£¨ëŠ” ê²½ìš°\n",
    "- ì¼ì¼ 100+ íšŒì˜ë¡ ìƒì„± ì‹œ\n",
    "- ì¶©ë¶„í•œ GPU ë¦¬ì†ŒìŠ¤ ë³´ìœ \n",
    "\n",
    "**OpenAIë¥¼ ì„ íƒí•˜ì„¸ìš”:**\n",
    "- ìµœê³  í’ˆì§ˆì´ í•„ìš”í•œ ê²½ìš°\n",
    "- ì†ŒëŸ‰ì˜ íšŒì˜ë¡ (ì¼ 10ê°œ ë¯¸ë§Œ)\n",
    "- ë¹ ë¥¸ ì‹œì‘ì´ ì¤‘ìš”í•œ ê²½ìš°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qlb5nvuthcm",
   "metadata": {},
   "source": [
    "### ì˜µì…˜ 2: OpenAI GPT-4 (í´ë¼ìš°ë“œ API)\n",
    "\n",
    "**GPT-4**ëŠ” OpenAIì˜ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ì¥ì \n",
    "- ğŸ¯ **ìµœê³  í’ˆì§ˆ**: ê°€ì¥ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì¶œë ¥\n",
    "- ğŸš€ **ì¦‰ì‹œ ì‚¬ìš©**: ì„¤ì¹˜ ë¶ˆí•„ìš”\n",
    "- ğŸ”§ **ìœ ì§€ë³´ìˆ˜ ë¶ˆí•„ìš”**: OpenAIê°€ ê´€ë¦¬\n",
    "- ğŸ“ˆ **í™•ì¥ì„±**: ì‚¬ìš©ëŸ‰ì— ë”°ë¼ ìë™ í™•ì¥\n",
    "\n",
    "#### ë‹¨ì \n",
    "- ğŸ’° **ë¹„ìš©**: API ì‚¬ìš©ë£Œ ë°œìƒ (ì…ë ¥ $0.03/1K í† í°, ì¶œë ¥ $0.06/1K í† í°)\n",
    "- ğŸŒ **ë„¤íŠ¸ì›Œí¬ í•„ìš”**: ì¸í„°ë„· ì—°ê²° í•„ìˆ˜\n",
    "- ğŸ”’ **í”„ë¼ì´ë²„ì‹œ**: ë°ì´í„°ê°€ OpenAI ì„œë²„ë¡œ ì „ì†¡\n",
    "- â±ï¸ **ë ˆì´íŠ¸ ë¦¬ë°‹**: API í˜¸ì¶œ ì œí•œ ì¡´ì¬\n",
    "\n",
    "#### ë¹„ìš© ì˜ˆì¸¡\n",
    "ì¼ë°˜ì ì¸ íšŒì˜ë¡ (5ë¶„ ìŒì„±):\n",
    "- ì…ë ¥: ~2,000 í† í° ($0.06)\n",
    "- ì¶œë ¥: ~500 í† í° ($0.03)\n",
    "- **ì´ ë¹„ìš©**: ~$0.09/íšŒì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8391d6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (0.49.1)\n",
      "Requirement already satisfied: accelerate in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (1.12.0)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from bitsandbytes) (2.9.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from bitsandbytes) (2.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from bitsandbytes) (25.0)\n",
      "Requirement already satisfied: filelock in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from torch<3,>=2.3->bitsandbytes) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from torch<3,>=2.3->bitsandbytes) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
      "Requirement already satisfied: psutil in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from accelerate) (7.2.1)\n",
      "Requirement already satisfied: pyyaml in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: requests in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/windfree/workspace/ws.study/ai-engineering/.venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  --upgrade bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89a957f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n",
    "import torch\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0vs4objiql0n",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸´ íšŒì˜ë¡ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°\n",
    "def chunk_text(text, max_chars=10000, overlap=500):\n",
    "    \"\"\"\n",
    "    í…ìŠ¤íŠ¸ë¥¼ ê²¹ì¹¨ì´ ìˆëŠ” ì²­í¬ë¡œ ë¶„í• \n",
    "    \n",
    "    Args:\n",
    "        text: ë¶„í• í•  í…ìŠ¤íŠ¸\n",
    "        max_chars: ì²­í¬ë‹¹ ìµœëŒ€ ë¬¸ì ìˆ˜\n",
    "        overlap: ì²­í¬ ê°„ ê²¹ì¹¨ ë¬¸ì ìˆ˜\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        end = start + max_chars\n",
    "        chunks.append(text[start:end])\n",
    "        start = end - overlap  # ê²¹ì¹¨ ì ìš©\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# ì˜ˆì œ\n",
    "long_text = transcription  # ì‹¤ì œ ê¸´ íšŒì˜ë¡\n",
    "chunks = chunk_text(long_text, max_chars=5000)\n",
    "\n",
    "print(f\"=== ì²­í‚¹ ê²°ê³¼ ===\")\n",
    "print(f\"ì „ì²´ ê¸¸ì´: {len(long_text)} ë¬¸ì\")\n",
    "print(f\"ì²­í¬ ê°œìˆ˜: {len(chunks)}\")\n",
    "print(f\"ê° ì²­í¬ í¬ê¸°: {[len(c) for c in chunks]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4k9cv7ov5rc",
   "metadata": {},
   "source": [
    "### JSON ì¶œë ¥ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„±\n",
    "\n",
    "Markdown ëŒ€ì‹  JSONìœ¼ë¡œ ì¶œë ¥í•˜ë©´ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ì´ë‚˜ ìë™í™”ê°€ ì‰¬ì›Œì§‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88w7a45s6k",
   "metadata": {},
   "source": [
    "## 5ë‹¨ê³„: ì‹¤ì „ í™œìš© íŒ\n",
    "\n",
    "### ìë™í™” ì›Œí¬í”Œë¡œìš°\n",
    "\n",
    "ì‹¤ë¬´ì—ì„œ íšŒì˜ë¡ ìë™í™”ë¥¼ êµ¬ì¶•í•  ë•Œ ê³ ë ¤ì‚¬í•­:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m66ljrth6lf",
   "metadata": {},
   "source": [
    "### ë¹„ìš© ìµœì í™” ì „ëµ\n",
    "\n",
    "**1. ëª¨ë¸ ì„ íƒ ìµœì í™”**\n",
    "```python\n",
    "# ë‹¨ê³„ë³„ë¡œ ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©\n",
    "- ì´ˆì•ˆ: GPT-3.5-turbo ($0.002/1K)\n",
    "- ìµœì¢…: GPT-4 ($0.03/1K)\n",
    "- ëŒ€ëŸ‰: Ollama (ë¬´ë£Œ)\n",
    "```\n",
    "\n",
    "**2. í”„ë¡¬í”„íŠ¸ ìµœì í™”**\n",
    "- ë¶ˆí•„ìš”í•œ ì»¨í…ìŠ¤íŠ¸ ì œê±°\n",
    "- few-shot ì˜ˆì‹œ ìµœì†Œí™”\n",
    "- ì¶œë ¥ ê¸¸ì´ ì œí•œ ì„¤ì •\n",
    "\n",
    "**3. ìºì‹± í™œìš©**\n",
    "- ìœ ì‚¬í•œ íšŒì˜ëŠ” í…œí”Œë¦¿ ì¬ì‚¬ìš©\n",
    "- ìì£¼ ì‚¬ìš©í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ìºì‹±\n",
    "\n",
    "### í’ˆì§ˆ ê´€ë¦¬ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "âœ… **í•„ìˆ˜ í•­ëª© í™•ì¸:**\n",
    "- [ ] ì°¸ì„ì ëª…ë‹¨ ì™„ì „ì„±\n",
    "- [ ] ë‚ ì§œ/ì‹œê°„/ì¥ì†Œ ì •í™•ì„±\n",
    "- [ ] ì•¡ì…˜ ì•„ì´í…œ ë‹´ë‹¹ì ëª…ì‹œ\n",
    "- [ ] ê²°ì • ì‚¬í•­ ëª…í™•ì„±\n",
    "\n",
    "âœ… **ì¼ê´€ì„± ê²€ì¦:**\n",
    "- [ ] ë™ì¼ í˜•ì‹ ìœ ì§€\n",
    "- [ ] ì „ë¬¸ ìš©ì–´ ì¼ê´€ì„±\n",
    "- [ ] ì‹œì œ ì¼ê´€ì„±\n",
    "\n",
    "### ì—ëŸ¬ í•¸ë“¤ë§\n",
    "\n",
    "ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²°ì±…:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u4syt4q6wb",
   "metadata": {},
   "source": [
    "## ê²°ë¡ \n",
    "\n",
    "### í•µì‹¬ ìš”ì•½\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œ ë‹¤ë£¬ ë‚´ìš©:\n",
    "\n",
    "1. âœ… **Speech-to-Text**: OpenAI Whisperë¥¼ í†µí•œ ìŒì„± ì¸ì‹\n",
    "2. âœ… **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**: íš¨ê³¼ì ì¸ íšŒì˜ë¡ ìƒì„± í”„ë¡¬í”„íŠ¸\n",
    "3. âœ… **ë‹¤ì–‘í•œ LLM**: Ollama(ë¡œì»¬) vs OpenAI(í´ë¼ìš°ë“œ) ë¹„êµ\n",
    "4. âœ… **ê³ ê¸‰ ê¸°ëŠ¥**: ì²­í‚¹, Map-Reduce, JSON ì¶œë ¥\n",
    "5. âœ… **ì‹¤ì „ í™œìš©**: ìë™í™”, ë¹„ìš© ìµœì í™”, ì—ëŸ¬ í•¸ë“¤ë§\n",
    "\n",
    "### ì‹¤ë¬´ ë„ì… ë¡œë“œë§µ\n",
    "\n",
    "**Phase 1: MVP (1-2ì£¼)**\n",
    "- OpenAI APIë¡œ ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\n",
    "- ì†Œìˆ˜ì˜ íšŒì˜ì—ì„œ í…ŒìŠ¤íŠ¸\n",
    "- í’ˆì§ˆ ê²€ì¦ ë° í”„ë¡¬í”„íŠ¸ ê°œì„ \n",
    "\n",
    "**Phase 2: ìµœì í™” (2-4ì£¼)**\n",
    "- ë¹„ìš© ë¶„ì„ ë° ëª¨ë¸ ì„ íƒ\n",
    "- Ollama ë„ì… ê²€í†  (ë¯¼ê° ì •ë³´ìš©)\n",
    "- ìë™í™” ì›Œí¬í”Œë¡œìš° êµ¬ì¶•\n",
    "\n",
    "**Phase 3: í™•ì¥ (1-2ê°œì›”)**\n",
    "- ì „ì‚¬ ë°°í¬\n",
    "- ë‹¤êµ­ì–´ ì§€ì›\n",
    "- ì»¤ìŠ¤í…€ í…œí”Œë¦¿ ë° í†µí•©\n",
    "\n",
    "### ì˜ˆìƒ íš¨ê³¼\n",
    "\n",
    "ğŸ“Š **ì •ëŸ‰ì  íš¨ê³¼:**\n",
    "- â° íšŒì˜ë¡ ì‘ì„± ì‹œê°„ **80% ê°ì†Œ**\n",
    "- ğŸ’° ì¸ê±´ë¹„ ì ˆê°: ì›” 100íšŒì˜ Ã— 30ë¶„ = **50ì‹œê°„ ì ˆì•½**\n",
    "- ğŸ“ˆ íšŒì˜ë¡ ì‘ì„±ë¥  **95%+ ë‹¬ì„±**\n",
    "\n",
    "ğŸ¯ **ì •ì„±ì  íš¨ê³¼:**\n",
    "- ì¼ê´€ëœ í’ˆì§ˆê³¼ í˜•ì‹\n",
    "- ë¹ ë¥¸ ê³µìœ  ë° ê²€ìƒ‰ ê°€ëŠ¥\n",
    "- ì•¡ì…˜ ì•„ì´í…œ ì¶”ì  ê°œì„ \n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "**ë” ì•Œì•„ë³´ê¸°:**\n",
    "- [OpenAI Whisper Documentation](https://platform.openai.com/docs/guides/speech-to-text)\n",
    "- [Ollama Documentation](https://ollama.ai/docs)\n",
    "- [LangChain for Production](https://python.langchain.com/)\n",
    "\n",
    "**ì¶”ê°€ ê°œì„  ì•„ì´ë””ì–´:**\n",
    "- ì‹¤ì‹œê°„ íšŒì˜ë¡ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)\n",
    "- í™”ì ë¶„ë¦¬ (Speaker Diarization)\n",
    "- ê°ì • ë¶„ì„ ì¶”ê°€\n",
    "- Slack/Teams í†µí•©\n",
    "- ìë™ ì´ë©”ì¼ ë°œì†¡\n",
    "\n",
    "### ë§ˆì§€ë§‰ ì¡°ì–¸\n",
    "\n",
    "> \"ì™„ë²½í•œ ìë™í™”ë³´ë‹¤ 90% ìë™í™” + 10% ì¸ê°„ ê²€í† ê°€ ë” ì‹¤ìš©ì ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "AIê°€ ì´ˆì•ˆì„ ìƒì„±í•˜ê³ , ì‚¬ëŒì´ ìµœì¢… ê²€í† í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ì´ ìµœì ì˜ ê²°ê³¼ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Automating!** ğŸš€\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì´ ì—¬ëŸ¬ë¶„ì˜ íšŒì˜ë¡ ì‘ì„±ì„ í˜ì‹ í•˜ëŠ” ë° ë„ì›€ì´ ë˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6pn5q5bb3h",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²¬ê³ í•œ ì—ëŸ¬ í•¸ë“¤ë§\n",
    "import time\n",
    "from openai import OpenAI, OpenAIError\n",
    "\n",
    "def robust_meeting_minutes(audio_path, max_retries=3):\n",
    "    \"\"\"ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì•ˆì •ì ì¸ íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Speech-to-Text\n",
    "            with open(audio_path, \"rb\") as audio_file:\n",
    "                transcription = openai.audio.transcriptions.create(\n",
    "                    model=\"gpt-4o-mini-transcribe\",\n",
    "                    file=audio_file,\n",
    "                    response_format=\"text\"\n",
    "                )\n",
    "            \n",
    "            # íšŒì˜ë¡ ìƒì„±\n",
    "            client = OpenAI(api_key=openai_api_key)\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_message},\n",
    "                    {\"role\": \"user\", \"content\": f\"Generate minutes: {transcription}\"}\n",
    "                ],\n",
    "                timeout=60  # íƒ€ì„ì•„ì›ƒ ì„¤ì •\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except OpenAIError as e:\n",
    "            print(f\"ì‹œë„ {attempt + 1}/{max_retries} ì‹¤íŒ¨: {e}\")\n",
    "            \n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 2 ** attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„\n",
    "                print(f\"{wait_time}ì´ˆ í›„ ì¬ì‹œë„...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(\"ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼\")\n",
    "                raise\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}\")\n",
    "            return None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
    "            return None\n",
    "\n",
    "print(\"âœ“ ì—ëŸ¬ í•¸ë“¤ë§ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9g22pbnnrsb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜\n",
    "def meeting_minutes_pipeline(audio_path, output_format=\"markdown\"):\n",
    "    \"\"\"\n",
    "    ìŒì„± íŒŒì¼ë¶€í„° íšŒì˜ë¡ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸\n",
    "    \n",
    "    Args:\n",
    "        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ\n",
    "        output_format: \"markdown\" ë˜ëŠ” \"json\"\n",
    "    \n",
    "    Returns:\n",
    "        íšŒì˜ë¡ (ë¬¸ìì—´ ë˜ëŠ” ë”•ì…”ë„ˆë¦¬)\n",
    "    \"\"\"\n",
    "    print(\"1ë‹¨ê³„: ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜...\")\n",
    "    \n",
    "    # Speech-to-Text\n",
    "    with open(audio_path, \"rb\") as audio_file:\n",
    "        transcription = openai.audio.transcriptions.create(\n",
    "            model=\"gpt-4o-mini-transcribe\",\n",
    "            file=audio_file,\n",
    "            response_format=\"text\"\n",
    "        )\n",
    "    \n",
    "    print(f\"   âœ“ ë³€í™˜ ì™„ë£Œ ({len(transcription)} ë¬¸ì)\")\n",
    "    \n",
    "    # 2ë‹¨ê³„: íšŒì˜ë¡ ìƒì„±\n",
    "    print(\"2ë‹¨ê³„: íšŒì˜ë¡ ìƒì„±...\")\n",
    "    \n",
    "    if output_format == \"json\":\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": json_system_message},\n",
    "                {\"role\": \"user\", \"content\": f\"Generate minutes: {transcription}\"}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(response.choices[0].message.content)\n",
    "    else:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": f\"Generate minutes: {transcription}\"}\n",
    "            ]\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "    \n",
    "    print(\"   âœ“ íšŒì˜ë¡ ìƒì„± ì™„ë£Œ!\")\n",
    "    return result\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "# minutes = meeting_minutes_pipeline(\"./denver_extract.mp3\", output_format=\"json\")\n",
    "# print(json.dumps(minutes, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xhcow4hmpa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# JSON ì¶œë ¥ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸\n",
    "json_system_message = \"\"\"\n",
    "You are a meeting minutes generator. Output ONLY valid JSON with this structure:\n",
    "{\n",
    "  \"meeting_info\": {\n",
    "    \"date\": \"YYYY-MM-DD\",\n",
    "    \"location\": \"string\",\n",
    "    \"attendees\": [\"name1\", \"name2\"]\n",
    "  },\n",
    "  \"summary\": \"string\",\n",
    "  \"discussion_points\": [\"point1\", \"point2\"],\n",
    "  \"decisions\": [\"decision1\", \"decision2\"],\n",
    "  \"action_items\": [\n",
    "    {\"task\": \"string\", \"owner\": \"string\", \"deadline\": \"string\"}\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "json_prompt = f\"Generate meeting minutes as JSON from this transcript:\\n\\n{transcription[:2000]}\"\n",
    "\n",
    "# GPT-4ë¡œ JSON ìƒì„±\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": json_system_message},\n",
    "        {\"role\": \"user\", \"content\": json_prompt}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}  # JSON ëª¨ë“œ ê°•ì œ\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ íŒŒì‹±\n",
    "minutes_json = json.loads(response.choices[0].message.content)\n",
    "\n",
    "print(\"=== JSON í˜•ì‹ íšŒì˜ë¡ ===\")\n",
    "print(json.dumps(minutes_json, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "go5g1x8ofef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map-Reduce íŒ¨í„´ìœ¼ë¡œ ì²­í¬ ì²˜ë¦¬\n",
    "def summarize_chunks(chunks, client, model=\"gpt-4\"):\n",
    "    \"\"\"ê° ì²­í¬ë¥¼ ìš”ì•½í•œ í›„ ìµœì¢… ìš”ì•½ ìƒì„±\"\"\"\n",
    "    \n",
    "    # 1ë‹¨ê³„: ê° ì²­í¬ ìš”ì•½ (Map)\n",
    "    chunk_summaries = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"ì²­í¬ {i+1}/{len(chunks)} ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Summarize this meeting transcript segment.\"},\n",
    "                {\"role\": \"user\", \"content\": chunk}\n",
    "            ]\n",
    "        )\n",
    "        chunk_summaries.append(response.choices[0].message.content)\n",
    "    \n",
    "    # 2ë‹¨ê³„: ì²­í¬ ìš”ì•½ë“¤ì„ ê²°í•©í•˜ì—¬ ìµœì¢… ìš”ì•½ (Reduce)\n",
    "    combined = \"\\n\\n\".join(chunk_summaries)\n",
    "    \n",
    "    final_response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": f\"Create final minutes from these summaries:\\n\\n{combined}\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return final_response.choices[0].message.content\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ (ì£¼ì„ ì²˜ë¦¬ - ì‹¤í–‰ ì‹œ ë¹„ìš© ë°œìƒ)\n",
    "# client = OpenAI(api_key=openai_api_key)\n",
    "# final_minutes = summarize_chunks(chunks, client)\n",
    "# display(Markdown(final_minutes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jvuazzykj4p",
   "metadata": {},
   "source": [
    "## 4ë‹¨ê³„: ê³ ê¸‰ ê¸°ëŠ¥\n",
    "\n",
    "### ê¸´ íšŒì˜ë¡ ì²˜ë¦¬ (ì²­í‚¹ ì „ëµ)\n",
    "\n",
    "ëŒ€ë¶€ë¶„ì˜ LLMì€ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì œí•œì´ ìˆìŠµë‹ˆë‹¤. ê¸´ íšŒì˜ëŠ” ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
