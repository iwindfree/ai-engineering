{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08-1. 데이터셋 개념 정리\n",
    "\n",
    "머신러닝/딥러닝 모델을 학습시킬 때 데이터를 어떻게 나누고 활용하는지 알아봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터셋 분할의 필요성\n",
    "\n",
    "모델을 학습시킬 때 **모든 데이터를 학습에 사용하면 안 됩니다**. 왜일까요?\n",
    "\n",
    "- 모델이 학습 데이터를 \"암기\"할 수 있음 (과적합, Overfitting)\n",
    "- 새로운 데이터에 대한 성능을 측정할 수 없음\n",
    "- 하이퍼파라미터 튜닝 시 객관적인 기준이 없음\n",
    "\n",
    "이를 해결하기 위해 데이터를 **Training, Validation, Test** 세 가지로 나눕니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 세 가지 데이터셋\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                        전체 데이터셋                              │\n",
    "├───────────────────────────┬─────────────────┬───────────────────┤\n",
    "│      Training Set         │ Validation Set  │     Test Set      │\n",
    "│        (60-80%)           │    (10-20%)     │     (10-20%)      │\n",
    "│                           │                 │                   │\n",
    "│   모델 학습에 사용          │  하이퍼파라미터   │   최종 성능 평가    │\n",
    "│   (가중치 업데이트)         │  튜닝에 사용     │   (한 번만 사용)    │\n",
    "└───────────────────────────┴─────────────────┴───────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training Set (훈련 데이터)\n",
    "\n",
    "**목적**: 모델의 파라미터(가중치)를 학습시키는 데 사용\n",
    "\n",
    "**특징**:\n",
    "- 전체 데이터의 60-80%를 차지\n",
    "- 모델이 패턴을 학습하는 데 직접 사용됨\n",
    "- 여러 번 반복(epoch)하여 학습\n",
    "\n",
    "**비유**: 학생이 공부하는 교과서와 문제집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Validation Set (검증 데이터)\n",
    "\n",
    "**목적**: 학습 중 모델의 성능을 모니터링하고 하이퍼파라미터를 조정\n",
    "\n",
    "**특징**:\n",
    "- 전체 데이터의 10-20%를 차지\n",
    "- 학습에 직접 사용되지 않음 (가중치 업데이트 X)\n",
    "- 학습 과정에서 여러 번 평가에 사용\n",
    "- Early Stopping, 모델 선택 등에 활용\n",
    "\n",
    "**비유**: 학생이 공부 중간중간 푸는 모의고사\n",
    "\n",
    "**주요 용도**:\n",
    "- 과적합(Overfitting) 감지\n",
    "- 하이퍼파라미터 튜닝 (학습률, 배치 크기, 레이어 수 등)\n",
    "- 최적의 학습 시점(epoch) 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Test Set (테스트 데이터)\n",
    "\n",
    "**목적**: 최종 모델의 성능을 객관적으로 평가\n",
    "\n",
    "**특징**:\n",
    "- 전체 데이터의 10-20%를 차지\n",
    "- **단 한 번만** 사용 (모델 개발 완료 후)\n",
    "- 모델이 한 번도 보지 못한 데이터\n",
    "- 실제 서비스 환경에서의 성능을 추정\n",
    "\n",
    "**비유**: 학생이 치르는 실제 수능 시험\n",
    "\n",
    "**주의사항**:\n",
    "- Test Set으로 하이퍼파라미터를 튜닝하면 안 됨\n",
    "- Test Set 성능을 보고 모델을 수정하면 안 됨\n",
    "- 그렇게 하면 Test Set도 간접적으로 학습에 사용된 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 과적합(Overfitting)과 데이터셋의 관계\n",
    "\n",
    "```\n",
    "손실(Loss)\n",
    "    │\n",
    "    │   \\                          \n",
    "    │    \\    Training Loss        \n",
    "    │     \\__________________      \n",
    "    │      \\                       \n",
    "    │       \\   Validation Loss    \n",
    "    │        \\____                 \n",
    "    │             \\___/‾‾‾‾‾‾‾‾    ← 과적합 시작점\n",
    "    │                              \n",
    "    └──────────────────────────── Epoch\n",
    "          ↑\n",
    "     최적 중단점 (Early Stopping)\n",
    "```\n",
    "\n",
    "- **Training Loss**는 계속 감소\n",
    "- **Validation Loss**는 어느 시점부터 증가 → 과적합 신호\n",
    "- Validation Loss가 증가하기 시작하면 학습 중단 (Early Stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 실제 분할 비율 예시\n",
    "\n",
    "| 데이터 크기 | Training | Validation | Test | 비고 |\n",
    "|------------|----------|------------|------|------|\n",
    "| 소규모 (< 1만) | 60% | 20% | 20% | 검증 데이터 충분히 확보 |\n",
    "| 중규모 (1-10만) | 70% | 15% | 15% | 일반적인 비율 |\n",
    "| 대규모 (> 100만) | 98% | 1% | 1% | 1%도 충분한 샘플 수 |\n",
    "\n",
    "**핵심**: Validation/Test Set은 통계적으로 유의미한 크기면 충분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 코드 예시: 데이터셋 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 예시 데이터 생성\n",
    "X = np.random.randn(1000, 10)  # 1000개 샘플, 10개 특성\n",
    "y = np.random.randint(0, 2, 1000)  # 이진 분류 레이블\n",
    "\n",
    "# 1단계: Train+Val / Test 분할 (80% / 20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2단계: Train / Val 분할 (Train+Val의 75% / 25% → 전체의 60% / 20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training Set:   {len(X_train)} samples ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"Validation Set: {len(X_val)} samples ({len(X_val)/len(X)*100:.0f}%)\")\n",
    "print(f\"Test Set:       {len(X_test)} samples ({len(X_test)/len(X)*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LLM Fine-tuning에서의 데이터셋\n",
    "\n",
    "LLM을 파인튜닝할 때도 동일한 원칙이 적용됩니다.\n",
    "\n",
    "### OpenAI Fine-tuning 예시\n",
    "\n",
    "```python\n",
    "# OpenAI는 Training과 Validation 파일을 별도로 업로드\n",
    "training_file = client.files.create(\n",
    "    file=open(\"train.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "validation_file = client.files.create(\n",
    "    file=open(\"validation.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "# Fine-tuning 작업 생성\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    validation_file=validation_file.id,  # 선택사항이지만 권장\n",
    "    model=\"gpt-4o-mini-2024-07-18\"\n",
    ")\n",
    "```\n",
    "\n",
    "### JSONL 형식 예시\n",
    "\n",
    "```json\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Hello\"}, {\"role\": \"assistant\", \"content\": \"Hi there!\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"What is 2+2?\"}, {\"role\": \"assistant\", \"content\": \"4\"}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 요약\n",
    "\n",
    "| 데이터셋 | 목적 | 사용 시점 | 사용 횟수 |\n",
    "|---------|------|----------|----------|\n",
    "| **Training** | 모델 학습 (가중치 업데이트) | 학습 중 | 여러 번 (매 epoch) |\n",
    "| **Validation** | 하이퍼파라미터 튜닝, 과적합 감지 | 학습 중 | 여러 번 |\n",
    "| **Test** | 최종 성능 평가 | 학습 완료 후 | **단 한 번** |\n",
    "\n",
    "### 핵심 원칙\n",
    "\n",
    "1. **Test Set은 금고에 넣어두세요** - 최종 평가 전까지 절대 보지 않기\n",
    "2. **Validation Set으로 튜닝하세요** - 하이퍼파라미터 조정은 여기서\n",
    "3. **분할은 무작위로** - 데이터 편향 방지를 위해 shuffle 후 분할\n",
    "4. **재현성 확보** - random_state 설정으로 동일한 분할 보장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 추가 개념: K-Fold Cross Validation\n",
    "\n",
    "데이터가 적을 때 더 신뢰할 수 있는 검증을 위해 K-Fold 교차 검증을 사용합니다.\n",
    "\n",
    "```\n",
    "5-Fold Cross Validation 예시:\n",
    "\n",
    "Fold 1: [Val] [Train] [Train] [Train] [Train]\n",
    "Fold 2: [Train] [Val] [Train] [Train] [Train]\n",
    "Fold 3: [Train] [Train] [Val] [Train] [Train]\n",
    "Fold 4: [Train] [Train] [Train] [Val] [Train]\n",
    "Fold 5: [Train] [Train] [Train] [Train] [Val]\n",
    "\n",
    "→ 5번 학습하고 평균 성능 계산\n",
    "```\n",
    "\n",
    "- 모든 데이터가 한 번씩 검증에 사용됨\n",
    "- 더 안정적인 성능 추정 가능\n",
    "- 단점: 학습 시간이 K배 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# 예시 데이터\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "y = np.array([0, 1, 0, 1, 0])\n",
    "\n",
    "# 5-Fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Train indices: {train_idx}\")\n",
    "    print(f\"  Val indices:   {val_idx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
