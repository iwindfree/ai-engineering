{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2975b8b7",
   "metadata": {},
   "source": [
    "언어 모델 (Language Model) 은 텍스트 데이터의 통계 정보를 기반으로 자연어를 이해하고 생성하는 기능을 제공합니다.  \n",
    "### 핵심 원리\n",
    "언어모델의 기본 아이디어는 다음에 올 토큰 을 예측하는 것입니다. 예를 들어 '오늘 날씨가 정말 ____' 이라는 문장이 주어지면, 모델은 '좋다', '덥다' 같은 단어가 올 확률을 계산합니다. 이 단순한 원리가 충분히 큰 규모로 학습되면 놀라운 기능을 제공하게 됩니다. \n",
    "\n",
    "### 발전과정\n",
    "#### 통계적 언어모델 (n-gram)\n",
    "초기에는 이전 n개 단어만 보고 다음 단어를 예측했습니다. 단순하지만 긴 문맥을 이해하지 못하는 한계가 있었습니다. \n",
    "#### 신경망 기반 언어모델 (RNN/LSTM/GRU 등)\n",
    "단어를 벡터로 표현하고  순환신경망을 통해 확률을 계산하는 방식입니다.  순차적으로 정보를 처리하며, 더 긴 문맥을 기억할 수 있게 되었지만, 긴 문장 학습이 어려웠고 병렬 처리가 어려워서 학습 속도가 느리다는 단점이 존재합니다.\n",
    "#### Transformer (2017)\n",
    "* \"Attention is All You need\" 라는 논문에서 핵심 아이디어가 도출되었습니다. Attention 매커니즘을 도입해 문장 내 모든 단어간의 관계를 병렬로 처리하게 되었습니다. 긴 문맥 이해가 가능하게 되었고 학습 속도가 급상승하게 되었습니다. 성능의 비약적 향상으로 LLM 의 기반 아키텍처가 됩니다. \n",
    "\n",
    "이후에도 언어 모델은 계속 발전하는 모습을 보여주고 있습니다. \n",
    "\n",
    "### Token\n",
    "언어 모델의 기반 단위는 토큰입니다. 토큰은 모델에 따라 문자, 단어, 또는 단어의 일부가 될 수 있으며, GPT-4 인 경우는 토큰 하나의 평균 길이는 단어의 3/4 정도라고 말하고 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55b90a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15339, 11, 856, 836, 374, 10160, 10816, 13]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "text=\"hello, my name is windfree.\"\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b0e3095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID: 15339, Token Text:hello\n",
      "Token ID: 11, Token Text:,\n",
      "Token ID: 856, Token Text: my\n",
      "Token ID: 836, Token Text: name\n",
      "Token ID: 374, Token Text: is\n",
      "Token ID: 10160, Token Text: wind\n",
      "Token ID: 10816, Token Text:free\n",
      "Token ID: 13, Token Text:.\n"
     ]
    }
   ],
   "source": [
    "for token_id in tokens:\n",
    "    token_text = encoding.decode([token_id])\n",
    "    print(f\"Token ID: {token_id}, Token Text:{token_text}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89552109",
   "metadata": {},
   "source": [
    "토큰을 확인해 보았을 때 앞에 공백이 포함되는 경우를 확인할 수 있습니다. 이것은 위치 정보까지 토큰에 포함하기 위해서 입니다.  **토큰화** 는 원문을 모델이 정한 길이로 나누는 과정을 말하는 것이며 모델이 다룰 수 있는 토큰의 집합을 모델의 **어휘** 라고 부릅니다. 소수의 토큰을 사용해 많은 단어를 만들 수 있으며 GPT-4 의 어휘 크기는 100,256 개로 알려져 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68758f29",
   "metadata": {},
   "source": [
    "## LLM ->  STATELESS \n",
    "### Memory 라는 환상\n",
    "아래의 코드를 수행해보면 재미있는 현상을 발견할 수 있습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ce102e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"No API key was found\")\n",
    "else:\n",
    "    print(\"API key found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3948fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Windfree, nice to meet you! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "openai_client = OpenAI()\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello, My name is windfree.\"}]\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=messages,)\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
