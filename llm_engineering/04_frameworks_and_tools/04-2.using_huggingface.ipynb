{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Hugging Face ì™„ì „ ì •ë³µ: AI ëª¨ë¸ì˜ GitHub\n",
    "\n",
    "## ê°œìš”\n",
    "\n",
    "**Hugging Face**ëŠ” AI/ML ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” í”Œë«í¼ìœ¼ë¡œ, ìˆ˜ì‹­ë§Œ ê°œì˜ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì„ ì œê³µí•©ë‹ˆë‹¤. \"AI ëª¨ë¸ì˜ GitHub\"ë¼ê³  ë¶ˆë¦¬ë©°, ëˆ„êµ¬ë‚˜ ëª¨ë¸ì„ ê³µìœ í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "- âœ… Hugging Face ìƒíƒœê³„ ì´í•´ (Hub, Transformers, Datasets)\n",
    "- âœ… Pipeline APIë¡œ ë¹ ë¥´ê²Œ ëª¨ë¸ ì‚¬ìš©í•˜ê¸°\n",
    "- âœ… ë‹¤ì–‘í•œ NLP íƒœìŠ¤í¬ ì‹¤ìŠµ (í…ìŠ¤íŠ¸ ìƒì„±, ë¶„ë¥˜, ì„ë² ë”©)\n",
    "- âœ… ì»´í“¨í„° ë¹„ì „ ëª¨ë¸ í™œìš©\n",
    "- âœ… ëª¨ë¸ ê²€ìƒ‰ ë° ë‹¤ìš´ë¡œë“œ ë°©ë²•\n",
    "\n",
    "## ì™œ Hugging Faceì¸ê°€?\n",
    "\n",
    "| íŠ¹ì§• | ì„¤ëª… |\n",
    "|------|------|\n",
    "| **ë°©ëŒ€í•œ ëª¨ë¸ ì €ì¥ì†Œ** | 50ë§Œ+ ê°œì˜ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ |\n",
    "| **ì‰¬ìš´ ì‚¬ìš©ë²•** | 3ì¤„ ì½”ë“œë¡œ SOTA ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ |\n",
    "| **ì»¤ë®¤ë‹ˆí‹°** | í™œë°œí•œ ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹° |\n",
    "| **ë¬´ë£Œ** | ëŒ€ë¶€ë¶„ ëª¨ë¸ ë¬´ë£Œ ì‚¬ìš© ê°€ëŠ¥ |\n",
    "| **ë‹¤ì–‘í•œ íƒœìŠ¤í¬** | NLP, Vision, Audio, Multimodal ì§€ì› |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concepts",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Hugging Face í•µì‹¬ ê°œë…\n",
    "\n",
    "### 1.1 Hugging Face Hub\n",
    "\n",
    "**Hub**ëŠ” ëª¨ë¸, ë°ì´í„°ì…‹, Spaces(ë°ëª¨ ì•±)ë¥¼ í˜¸ìŠ¤íŒ…í•˜ëŠ” ì¤‘ì•™ ì €ì¥ì†Œì…ë‹ˆë‹¤.\n",
    "\n",
    "- ğŸ”— **URL**: https://huggingface.co\n",
    "- ğŸ“¦ **ëª¨ë¸**: GPT, BERT, LLaMA, Stable Diffusion ë“±\n",
    "- ğŸ“Š **ë°ì´í„°ì…‹**: GLUE, SQuAD, ImageNet ë“±\n",
    "- ğŸš€ **Spaces**: Gradio/Streamlit ê¸°ë°˜ ë°ëª¨ ì•±\n",
    "\n",
    "### 1.2 Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "**Transformers**ëŠ” ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ì‰½ê²Œ ë¡œë“œí•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” Python ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I love Hugging Face!\")\n",
    "# [{'label': 'POSITIVE', 'score': 0.9998}]\n",
    "```\n",
    "\n",
    "### 1.3 ì£¼ìš” êµ¬ì„± ìš”ì†Œ\n",
    "\n",
    "| êµ¬ì„± ìš”ì†Œ | ì—­í•  |\n",
    "|----------|------|\n",
    "| **Model** | ì‚¬ì „ í•™ìŠµëœ ì‹ ê²½ë§ (weights) |\n",
    "| **Tokenizer** | í…ìŠ¤íŠ¸ â†” í† í° ë³€í™˜ |\n",
    "| **Pipeline** | ì „ì²˜ë¦¬-ì¶”ë¡ -í›„ì²˜ë¦¬ë¥¼ í•œ ë²ˆì— |\n",
    "| **Trainer** | ëª¨ë¸ í•™ìŠµ/íŒŒì¸íŠœë‹ ë„êµ¬ |\n",
    "| **Dataset** | ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ê³  ì„í¬íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ ìŠ¤í‚µ)\n",
    "# !pip install transformers datasets pillow requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from transformers import pipeline, AutoModel, AutoTokenizer\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Pipeline API: ê°€ì¥ ì‰¬ìš´ ì‹œì‘ ë°©ë²•\n",
    "\n",
    "**Pipeline**ì€ ì „ì²˜ë¦¬, ëª¨ë¸ ì¶”ë¡ , í›„ì²˜ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ê³ ìˆ˜ì¤€ APIì…ë‹ˆë‹¤.\n",
    "\n",
    "### Pipeline ì‚¬ìš© íë¦„\n",
    "\n",
    "```\n",
    "ì…ë ¥ í…ìŠ¤íŠ¸ â†’ Tokenizer â†’ Model â†’ Post-processing â†’ ê²°ê³¼\n",
    "```\n",
    "\n",
    "ëª¨ë“  ê³¼ì •ì´ ìë™í™”ë˜ì–´ **3ì¤„ ì½”ë“œ**ë¡œ SOTA ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sentiment",
   "metadata": {},
   "source": [
    "### 3.1 ê°ì • ë¶„ì„ (Sentiment Analysis)\n",
    "\n",
    "í…ìŠ¤íŠ¸ì˜ ê°ì •(ê¸ì •/ë¶€ì •)ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "#### Pipelineì´ë€?\n",
    "\n",
    "**Pipeline**ì€ ë³µì¡í•œ ML ì›Œí¬í”Œë¡œìš°ë¥¼ ë‹¨ìˆœí™”í•˜ëŠ” ê³ ìˆ˜ì¤€ APIì…ë‹ˆë‹¤. ë‚´ë¶€ì ìœ¼ë¡œ ë‹¤ìŒ 3ë‹¨ê³„ë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤:\n",
    "\n",
    "```\n",
    "1. ì „ì²˜ë¦¬ (Preprocessing)\n",
    "   â””â”€ Tokenizer: í…ìŠ¤íŠ¸ â†’ í† í° IDë¡œ ë³€í™˜\n",
    "   â””â”€ ë°°ì¹˜ ì²˜ë¦¬, íŒ¨ë”©, attention mask ìƒì„±\n",
    "\n",
    "2. ëª¨ë¸ ì¶”ë¡  (Model Inference)\n",
    "   â””â”€ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì— í† í° ì…ë ¥\n",
    "   â””â”€ ê° í´ë˜ìŠ¤ì— ëŒ€í•œ logits(ì ìˆ˜) ê³„ì‚°\n",
    "\n",
    "3. í›„ì²˜ë¦¬ (Post-processing)\n",
    "   â””â”€ Softmaxë¡œ í™•ë¥  ë³€í™˜\n",
    "   â””â”€ ê²°ê³¼ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜\n",
    "```\n",
    "\n",
    "#### Pipelineì˜ ì¥ì \n",
    "\n",
    "âœ… **ê°„í¸í•¨**: 3ì¤„ ì½”ë“œë¡œ SOTA ëª¨ë¸ ì‚¬ìš©  \n",
    "âœ… **ìë™í™”**: ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ìë™ ì²˜ë¦¬  \n",
    "âœ… **ìœ ì—°ì„±**: ë‹¤ì–‘í•œ ëª¨ë¸ë¡œ ì‰½ê²Œ êµì²´ ê°€ëŠ¥  \n",
    "âœ… **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ ì…ë ¥ ë™ì‹œ ì²˜ë¦¬ ì§€ì›"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hbl6s8tlxng",
   "metadata": {},
   "source": [
    "#### Pipeline ìƒì„± ì˜µì…˜\n",
    "\n",
    "`pipeline()` í•¨ìˆ˜ëŠ” ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì›í•©ë‹ˆë‹¤:\n",
    "\n",
    "| íŒŒë¼ë¯¸í„° | ì„¤ëª… | ì˜ˆì‹œ |\n",
    "|---------|------|------|\n",
    "| `task` | ìˆ˜í–‰í•  íƒœìŠ¤í¬ (í•„ìˆ˜) | `\"sentiment-analysis\"` |\n",
    "| `model` | ì‚¬ìš©í•  ëª¨ë¸ (ì„ íƒ) | `\"distilbert-base-uncased\"` |\n",
    "| `tokenizer` | ì»¤ìŠ¤í…€ í† í¬ë‚˜ì´ì € | `AutoTokenizer.from_pretrained(...)` |\n",
    "| `device` | ì‹¤í–‰ ë””ë°”ì´ìŠ¤ | `0` (GPU), `-1` (CPU) |\n",
    "| `batch_size` | ë°°ì¹˜ í¬ê¸° | `8`, `16` |\n",
    "\n",
    "**ì˜ˆì‹œ:**\n",
    "\n",
    "```python\n",
    "# ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš© (ìë™ ì„ íƒ)\n",
    "pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# íŠ¹ì • ëª¨ë¸ ì§€ì •\n",
    "pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "# GPU ì‚¬ìš©\n",
    "pipeline(\"sentiment-analysis\", device=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sentiment-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
      "ğŸ”§ í† í¬ë‚˜ì´ì €: DistilBertTokenizerFast\n",
      "\n",
      "============================================================\n",
      "ê°ì • ë¶„ì„ ê²°ê³¼\n",
      "============================================================\n",
      "\n",
      "ğŸ˜Š í…ìŠ¤íŠ¸: \"I absolutely love this product! It's amazing!\"\n",
      "   ê°ì •: POSITIVE\n",
      "   í™•ë¥ : 0.9999 (99.99%)\n",
      "\n",
      "ğŸ˜ í…ìŠ¤íŠ¸: \"This is the worst experience ever.\"\n",
      "   ê°ì •: NEGATIVE\n",
      "   í™•ë¥ : 0.9998 (99.98%)\n",
      "\n",
      "ğŸ˜ í…ìŠ¤íŠ¸: \"It's okay, nothing special.\"\n",
      "   ê°ì •: NEGATIVE\n",
      "   í™•ë¥ : 0.8190 (81.90%)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 1ë‹¨ê³„: Pipeline ìƒì„±\n",
    "# ============================================\n",
    "\n",
    "# task=\"sentiment-analysis\"ë¥¼ ì§€ì •í•˜ë©´ ìë™ìœ¼ë¡œ:\n",
    "# - ì í•©í•œ ëª¨ë¸ ì„ íƒ (ê¸°ë³¸: distilbert-base-uncased-finetuned-sst-2-english)\n",
    "# - í•´ë‹¹ ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "# - ì¶”ë¡  íŒŒì´í”„ë¼ì¸ êµ¬ì„±\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "print(f\"ğŸ“¦ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: {sentiment_analyzer.model.name_or_path}\")\n",
    "print(f\"ğŸ”§ í† í¬ë‚˜ì´ì €: {sentiment_analyzer.tokenizer.__class__.__name__}\\n\")\n",
    "\n",
    "# ============================================\n",
    "# 2ë‹¨ê³„: ì…ë ¥ ë°ì´í„° ì¤€ë¹„\n",
    "# ============================================\n",
    "\n",
    "texts = [\n",
    "    \"I absolutely love this product! It's amazing!\",  # ê°•í•œ ê¸ì •\n",
    "    \"This is the worst experience ever.\",             # ê°•í•œ ë¶€ì •\n",
    "    \"It's okay, nothing special.\"                      # ì¤‘ë¦½ì \n",
    "]\n",
    "\n",
    "# ============================================\n",
    "# 3ë‹¨ê³„: ê°ì • ë¶„ì„ ì‹¤í–‰\n",
    "# ============================================\n",
    "\n",
    "# Pipelineì— í…ìŠ¤íŠ¸(ë˜ëŠ” í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸)ë¥¼ ì „ë‹¬í•˜ë©´:\n",
    "# - ìë™ìœ¼ë¡œ í† í°í™”\n",
    "# - ëª¨ë¸ ì¶”ë¡ \n",
    "# - ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜\n",
    "sentiment_results = sentiment_analyzer(texts)\n",
    "\n",
    "# ë‚´ë¶€ì ìœ¼ë¡œ ì¼ì–´ë‚˜ëŠ” ì¼:\n",
    "# 1. Tokenizer: \"I love this\" â†’ [101, 1045, 2293, 2023, 102]\n",
    "# 2. Model: [í† í° IDs] â†’ logits [-2.5, 4.8] (NEGATIVE, POSITIVE ì ìˆ˜)\n",
    "# 3. Softmax: logits â†’ í™•ë¥  [0.0002, 0.9998]\n",
    "# 4. Argmax: ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ë ˆì´ë¸” ì„ íƒ â†’ \"POSITIVE\"\n",
    "\n",
    "# ============================================\n",
    "# 4ë‹¨ê³„: ê²°ê³¼ ì¶œë ¥\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ê°ì • ë¶„ì„ ê²°ê³¼\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for text, sentiment_result in zip(texts, sentiment_results):\n",
    "    label = sentiment_result['label']        # ì˜ˆì¸¡ëœ ë ˆì´ë¸” (POSITIVE/NEGATIVE)\n",
    "    score = sentiment_result['score']        # í•´ë‹¹ ë ˆì´ë¸”ì˜ í™•ë¥  (0~1)\n",
    "    \n",
    "    # ì´ëª¨ì§€ ì¶”ê°€\n",
    "    emoji = \"ğŸ˜Š\" if label == \"POSITIVE\" else \"ğŸ˜\"\n",
    "    \n",
    "    print(f\"\\n{emoji} í…ìŠ¤íŠ¸: \\\"{text}\\\"\")\n",
    "    print(f\"   ê°ì •: {label}\")\n",
    "    print(f\"   í™•ë¥ : {score:.4f} ({score*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e106urdl1c",
   "metadata": {},
   "source": [
    "#### ê²°ê³¼ êµ¬ì¡° ì´í•´í•˜ê¸°\n",
    "\n",
    "Pipelineì´ ë°˜í™˜í•˜ëŠ” ê²°ê³¼ëŠ” **ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬**ì…ë‹ˆë‹¤:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {'label': 'POSITIVE', 'score': 0.9998},\n",
    "    {'label': 'NEGATIVE', 'score': 0.9995}\n",
    "]\n",
    "```\n",
    "\n",
    "**ê° ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°:**\n",
    "\n",
    "- `label`: ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ë ˆì´ë¸” (ë¬¸ìì—´)\n",
    "  - ê°ì • ë¶„ì„ì˜ ê²½ìš°: `\"POSITIVE\"` ë˜ëŠ” `\"NEGATIVE\"`\n",
    "  - ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥¸ ë ˆì´ë¸” ì‚¬ìš© ê°€ëŠ¥\n",
    "  \n",
    "- `score`: í•´ë‹¹ ë ˆì´ë¸”ì˜ í™•ë¥  (float, 0~1)\n",
    "  - ëª¨ë¸ì´ í•´ë‹¹ ë ˆì´ë¸”ì— ëŒ€í•´ ì–¼ë§ˆë‚˜ í™•ì‹ í•˜ëŠ”ì§€\n",
    "  - 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ í™•ì‹ ë„\n",
    "  - Softmax í•¨ìˆ˜ë¡œ ê³„ì‚°ë¨\n",
    "\n",
    "**ì£¼ì˜ì‚¬í•­:**\n",
    "\n",
    "âš ï¸ `score`ëŠ” í•­ìƒ **ì„ íƒëœ ë ˆì´ë¸”**ì˜ í™•ë¥ ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë ˆì´ë¸”ì˜ í™•ë¥ ì€ `1 - score`ê°€ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ë‹¤ì¤‘ í´ë˜ìŠ¤ì¸ ê²½ìš°)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbit72kkdcu",
   "metadata": {},
   "source": [
    "#### ê³ ê¸‰ ì˜µì…˜: ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©í•˜ê¸°\n",
    "\n",
    "ê¸°ë³¸ ëª¨ë¸ ëŒ€ì‹  ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "p8w46ccw9br",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ì  ì²™ë„ ê°ì • ë¶„ì„ (ë‹¤êµ­ì–´ ì§€ì›):\n",
      "\n",
      "í…ìŠ¤íŠ¸: This restaurant is amazing!\n",
      "í‰ê°€: 5 stars â­â­â­â­â­\n",
      "í™•ë¥ : 0.8884\n",
      "\n",
      "í…ìŠ¤íŠ¸: ì´ ì œí’ˆì€ ì •ë§ í›Œë¥­í•´ìš”!\n",
      "í‰ê°€: 5 stars â­â­â­â­â­\n",
      "í™•ë¥ : 0.7375\n",
      "\n",
      "í…ìŠ¤íŠ¸: æœ€é«˜ã®ã‚µãƒ¼ãƒ“ã‚¹ã§ã™!\n",
      "í‰ê°€: 5 stars â­â­â­â­â­\n",
      "í™•ë¥ : 0.9166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5ì  ì²™ë„ ê°ì • ë¶„ì„ ëª¨ë¸ ì‚¬ìš© (1~5 stars)\n",
    "# ì´ ëª¨ë¸ì€ POSITIVE/NEGATIVE ëŒ€ì‹  1~5ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤\n",
    "\n",
    "star_classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    ")\n",
    "\n",
    "# ë‹¤êµ­ì–´ ì§€ì› (ì˜ì–´, í•œêµ­ì–´, ì¼ë³¸ì–´ ë“±)\n",
    "multilingual_texts = [\n",
    "    \"This restaurant is amazing!\",\n",
    "    \"ì´ ì œí’ˆì€ ì •ë§ í›Œë¥­í•´ìš”!\",\n",
    "    \"æœ€é«˜ã®ã‚µãƒ¼ãƒ“ã‚¹ã§ã™!\"\n",
    "]\n",
    "\n",
    "print(\"5ì  ì²™ë„ ê°ì • ë¶„ì„ (ë‹¤êµ­ì–´ ì§€ì›):\\n\")\n",
    "for text in multilingual_texts:\n",
    "    # Pipeline í˜¸ì¶œ: ë‹¨ì¼ í…ìŠ¤íŠ¸ â†’ [{'label': '...', 'score': ...}]\n",
    "    # [0]ìœ¼ë¡œ ì²« ë²ˆì§¸(ê·¸ë¦¬ê³  ìœ ì¼í•œ) ê²°ê³¼ ì¶”ì¶œ\n",
    "    star_result = star_classifier(text)[0]\n",
    "    \n",
    "    # labelì€ \"5 stars\" ê°™ì€ ë¬¸ìì—´\n",
    "    # [0]ìœ¼ë¡œ ì²« ë²ˆì§¸ ë¬¸ì('5')ë¥¼ ì¶”ì¶œí•˜ì—¬ ë³„ ê°œìˆ˜ ê²°ì •\n",
    "    stars = \"â­\" * int(star_result['label'][0])\n",
    "    \n",
    "    print(f\"í…ìŠ¤íŠ¸: {text}\")\n",
    "    print(f\"í‰ê°€: {star_result['label']} {stars}\")\n",
    "    print(f\"í™•ë¥ : {star_result['score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "text-generation",
   "metadata": {},
   "source": [
    "### 3.2 í…ìŠ¤íŠ¸ ìƒì„± (Text Generation)\n",
    "\n",
    "ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generation-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4da1e2b8124af1a2c31a0ea5cdb07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# í…ìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸ (GPT-2 ëª¨ë¸ ì‚¬ìš©)\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸\n",
    "prompt = \"Artificial intelligence will\"\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ìƒì„±\n",
    "generated_texts = generator(\n",
    "    prompt,\n",
    "    max_length=50,      # ìµœëŒ€ í† í° ìˆ˜\n",
    "    num_return_sequences=2,  # ìƒì„±í•  ë¬¸ì¥ ê°œìˆ˜\n",
    "    temperature=0.8     # ì°½ì˜ì„± ì¡°ì ˆ (ë†’ì„ìˆ˜ë¡ ë‹¤ì–‘í•¨)\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"í”„ë¡¬í”„íŠ¸: {prompt}\\n\")\n",
    "for i, gen_result in enumerate(generated_texts, 1):\n",
    "    print(f\"ìƒì„± {i}: {gen_result['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qa",
   "metadata": {},
   "source": [
    "### 3.3 ì§ˆë¬¸ ë‹µë³€ (Question Answering)\n",
    "\n",
    "ë¬¸ë§¥(context)ì´ ì£¼ì–´ì¡Œì„ ë•Œ, ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qa-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§ˆë¬¸ ë‹µë³€ íŒŒì´í”„ë¼ì¸\n",
    "qa_pipeline = pipeline(\"question-answering\")\n",
    "\n",
    "# ë¬¸ë§¥ê³¼ ì§ˆë¬¸\n",
    "context = \"\"\"\n",
    "Hugging Face is a company that provides tools and infrastructure for machine learning.\n",
    "It was founded in 2016 and is based in New York City. The company is known for its\n",
    "Transformers library, which allows developers to easily use pre-trained models.\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"When was Hugging Face founded?\",\n",
    "    \"Where is Hugging Face based?\",\n",
    "    \"What is Hugging Face known for?\"\n",
    "]\n",
    "\n",
    "# ê° ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ì¶”ì¶œ\n",
    "for question in questions:\n",
    "    qa_result = qa_pipeline(question=question, context=context)\n",
    "    print(f\"ì§ˆë¬¸: {question}\")\n",
    "    print(f\"ë‹µë³€: {qa_result['answer']} (í™•ë¥ : {qa_result['score']:.4f})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "translation",
   "metadata": {},
   "source": [
    "### 3.4 ë²ˆì—­ (Translation)\n",
    "\n",
    "ë‹¤ì–‘í•œ ì–¸ì–´ ê°„ ë²ˆì—­ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "translation-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ì–´ â†’ í”„ë‘ìŠ¤ì–´ ë²ˆì—­\n",
    "translator = pipeline(\"translation_en_to_fr\")\n",
    "\n",
    "text = \"Hugging Face is an amazing platform for AI developers.\"\n",
    "translation = translator(text)\n",
    "\n",
    "print(f\"ì›ë¬¸ (ì˜ì–´): {text}\")\n",
    "print(f\"ë²ˆì—­ (í”„ë‘ìŠ¤ì–´): {translation[0]['translation_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summarization",
   "metadata": {},
   "source": [
    "### 3.5 ìš”ì•½ (Summarization)\n",
    "\n",
    "ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì§§ê²Œ ìš”ì•½í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summarization-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìš”ì•½ íŒŒì´í”„ë¼ì¸\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# ê¸´ í…ìŠ¤íŠ¸\n",
    "article = \"\"\"\n",
    "The transformer architecture has revolutionized natural language processing since its \n",
    "introduction in 2017. Unlike previous recurrent neural networks, transformers process \n",
    "entire sequences in parallel using self-attention mechanisms. This allows them to \n",
    "capture long-range dependencies more effectively. Models like BERT, GPT, and T5 are \n",
    "all based on the transformer architecture. These models have achieved state-of-the-art \n",
    "results on numerous NLP benchmarks and are now widely used in production systems.\n",
    "\"\"\"\n",
    "\n",
    "# ìš”ì•½ ìƒì„±\n",
    "summary = summarizer(article, max_length=50, min_length=20)\n",
    "\n",
    "print(\"ì›ë¬¸:\")\n",
    "print(article.strip())\n",
    "print(\"\\nìš”ì•½:\")\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image-classification",
   "metadata": {},
   "source": [
    "### 3.6 ì´ë¯¸ì§€ ë¶„ë¥˜ (Image Classification)\n",
    "\n",
    "Hugging FaceëŠ” NLPë¿ë§Œ ì•„ë‹ˆë¼ ì»´í“¨í„° ë¹„ì „ ëª¨ë¸ë„ ì œê³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "image-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸\n",
    "image_classifier = pipeline(\"image-classification\")\n",
    "\n",
    "# ìƒ˜í”Œ ì´ë¯¸ì§€ URL (ê³ ì–‘ì´ ì‚¬ì§„)\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    "response = requests.get(url)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "\n",
    "# ì´ë¯¸ì§€ ë¶„ë¥˜\n",
    "image_predictions = image_classifier(image)\n",
    "\n",
    "# ìƒìœ„ 3ê°œ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ì´ë¯¸ì§€ ë¶„ë¥˜ ê²°ê³¼:\")\n",
    "for pred in image_predictions[:3]:\n",
    "    print(f\"- {pred['label']}: {pred['score']:.4f}\")\n",
    "\n",
    "# ì´ë¯¸ì§€ í‘œì‹œ\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ê³ ê¸‰ ì‚¬ìš©ë²•: Tokenizerì™€ Model ì§ì ‘ ì‚¬ìš©\n",
    "\n",
    "Pipelineì€ í¸ë¦¬í•˜ì§€ë§Œ, ì„¸ë°€í•œ ì œì–´ê°€ í•„ìš”í•  ë•ŒëŠ” **Tokenizer**ì™€ **Model**ì„ ì§ì ‘ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### 4.1 Tokenizer ì´í•´í•˜ê¸°\n",
    "\n",
    "TokenizerëŠ” í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ«ì(í† í° ID)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tokenizer-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "text = \"Hugging Face is awesome!\"\n",
    "\n",
    "# í† í°í™”\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(f\"í† í°: {tokens}\")\n",
    "\n",
    "# í† í° IDë¡œ ë³€í™˜\n",
    "token_ids = tokenizer.encode(text)\n",
    "print(f\"í† í° ID: {token_ids}\")\n",
    "\n",
    "# IDë¥¼ ë‹¤ì‹œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "decoded = tokenizer.decode(token_ids)\n",
    "print(f\"ë””ì½”ë”©: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedding",
   "metadata": {},
   "source": [
    "### 4.2 ì„ë² ë”© ìƒì„± (Sentence Embeddings)\n",
    "\n",
    "í…ìŠ¤íŠ¸ë¥¼ ê³ ì • ê¸¸ì´ì˜ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ìœ ì‚¬ë„ ê³„ì‚°, ê²€ìƒ‰ ë“±ì— í™œìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedding-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Sentence-BERT ëª¨ë¸ ë¡œë“œ\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# ì„ë² ë”© ìƒì„± í•¨ìˆ˜\n",
    "def get_embedding(text):\n",
    "    # í† í°í™”\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    # ëª¨ë¸ ì¶”ë¡ \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Mean pooling\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# ì˜ˆì œ ë¬¸ì¥ë“¤\n",
    "sentences = [\n",
    "    \"I love machine learning\",\n",
    "    \"I enjoy artificial intelligence\",\n",
    "    \"The weather is nice today\"\n",
    "]\n",
    "\n",
    "# ì„ë² ë”© ìƒì„±\n",
    "embeddings = [get_embedding(sent) for sent in sentences]\n",
    "\n",
    "# ì„ë² ë”© í¬ê¸° í™•ì¸\n",
    "print(f\"ì„ë² ë”© ì°¨ì›: {embeddings[0].shape}\")\n",
    "\n",
    "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "sim_01 = cosine_similarity(embeddings[0], embeddings[1]).item()\n",
    "sim_02 = cosine_similarity(embeddings[0], embeddings[2]).item()\n",
    "\n",
    "print(f\"\\nìœ ì‚¬ë„:\")\n",
    "print(f\"'{sentences[0]}' vs '{sentences[1]}': {sim_01:.4f}\")\n",
    "print(f\"'{sentences[0]}' vs '{sentences[2]}': {sim_02:.4f}\")\n",
    "print(f\"\\nğŸ’¡ ì²« ë‘ ë¬¸ì¥(ML ê´€ë ¨)ì´ ë” ìœ ì‚¬í•©ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-search",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ëª¨ë¸ íƒìƒ‰ ë° ì„ íƒ\n",
    "\n",
    "### 5.1 Hubì—ì„œ ëª¨ë¸ ê²€ìƒ‰\n",
    "\n",
    "Hugging Face Hubì—ì„œëŠ” íƒœìŠ¤í¬, ì–¸ì–´, ë¼ì´ì„¼ìŠ¤ ë“±ìœ¼ë¡œ ëª¨ë¸ì„ í•„í„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì›¹ ì¸í„°í˜ì´ìŠ¤ë¡œ ê²€ìƒ‰:**\n",
    "- ğŸ”— https://huggingface.co/models\n",
    "- ì™¼ìª½ í•„í„°ë¡œ íƒœìŠ¤í¬, ë¼ì´ë¸ŒëŸ¬ë¦¬, ì–¸ì–´ ì„ íƒ\n",
    "- ì¸ê¸°ìˆœ, ìµœì‹ ìˆœ ì •ë ¬ ê°€ëŠ¥\n",
    "\n",
    "**Pythonìœ¼ë¡œ ê²€ìƒ‰:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "search-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¸ê¸° ê°ì • ë¶„ì„ ëª¨ë¸ TOP 5:\n",
      "1. cross-encoder/ms-marco-MiniLM-L6-v2\n",
      "2. cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "3. facebook/bart-large-mnli\n",
      "4. distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
      "5. BAAI/bge-reranker-v2-m3\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_models\n",
    "\n",
    "# ê°ì • ë¶„ì„ ëª¨ë¸ ê²€ìƒ‰ (ìƒìœ„ 5ê°œ)\n",
    "models = list_models(\n",
    "    filter=\"text-classification\",\n",
    "    sort=\"downloads\",\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "print(\"ì¸ê¸° ê°ì • ë¶„ì„ ëª¨ë¸ TOP 5:\")\n",
    "for i, model in enumerate(models, 1):\n",
    "    print(f\"{i}. {model.modelId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-info",
   "metadata": {},
   "source": [
    "### 5.2 ëª¨ë¸ ì •ë³´ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "info-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ID: openai-community/gpt2\n",
      "íŒŒì´í”„ë¼ì¸ íƒœê·¸: text-generation\n",
      "ë‹¤ìš´ë¡œë“œ ìˆ˜: 6,397,931\n",
      "ë¼ì´ë¸ŒëŸ¬ë¦¬: transformers\n",
      "ë¼ì´ì„¼ìŠ¤: mit\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import model_info\n",
    "\n",
    "# GPT-2 ëª¨ë¸ ì •ë³´ ì¡°íšŒ\n",
    "info = model_info(\"gpt2\")\n",
    "\n",
    "print(f\"ëª¨ë¸ ID: {info.modelId}\")\n",
    "print(f\"íŒŒì´í”„ë¼ì¸ íƒœê·¸: {info.pipeline_tag}\")\n",
    "print(f\"ë‹¤ìš´ë¡œë“œ ìˆ˜: {info.downloads:,}\")\n",
    "print(f\"ë¼ì´ë¸ŒëŸ¬ë¦¬: {info.library_name}\")\n",
    "print(f\"ë¼ì´ì„¼ìŠ¤: {info.cardData.get('license', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caching",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ìºì‹±\n",
    "\n",
    "### 6.1 ìë™ ìºì‹±\n",
    "\n",
    "Hugging FaceëŠ” ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ìºì‹œí•©ë‹ˆë‹¤:\n",
    "- **ìœ„ì¹˜**: `~/.cache/huggingface/hub/`\n",
    "- ë™ì¼ ëª¨ë¸ ì¬ì‚¬ìš© ì‹œ ë‹¤ìš´ë¡œë“œ ìŠ¤í‚µ\n",
    "\n",
    "### 6.2 ì˜¤í”„ë¼ì¸ ì‚¬ìš©\n",
    "\n",
    "ëª¨ë¸ì„ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì¸í„°ë„· ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offline-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "print(\"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ì´ ë¡œì»¬ ìºì‹œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"ìºì‹œ ìœ„ì¹˜: ~/.cache/huggingface/hub/\")\n",
    "\n",
    "# ì´ì œ ì˜¤í”„ë¼ì¸ì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, local_files_only=True)\n",
    "# model = AutoModel.from_pretrained(model_name, local_files_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tasks-overview",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. ì§€ì›í•˜ëŠ” ì£¼ìš” íƒœìŠ¤í¬\n",
    "\n",
    "Hugging FaceëŠ” ë‹¤ì–‘í•œ AI íƒœìŠ¤í¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤:\n",
    "\n",
    "### NLP (ìì—°ì–´ ì²˜ë¦¬)\n",
    "\n",
    "| íƒœìŠ¤í¬ | Pipeline ì´ë¦„ | ì˜ˆì‹œ |\n",
    "|--------|--------------|------|\n",
    "| í…ìŠ¤íŠ¸ ë¶„ë¥˜ | `text-classification` | ê°ì • ë¶„ì„, ìŠ¤íŒ¸ ë¶„ë¥˜ |\n",
    "| í† í° ë¶„ë¥˜ | `token-classification` | ê°œì²´ëª… ì¸ì‹(NER) |\n",
    "| ì§ˆë¬¸ ë‹µë³€ | `question-answering` | SQuAD ìŠ¤íƒ€ì¼ QA |\n",
    "| í…ìŠ¤íŠ¸ ìƒì„± | `text-generation` | GPT ìŠ¤íƒ€ì¼ ìƒì„± |\n",
    "| ìš”ì•½ | `summarization` | ë‰´ìŠ¤ ê¸°ì‚¬ ìš”ì•½ |\n",
    "| ë²ˆì—­ | `translation_XX_to_YY` | ë‹¤êµ­ì–´ ë²ˆì—­ |\n",
    "| ì±„ìš°ê¸° | `fill-mask` | BERT ìŠ¤íƒ€ì¼ ë§ˆìŠ¤í¬ ì˜ˆì¸¡ |\n",
    "\n",
    "### Computer Vision\n",
    "\n",
    "| íƒœìŠ¤í¬ | Pipeline ì´ë¦„ |\n",
    "|--------|-------------|\n",
    "| ì´ë¯¸ì§€ ë¶„ë¥˜ | `image-classification` |\n",
    "| ê°ì²´ íƒì§€ | `object-detection` |\n",
    "| ì´ë¯¸ì§€ ë¶„í•  | `image-segmentation` |\n",
    "| ì´ë¯¸ì§€ ìƒì„± | Stable Diffusion |\n",
    "\n",
    "### Audio\n",
    "\n",
    "| íƒœìŠ¤í¬ | Pipeline ì´ë¦„ |\n",
    "|--------|-------------|\n",
    "| ìŒì„± ì¸ì‹ | `automatic-speech-recognition` |\n",
    "| ì˜¤ë””ì˜¤ ë¶„ë¥˜ | `audio-classification` |\n",
    "| Text-to-Speech | TTS ëª¨ë¸ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. ê²°ë¡  ë° ìš”ì•½\n",
    "\n",
    "### í•µì‹¬ ì •ë¦¬\n",
    "\n",
    "1. **Hugging FaceëŠ” AI ëª¨ë¸ì˜ GitHub**\n",
    "   - 50ë§Œ+ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸\n",
    "   - ë¬´ë£Œë¡œ ì‚¬ìš© ê°€ëŠ¥\n",
    "   - í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹°\n",
    "\n",
    "2. **Pipelineìœ¼ë¡œ ë¹ ë¥¸ ì‹œì‘**\n",
    "   - 3ì¤„ ì½”ë“œë¡œ SOTA ëª¨ë¸ ì‚¬ìš©\n",
    "   - ì „ì²˜ë¦¬-ì¶”ë¡ -í›„ì²˜ë¦¬ ìë™í™”\n",
    "   - ë‹¤ì–‘í•œ íƒœìŠ¤í¬ ì§€ì›\n",
    "\n",
    "3. **ì„¸ë°€í•œ ì œì–´ê°€ í•„ìš”í•˜ë©´ Tokenizer + Model**\n",
    "   - ì»¤ìŠ¤í…€ ì „ì²˜ë¦¬ ê°€ëŠ¥\n",
    "   - ì„ë² ë”© ì¶”ì¶œ\n",
    "   - íŒŒì¸íŠœë‹ ì¤€ë¹„\n",
    "\n",
    "4. **ìë™ ìºì‹±ìœ¼ë¡œ íš¨ìœ¨ì  ì‚¬ìš©**\n",
    "   - í•œ ë²ˆ ë‹¤ìš´ë¡œë“œí•˜ë©´ ì¬ì‚¬ìš©\n",
    "   - ì˜¤í”„ë¼ì¸ ì‚¬ìš© ê°€ëŠ¥\n",
    "\n",
    "### ë‹¤ìŒ í•™ìŠµ ë°©í–¥\n",
    "\n",
    "- âœ… **íŒŒì¸íŠœë‹**: ìì‹ ì˜ ë°ì´í„°ë¡œ ëª¨ë¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•\n",
    "- âœ… **Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬**: ëŒ€ìš©ëŸ‰ ë°ì´í„° íš¨ìœ¨ì  ì²˜ë¦¬\n",
    "- âœ… **Trainer API**: í•™ìŠµ ì½”ë“œ ê°„ì†Œí™”\n",
    "- âœ… **Gradio/Spaces**: ëª¨ë¸ ë°ëª¨ ì•± ë°°í¬\n",
    "- âœ… **Quantization**: ëª¨ë¸ ê²½ëŸ‰í™”ë¡œ ì¶”ë¡  ì†ë„ í–¥ìƒ\n",
    "\n",
    "### ìœ ìš©í•œ ë§í¬\n",
    "\n",
    "- ğŸ“š [ê³µì‹ ë¬¸ì„œ](https://huggingface.co/docs)\n",
    "- ğŸ¤— [Hugging Face Hub](https://huggingface.co)\n",
    "- ğŸ“– [Transformers Course](https://huggingface.co/course)\n",
    "- ğŸ’¬ [ì»¤ë®¤ë‹ˆí‹° í¬ëŸ¼](https://discuss.huggingface.co)\n",
    "\n",
    "### ì‹¤ìŠµ ê³¼ì œ\n",
    "\n",
    "1. Hubì—ì„œ í•œêµ­ì–´ ê°ì • ë¶„ì„ ëª¨ë¸ì„ ì°¾ì•„ ì‚¬ìš©í•´ë³´ê¸°\n",
    "2. ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì„ ë¹„êµí•´ë³´ê¸°\n",
    "3. ìì‹ ë§Œì˜ í…ìŠ¤íŠ¸ë¡œ ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ‰ Hugging Face ê¸°ì´ˆ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(\"ì´ì œ ì—¬ëŸ¬ë¶„ë„ ìµœì‹  AI ëª¨ë¸ì„ ììœ ë¡­ê²Œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
